utt_0000 utt 0.06 5.07 -X WE PRESENT OUR WORK ON UNSUPERVISED CONTINUAL SEMANTIC ADAPTATION THROUGH NEURAL RENDERING.
utt_0001 utt 5.71 14.99 -X THE GOAL OF OUR WORK IS TO IMPROVE THE LEVEL OF SEMANTIC SCENE UNDERSTANDING FOR AGENTS THAT ARE DEPLOYED ACROSS A SEQUENCE OF SCENES. FOR THIS PURPOSE, WE EXPLOIT
utt_0003 utt 14.99 21.39 -X KNOWLEDGE TRANSFER BETWEEN A two-D SEMANTIC SEGMENTATION NETWORK AND A three-D REPRESENTATION.
utt_0004 utt 21.39 33.75 -X IN PARTICULAR, FOR EACH SCENE THAT THE AGENT TRAVERSES WE FORM A three-D REPRESENTATION BASED ON SEMANTIC-NERF, WHICH COMPACTLY ENCODES GEOMETRY AND PRIOR SEMANTIC KNOWLEDGE ABOUT THE SCENE.
utt_0006 utt 33.75 38.64 -X PRIOR KNOWLEDGE, HOWEVER, MIGHT FAIL TO CORRECTLY CAPTURE THE SEMANTIC CONTENT OF NEW SCENES.
utt_0007 utt 38.77 50.84 -X AS WE WILL SHOW, JOINTLY TRAINING THE three-D REPRESENTATION AND THE two-D SEMANTIC NETWORK ALLOWS EFFECTIVELY IMPROVING THE SEMANTIC UNDERSTANDING OF THE AGENT IN THESE CASES. IN SHORT, WE PROPOSE
utt_0009 utt 50.84 55.67 -X A FRAMEWORK THAT ACHIEVES UNSUPERVISED CONTINUAL SEMANTIC ADAPTATION THROUGH NEURAL RENDERING.
utt_0010 utt 56.11 60.05 -X IN THE REST OF THIS VIDEO WE WILL LOOK AT EACH OF THESE KEYWORDS MORE IN DETAIL.
utt_0011 utt 61.33 66.68 -X LET'S START BY CONSIDERING HOW A PIPELINE FOR SCENE UNDERSTANDING IS COMMONLY STRUCTURED.
utt_0012 utt 66.68 71.48 -X USUALLY, IN AN INITIAL STAGE AT A two-D SEGMENTATION NETWORK IS PRE-TRAINED ON A LARGE DATASET,
utt_0013 utt 71.48 77.68 -X USING SUPERVISED LEARNING. THEN, THE PRE-TRAINED NETWORK IS DEPLOYED ON DATA FROM A TARGET SCENE.
utt_0014 utt 78.03 88.57 -X WHEN DOING SO, HOWEVER, TWO CHALLENGES ARISE. FIRST, DUE TO THE DOMAIN GAP WITH THE PRE-TRAINING DATASET, THE PREDICTIONS OF THE NETWORK ON THE TARGET SCENE MIGHT FAIL TO CORRECTLY APPROXIMATE
utt_0016 utt 88.57 93.85 -X THE GROUND-TRUTH LABELS. THIS PROMPTS THE NEED FOR AN ADAPTATION OF THE SEGMENTATION MODEL,
utt_0017 utt 93.85 107.48 -X TO IMPROVE ITS PERFORMANCE ON THE TARGET SCENE. SECOND, FOR THIS ADAPTATION GROUND-TRUTH LABELS ARE OFTEN NOT AVAILABLE, WHICH THEREFORE FORCES THE ADAPTATION PROCESS TO BE UNSUPERVISED.
utt_0019 utt 107.48 119.27 -X A KEY OBSERVATION THAT WE MAKE USE OF IS THAT MANY PERCEPTION MODULES ARE DEPLOYED IN A MULTI-VIEW SETTING, AS FOR INSTANCE TRAJECTORIES IN A SCENE. AT THE SAME TIME, SEMANTICS ARE VIEW-CONSISTENT
utt_0021 utt 119.27 124.57 -X three-D PROPERTY, BUT two-D SEGMENTATION NETWORKS CANNOT ENFORCE THIS VIEW CONSISTENCY BY DESIGN.
utt_0022 utt 125.27 136.09 -X AS A RESULT, DIFFERENT OBSERVATIONS OF THE SAME PART OF A SCENE MIGHT BE ASSIGNED DIFFERENT SEMANTIC LABELS BY THE NETWORK. IN THIS WORK, WE PROPOSE TO MAKE USE OF MULTI-VIEW CONSISTENCY AS
utt_0024 utt 136.09 147.37 -X A SELF-SUPERVISION SIGNAL TO ADAPT THE NETWORK. FOR THIS PURPOSE, WE USE NEURAL RENDERING. IN PARTICULAR, WE ASSUME WE ARE GIVEN A PRE-TRAINED two-D SEGMENTATION NETWORK AND A SET OF POSED IMAGES
utt_0026 utt 147.37 162.01 -X TAKEN A LONGER TRAJECTORY IN A PREVIOUSLY UNSEEN SCENE. WE ADDITIONALLY INSTANTIATE A SEMANTIC-NERF MODEL, WHICH WE SUPERVISE WITH THE CAPTURED IMAGES, FOR COLOR RECONSTRUCTION, AS WELL AS WITH THE PREDICTIONS OF THE SEGMENTATION MODEL FOR THESE IMAGES, FOR SEMANTIC RECONSTRUCTION. AS
utt_0029 utt 162.01 172.81 -X THE TRAINING PROGRESSES, THE IMPERFECT SEMANTIC PREDICTIONS OF THE two-D SEGMENTATION MODEL ARE FUSED INTO A DENSE three-D REPRESENTATION. IN A SECOND STAGE, THIS three-D REPRESENTATION CAN BE USED TO
utt_0031 utt 172.81 184.19 -X RENDER MULTI-VIEW CONSISTENT SEMANTIC LABELS, WHICH WE USE AS PSEUDO LABELS TO ADAPT TO two-D NETWORK. HOWEVER, OUR SETUP PROVIDES ADDITIONAL ADVANTAGES. ON ONE HAND, GIVEN THE ABILITY OF
utt_0033 utt 184.19 196.12 -X SEMANTIC-NERF TO GENERATE PHOTOREALISTIC IMAGES WE CAN DIRECTLY USE ITS COLOR RENDERINGS AS INPUT TO THE SEGMENTATION MODEL, REMOVING THE NEED TO STORE IMAGES FOR THE MODEL ADAPTATION. MORE IMPORTANTLY,
utt_0035 utt 196.12 206.01 -X GIVEN THE FULL DIFFERENTIABILITY OF OUR SETUP WE CAN JOINTLY ADAPT SEMANTIC-NERF AND THE two-D SEGMENTATION MODEL, BY MUTUALLY SUPERVISING EACH OF THEM WITH THE OUTPUT OF THE OTHER ONE.
utt_0037 utt 208.41 219.10 -X THIS JOINT ADAPTATION ENABLES two-D/three-D KNOWLEDGE TRANSFER. ON ONE HAND, ARTIFACTS IN THE two-D PREDICTIONS ARE EFFECTIVELY RESOLVED THROUGH THE VIEW CONSISTENCY ENFORCED BY SEMANTIC-NERF.
utt_0039 utt 220.28 225.53 -X ON THE OTHER HAND, THE SMOOTHNESS OF THE two-D PREDICTIONS TRANSFERS TO THE three-D SEGMENTATION.
utt_0040 utt 226.43 236.64 -X COMPARING THE PERFORMANCE OF THE SEGMENTATION MODEL ADAPTED THROUGH OUR JOINT TRAINING WITH THAT OF THE PRE-TRAINED MODEL, WE FIND AN AVERAGE INCREASE OF PERFORMANCE OF two point six PERCENT MEAN IOU
utt_0042 utt 236.64 248.22 -X OVER ten SCENES FROM THE SCANNET DATASET. OUR NERF-BASED JOINT ADAPTATION OUTPERFORMS BOTH A VOXEL-BASED BASELINE AND SIMPLE FINE TUNING WITH OUR SEMANTIC-NERF PSEUDO LABELS.
utt_0044 utt 253.79 259.26 -X THE CONTINUOUS NERF-BASED REPRESENTATION PROVIDES ACCURATE RECONSTRUCTION OF THE SCENE GEOMETRY,
utt_0045 utt 259.39 273.82 -X WITH HIGH QUALITY TEXTURE AS WELL AS DENSE SEMANTIC INFORMATION.
utt_0046 utt 273.82 279.01 -X DESPITE THE ABSENCE OF SUPERVISION, THE SEMANTICS APPROXIMATE WELL THE GROUND-TRUTH LABELS.
utt_0047 utt 284.32 285.95 -X THROUGH JOINT TRAINING,
utt_0048 utt 285.95 296.23 -X VIEW CONSISTENCY AND SMOOTHNESS ARE EFFECTIVELY ENFORCED IN THE SEMANTICS.
utt_0049 utt 296.23 300.35 -X THE ADAPTATION PROCESS CAN BE PERFORMED SEQUENTIALLY FOR EACH NEW VISITED SCENE.
utt_0050 utt 300.35 310.21 -X HOWEVER, ADDITIONAL CARE NEEDS TO BE TAKEN. LET'S CONSIDER FOR INSTANCE THE CASE OF A PRE-TRAINED SEGMENTATION MODEL F_THETA_zero BEING ADAPTED ACROSS TWO SCENES.
utt_0052 utt 310.21 314.79 -X ADAPTATION TO SCENE NUMBER ONE WILL PRODUCE AN UPDATED VERSION F_THETA_one OF THE MODEL.
utt_0053 utt 315.36 325.76 -X WHEN TESTING THE NEW MODEL ON THE DATA FROM THE ADAPTATION SCENE, AS WE SAW THE PREDICTIONS CORRECTLY CAPTURE THE SEMANTIC CONTENT OF THE SCENE. HOWEVER, WHEN ADAPTING F_THETA_one ON SCENE
utt_0055 utt 325.76 336.85 -X NUMBER two, THEREBY OBTAINING A NEW MODEL F_THETA_two, WHILE THE PREDICTIONS OF THE NEW MODEL ON SCENE NUMBER two APPROXIMATE WELL THE SEMANTIC CONTENT OF THE SCENE, THIS IS NO LONGER THE CASE FOR
utt_0057 utt 336.85 348.10 -X THE PREDICTIONS OF THE NEW MODEL ON SCENE NUMBER one. THIS PHENOMENON IS KNOWN IN THE LITERATURE AS CATASTROPHIC FORGETTING. WE PROPOSE TO ADDRESS THIS PROBLEM THROUGH RENDERING-BASED CONTINUAL
utt_0059 utt 348.10 353.45 -4.6150 ADAPTATION. IN PARTICULAR, SINCE NERF COMPACTLY ENCODES COLOR AND SEMANTIC CONTENT AT A LIMITED,
