utt_0000 utt 0.38 5.39 -X HELLO! I'M BÃœLENT A PHD STUDENT AT NAVER LABS EUROPE AND INRIA GRENOBLE.
utt_0001 utt 5.48 10.23 -X I WILL PRESENT YOU OUR WORK CONCEPT GENERALIZATION IN VISUAL REPRESENTATION LEARNING,
utt_0002 utt 10.23 20.02 -X WHICH WE DID TOGETHER WITH YANNIS AND DIANE FROM NAVER LABS EUROPE AND KARTEEK FROM INRIA GRENOBLE. WE CONSIDER THE PROBLEM OF LEARNING GENERAL PURPOSE VISUAL REPRESENTATIONS.
utt_0004 utt 20.08 32.02 -X IN THIS PARADIGM, OUR GOAL IS TO TRAIN A MODEL BY SOLVING A PRE-TEXT TASK ON A LARGE SCALE DATA SET WHICH IS TYPICALLY IMAGENETminus oneK. AFTER WE TRAIN OUR MODEL WE HOPE THAT IT HAS LEARNED HIGH
utt_0006 utt 32.02 43.08 -X QUALITY VISUAL REPRESENTATIONS WHICH ARE USEFUL TO SOLVE DOWNSTREAM TASKS ON OTHER DATASETS EACH CONTAINING A POSSIBLY DIFFERENT SET OF IMAGES AND CLASSES. AND THE OVERALL PERFORMANCE OF OUR
utt_0008 utt 43.08 47.83 -X MODEL ON THESE DOWNSTREAM DATASETS DETERMINES THE GENERALIZATION CAPABILITY OF OUR MODEL.
utt_0009 utt 49.17 59.19 -X MEASURING THIS GENERALIZATION HAS MULTIPLE DIMENSIONS AND ONE OF THEM IS CONCEPT GENERALIZATION. IN THIS SCENARIO WE TRAIN OUR MODEL ON A SPECIFIC SET OF SEEN CONCEPTS, THEN
utt_0011 utt 59.19 70.14 -X WE EVALUATE THE REPRESENTATIONS LEARNED BY OUR MODEL ON A DIFFERENT SET OF UNSEEN CONCEPTS WITH VARYING DEGREES OF SIMILARITY TO THE SEEN ONES. THIS WAY WE QUANTIFY THE ABILITY OF OUR MODEL TO
utt_0013 utt 70.14 82.81 -X TRANSFER ITS REPRESENTATIONS ACROSS CONCEPTS. HOWEVER THERE IS NO SYSTEMATIC APPROACH FOR EVALUATING CONCEPT GENERALIZATION USING THE COMMON DOWNSTREAM DATASETS. BECAUSE WE DON'T KNOW HOW THE
utt_0015 utt 82.81 87.03 -X CONCEPTS IN THESE DATA SETS ARE SEMANTICALLY RELATED TO THE CONCEPTS IN IMAGENETminus oneK.
utt_0016 utt 87.03 92.25 -X THEREFORE IT IS NOT STRAIGHTFORWARD TO DETERMINE WHICH CONCEPTS ARE UNSEEN AT TEST TIME.
utt_0017 utt 93.27 104.83 -X MOTIVATED BY THESE ISSUES, WE PROPOSE A NEW BENCHMARK IMAGENET-COG TAILORED FOR CONCEPT GENERALIZATION. WE BUILD IMAGENET-COG ON THE FULL IMAGENETminus twenty-oneK DATASET WHICH ALLOWS US TO
utt_0019 utt 104.83 109.85 -X SELECT SEEN AND UNSEEN CONCEPTS FROM THE SAME CONCEPT ONTOLOGY, WHICH IS THE WORDNET ONTOLOGY,
utt_0020 utt 109.85 114.30 -X WHERE WE HAVE SEMANTIC SIMILARITY BETWEEN CONCEPTS MANUALLY DEFINED BY LINGUISTS.
utt_0021 utt 115.83 124.99 -X TO CREATE IMAGENET-COG, FIRST WE MEASURE THE SEMANTIC DISTANCE BETWEEN CONCEPTS USING LIN SIMILARITY, WHICH RELIES ON THE WORDNET ONTOLOGY FOR THE CONCEPTS.
utt_0023 utt 124.99 129.92 -X AS AN EXAMPLE TO LIN SIMILARITY, HERE IS THE TIGER CAT CONCEPT FROM IMAGENETminus oneK
utt_0024 utt 130.11 137.12 -X AND five OTHER CONCEPTS FROM THE FULL IMAGENETminus twenty-oneK SORTED BY THEIR SEMANTIC DISTANCE TO TIGER CAT.
utt_0025 utt 138.62 150.37 -X THEN WE GENERALIZE THIS PAIRWISE THEN SIMILARITY TO SETS OF CONCEPTS AND CREATE FIVE CONCEPT GENERALIZATION SCENARIOS. EACH SCENARIO CONSISTS OF TRAINING A MODEL ON IMAGENETminus oneK AND EVALUATING
utt_0027 utt 150.37 162.08 -X ITS PERFORMANCE ON A CONCEPT GENERALIZATION LEVEL. HERE EACH LEVEL IS A TRANSFER DATASET SAMPLED FROM THE FULL IMAGENET AND THEY ARE ARRANGED SUCH THAT FROM LEVEL one TO LEVEL five THEY CONTAIN SEMANTICALLY
utt_0029 utt 162.08 174.08 -X LESS AND LESS SIMILAR CONCEPTS TO THE ONES IN IMAGENETminus oneK. WE ALSO PROPOSE AN EFFICIENT PROTOCOL TO EVALUATE A MODEL THAT IS PRETRAINED ON IMAGENETminus oneK. CONCRETELY, WE EXTRACT IMAGE
utt_0031 utt 174.08 178.98 -X FEATURES FOR ALL THE CONCEPTS THEN WE TRAIN LINEAR CLASSIFIERS ON EACH LEVEL SEPARATELY,
utt_0032 utt 178.98 184.26 -X AND DENOTE THE PERFORMANCE OF CLASSIFIERS AS THE CONCEPT GENERALIZATION CAPABILITY OF THAT MODEL.
utt_0033 utt 184.55 195.35 -X TO TRAIN LINEAR CLASSIFIERS WE DIVIDE THE DATA FOR THE CONCEPTS ON EACH LEVEL INTO TRAINING AND TEST SETS AND TRAIN CLASSIFIERS ON THE TRAINING SETS THEN EMULATE THEIR PERFORMANCE ON THE TEST SETS
utt_0035 utt 198.85 203.94 -X WE PERFORM AN EXTENSIVE ANALYSIS USING thirty-one RECENT REPRESENTATION LEARNING MODELS.
utt_0036 utt 203.94 214.35 -X FIRST A BASELINE MODEL SUPERVISED RESNETfifty AVAILABLE IN TORCHVISION. THEN WE COMPARE THIS BASELINE AGAINST THE REMAINING thirty MODELS THAT YOU PUT INTO FOUR GROUPS:
utt_0038 utt 214.60 221.56 -X THE ARCHITECTURE GROUP, THE SELF-SUPERVISION GROUP, THE REGULARIZATION GROUP AND THE DATA GROUP
utt_0039 utt 223.94 227.69 -X THE OUTCOMES OF A SUBSET OF OUR EXPERIMENTS INCLUDE THE FOLLOWINGS.
utt_0040 utt 227.91 239.56 -X OVERALL, WE SEE THAT THE PERFORMANCE OF ALL thirty-one MODELS MONOTONICALLY DECREASES AS WE MOVE TOWARDS SEMANTICALLY SIMILAR CONCEPTS. MOREOVER, BY COMPARING EACH GROUP OF METHODS TO OUR
utt_0042 utt 239.56 244.97 -X BASELINE WE FURTHER OBSERVE THAT SELF-SUPERVISED MODELS PERFORM BETTER AND BETTER AS WE MOVE TO Lfive
utt_0043 utt 245.32 248.72 -X INDICATING THAT THEY ARE VERY PROMISING FOR CONCEPT GENERALIZATION.
utt_0044 utt 249.07 259.66 -X HOWEVER, LABEL BASED REGULARIZATION TECHNIQUES PERFORM WORSE ON ALL COG LEVELS SUGGESTING THAT THEY MIGHT BE OVER FITTING TO SCENE CONCEPTS. PLEASE VISIT OUR POSTER FOR MORE RESULTS.
utt_0046 utt 262.19 274.10 -X TO CONCLUDE, WE PROPOSE IMAGENET-COG BENCHMARK FOR MEASURING CONCEPT GENERALIZATION IN A CONTROLLED WAY. THE SEEN CONCEPTS ARE THE CONCEPTS IN THE IMAGENETminus oneK DATASET, WHEREAS THE UNSEEN CONCEPTS
utt_0048 utt 274.10 285.14 -X ARE SAMPLED FROM THE FULL IMAGENETminus twenty-oneK DATASET AND ARRANGED IN LEVELS WHICH ARE INCREASINGLY CHALLENGING TRANSFER DATASETS. THIS NATURALLY MAKES IMAGENET-COG TO BE USED OUT OF
utt_0050 utt 285.14 296.85 -X THE BOX FOR IMAGENETminus oneK PRE-TRAINED MODELS. OUR EVALUATIONS REVEALED SEVERAL INTERESTING INSIGHTS ON POPULAR STATE-OF-THE-ART MODELS. PLEASE COME TO OUR POSTER TO DISCUSS THEM IN DETAIL.
