utt_0000 utt 0.75 2.00 -X IN THIS TALK,
utt_0001 utt 2.00 5.42 -X WE PRESENT A NEW VIDEO CAMOUFLAGED OBJECT DETECTION FRAMEWORK.
utt_0002 utt 5.42 8.85 -X VIDEO CAMOUFLAGE OBJECT DETECTION IS THE TASK OF
utt_0005 utt 12.40 15.63 -X THE KEY OF THE TASK IS TO EFFECTIVELY HANDLE TEMPORAL DYNAMICS IN VIDEOS,
utt_0006 utt 15.63 18.13 -X CURRENT METHODS OFTEN LEVERAGE HOMOGRAPHY OR OPTICAL FLOW TO
utt_0009 utt 23.67 25.08 -X ON THE OTHER HAND,
utt_0011 utt 27.60 29.84 -X WITHIN A SINGLE OPTIMIZATION FRAMEWORK.
utt_0016 utt 38.36 41.88 -X THE LONG-TERM REFINEMENT MODULE TAKES T FRAME PREDICTIONS FROM
utt_0018 utt 43.41 46.84 -X THEIR CORRESPONDING REFERENCED IMAGES TO GENERATE THE FINAL PREDICTIONS.
utt_0019 utt 77.53 84.57 -X WE BUILD THE SHORT-TERM ARCHITECTURE AS A HYBRID NEURAL NETWORK WITH BOTH TRANSFORMER AND CNN COMPONENTS.
utt_0021 utt 84.86 85.82 -X IN PARTICULAR,
utt_0022 utt 86.07 89.31 -X WE USE A TRANSFORMER STRUCTURE TO ENCODE FEATURES
utt_0023 utt 89.40 92.32 -X FOR CONSTRUCTING A SHORT-TERM CORRELATION PYRAMID.
utt_0024 utt 92.63 96.41 -X BY THIS WAY, FEATURES EXTRACTED BY TRANSFORMER
utt_0025 utt 96.47 101.53 -X CAN CONTAIN GLOBAL CONTEXTUAL INFORMATION AND LESS INDUCTIVE BIAS.
utt_0026 utt 102.07 105.82 -X THUS, WE CAN GET MORE DISTINGUISHED MOTION INFORMATION.
utt_0027 utt 106.52 114.08 -X A CNN DECODER IS USED TO PREDICT THE FINAL PREDICTION FROM THE MOTIONS CAPTURED BY THE SHORT-TERM CORRELATION PYRAMID.
utt_0030 utt 115.23 119.10 -X THIS FIGURE SHOWS THE CORE UNIT OF OUR CORRELATION PYRAMID,
utt_0031 utt 119.26 122.50 -X NAMELY CORRELATION AGGREGATION BLOCK (CAB).
utt_0032 utt 122.50 129.28 -X IT COMPUTES A FULL-RANGE VOLUMETRIC CORRESPONDENCE BETWEEN THE REFERENCE FRAME AND ITS NEIGHBOURING FRAME.
utt_0034 utt 129.57 130.75 -X BY DOING THIS,
utt_0035 utt 130.78 133.60 -X WE CAN CAPTURE MOTION INFORMATION IMPLICITLY.
utt_0036 utt 134.11 138.37 -X AND THIS MODULE WILL BE UPDATED WITH THE SEGMENTATION GROUND TRUTH.
utt_0037 utt 138.66 143.43 -X THUS, WE CAN OPTIMIZE MOTION ESTIMATION AND SEGMENTATION RESULTS JOINTLY.
utt_0039 utt 144.80 149.32 -X ALTHOUGH THE CORRELATION PYRAMID STRATEGY CAN EFFECTIVELY CAPTURE MOTIONS,
utt_0040 utt 149.50 152.81 -X IT IS NOT SUITABLE FOR THE LONG VIDEO SEQUENCES,
utt_0041 utt 152.81 155.37 -X DUE TO ITS COMPUTATIONAL COMPLEXITY.
utt_0043 utt 159.14 161.25 -X WITH A SPATIAL-TEMPORAL TRANSFORMER,
utt_0044 utt 161.28 164.65 -X TO REFINE THE PREDICTION WITH LONG-TERM CONSISTENCY.
utt_0045 utt 165.09 168.84 -X WE USE THE SAME BACKBONE AS THE SHORT-TERM ARCHITECTURE.
utt_0046 utt 169.03 173.64 -X FOR EXAMPLE, THE TRANSFORMER ENCODER AND CNN DECODER.
utt_0047 utt 173.64 176.17 -X SINCE IT HAS BEEN ALREADY PRE-TRAINED ON THE DATASET,
utt_0048 utt 176.42 180.87 -X THAT COULD LARGELY ACCELERATE THE LONG-TERM TRAINING PROCESSING.
utt_0049 utt 181.77 185.77 -X AS THE VIDEO COD IS STILL A LESS-EXPLORED PROBLEM.
utt_0050 utt 185.77 188.91 -X THERE'S NO LARGE SCALE BENCHMARK.
utt_0051 utt 188.91 195.08 -X WE ORGANIZED A NEW DATASET BASED ON THE THE MOVING CAMOUFLAGED ANIMALS DATASET (MOCA).
utt_0053 utt 195.59 197.77 -X AS IN THIS ORIGINAL DATASET,
utt_0054 utt 197.99 202.44 -X THE GROUND TRUTH IS THE BOUNDING BOX RATHER THAN THE DENSE SEGMENTATION MASK.
utt_0056 utt 202.73 208.94 -X THIS MAKES IT HARD TO EVALUATE THE SEGMENTATION PERFORMANCE.
utt_0057 utt 208.94 210.83 -X AFTER THE DATASET CREATION,
utt_0058 utt 211.47 214.19 -X WE HAVE eighty-seven VIDEO SEQUENCES IN TOTAL,
utt_0059 utt 214.19 219.31 -X WITH THE HANDY-CRAFTED / PIXEL-LEVEL GT AT EVERY FIVE FRAMES.
utt_0060 utt 220.68 223.12 -X FOR THOSE FRAMES WITHOUT GROUND TRUTH,
utt_0061 utt 223.15 225.87 -X WE USE A BI-DIRECTION CHECK STRATEGY
utt_0062 utt 226.03 228.46 -X TO GENERATE THE PSEUDO GRAND TRUTH.
utt_0063 utt 228.88 231.22 -X HERE IS AN ILLUSTRATION.
utt_0064 utt 231.22 239.89 -X WE FIRST COMPUTE THE FORWARD OPTICAL FLOW SEQUENCES AND THEN USE THEM TO GENERATE PSEUDO GROUND TRUTH BY WARPING THE GROUND TRUTH AT THE FRAME T.
utt_0067 utt 240.78 243.19 -X THE BACKWARD PSEUDO GROUND TRUTH SEQUENCES
utt_0068 utt 243.57 248.69 -X ARE OBTAINED BY PERFORMING WARPING OPERATIONS IN THE INVERSE ORDER.
utt_0069 utt 250.09 252.05 -X AFTER BIDIRECTIONAL CHECK,
utt_0070 utt 252.11 256.34 -X SOME ARTIFACTS AND OCCLUSIONS CAN BE EFFECTIVELY REMOVED.
utt_0071 utt 257.68 259.41 -X AS SHOWN IN THIS TABLE,
utt_0072 utt 259.41 263.99 -X OUR METHOD OUTPERFORMS ALL THE STUDIED METHODS BY A SIGNIFICANT MARGIN.
utt_0073 utt 265.20 272.57 -X WE EVALUATE DIFFERENT APPROACHES BY STUDIED THEIR CROSS-DATASET GENERALIZATION ABILITY ON THE CAD DATASET.
utt_0075 utt 272.69 276.79 -X AGAIN, OUR PROPOSED NETWORK OBTAINS THE BEST PERFORMANCE.
utt_0076 utt 278.23 286.87 -X QUALITATIVE RESULTS SHOW THAT OUR MODEL CAN PROVIDE MORE ACCURATE PREDICTIONS IN VARIOUS CHALLENGING SITUATIONS,
utt_0078 utt 286.87 291.48 -X SUCH AS THE UNCLEAR APPEARANCE, LOW LIGHTING CONDITIONS AND TINY OBJECTS.
utt_0079 utt 292.15 296.06 -X WE NOW RELEASED OUR CODE AS WELL AS THE NEW DATASET,
utt_0080 utt 296.06 298.78 -X GET THE INFORMATION BY SIMPLY SCANNING THIS QR CODE!
utt_0081 utt 298.78 301.31 -2.3606 THAT'S ALL. THANK YOU.
