utt_0000 utt 0.59 5.23 -X WELCOME TO OUR PAPER VARITEX: VARIATIONAL NEURAL FACE TEXTURES.
utt_0001 utt 5.58 10.00 -X MY NAME IS MARCEL AND THIS IS JOINT WORK BETWEEN ETH ZURICH AND GOOGLE.
utt_0002 utt 11.63 16.75 -X THESE ARE SYNTHETIC IMAGES OF UNSEEN IDENTITIES FROM STATE-OF-THE-ART GENERATIVE MODELS.
utt_0003 utt 16.75 19.63 -X IMPRESSIVE RESULTS!
utt_0004 utt 19.63 26.00 -X BUT WHAT HAPPENS IF WE ROTATE THE HEAD POSE TO THE SIDE, FOR EXAMPLE, IN A VIRTUAL OR AUGMENTED REALITY APPLICATION?
utt_0006 utt 26.70 29.94 -X THE OUTPUTS SUFFER FROM STRONG ARTIFACTS.
utt_0007 utt 29.94 32.82 -X SOMETIMES, THEY ALSO FALL BACK TO A LESS EXTREME POSE.
utt_0008 utt 33.30 43.48 -X THE PROBLEM IS THAT THESE METHODS ARE TRAINED ON A DATASET THAT IS STRONGLY BIASED TOWARDS A FRONTAL HEAD POSE, AND THEY STRUGGLE TO EXTRAPOLATE TO MORE EXTREME POSE ANGLES.
utt_0010 utt 44.21 49.56 -X IN THIS PAPER, WE TRAIN ON THE SAME DATASET, BUT FOR THE FIRST TIME
utt_0011 utt 49.78 56.05 -X OUR METHOD OVERCOMES THIS BIAS TOWARDS FRONTAL FACES, AND SYNTHESIZES EXTREME HEAD POSES
utt_0012 utt 56.11 58.10 -X FOR UNSEEN IDENTITIES.
utt_0013 utt 58.45 62.87 -X OUR METHOD IS VARITEX: VARIATIONAL NEURAL FACE TEXTURES.
utt_0014 utt 63.28 75.42 -X IT’S THE FIRST MODEL THAT CAN GENERATE NEURAL FACE TEXTURES FOR NOVEL IDENTITIES, AND RENDER EXTREME HEAD POSES, WHILE CONTROLLING EXPRESSIONS.
utt_0016 utt 75.42 76.92 -X VARITEX IS A GENERATIVE MODEL.
utt_0017 utt 77.08 84.99 -X IT CAN SAMPLE LATENT CODES FOR NOVEL IDENTITIES AND USE THE GRAPHICAL CONTROLS TO RENDER EXTREME POSES AND EXPRESSIONS.
utt_0019 utt 86.29 89.37 -X HERE IS A DESCRIPTION OF OUR NEURAL RENDERING PIPELINE.
utt_0020 utt 90.36 95.64 -X THE INPUTS TO OUR METHOD ARE A LATENT IDENTITY CODE SAMPLED FROM A LEARNED DISTRIBUTION,
utt_0021 utt 96.02 100.35 -X AND GRAPHICAL CONTROL PARAMETERS FOR SHAPE, EXPRESSION, AND POSE.
utt_0022 utt 100.50 104.38 -X WITH THESE PARAMETERS, THE FACE MODEL GENERATES A UV MAP.
utt_0023 utt 104.89 113.50 -X GIVEN THE UV MAP AND THE LATENT CODE, THE NEURAL RENDERING PIPELINE GENERATES AN RGB IMAGE AND A FOREGROUND MASK.
utt_0025 utt 113.50 117.44 -X LET’S ZOOM INTO THE RENDERING PIPELINE.
utt_0026 utt 117.44 122.56 -X GIVEN A LATENT CODE, VARITEX GENERATES NEURAL TEXTURES IN THE FACE TEXTURE DECODER.
utt_0027 utt 123.07 128.29 -X THE UV MAP SAMPLES THIS TEXTURE TO A NEURAL FEATURE IMAGE FOR THE FACE.
utt_0028 utt 128.73 136.67 -X A SECOND DECODER ENRICHES THE NEURAL FEATURE IMAGE WITH THE MISSING REGIONS, LIKE HAIR OR THE MOUTH INTERIOR.
utt_0031 utt 142.97 151.26 -X THE VARITEX FRAMEWORK ALLOWS TO SAMPLE NEW IDENTITIES AND INTERPOLATE IN THE LATENT IDENTITY SPACE.
utt_0033 utt 151.26 156.96 -X VARITEX CAN MAINTAIN HIGH CONSISTENCY FOR CHANGES IN HEAD POSE AND FACIAL EXPRESSIONS.
utt_0034 utt 156.96 157.66 -X . . .
utt_0035 utt 158.08 164.55 -X FOR THE FACE INTERIOR REGION, THE threeD MODEL ENABLES OUR METHOD TO GENERATE VERY CONSISTENT FACES.
utt_0037 utt 164.89 171.49 -X UNLIKE PREVIOUS GENERATIVE METHODS, WE GENERATE MORE EXTREME VIEWPOINTS.
utt_0038 utt 171.49 176.93 -X THE METHOD HAS NO ACCESS TO THE GEOMETRY OF THE EXTERIOR REGION AND IT HAS NO TEMPORAL COMPONENT
utt_0040 utt 177.31 182.85 -X THEREFORE, THE PER-FRAME PREDICTIONS ARE PLAUSIBLE, BUT MIGHT NOT BE CONSISTENT OVER TIME.
utt_0041 utt 184.77 198.41 -X IN CONTRAST TO EXISTING METHODS THAT REQUIRE STRONG SUPERVISION IN THE FORM OF MULTI-VIEW IMAGES OR VIDEOS, WE TRAIN ONLY ON UNPAIRED MONOCULAR RGB IMAGES IN A SELF-SUPERVISED SETTING.
utt_0044 utt 199.04 207.56 -X DIRECTLY RECONSTRUCTING THE ORIGINAL IMAGE YIELDS ARTIFACTS, THEREFORE, WE RECONSTRUCT AN AFFINE TRANSFORMED VARIANT.
utt_0046 utt 207.56 217.83 -X OUR METHOD EXPECTS KNOWN FACIAL GEOMETRY, SO WE FIT A threeD MORPHABLE FACE MODEL, WHICH YIELDS PARAMETERS FOR SHAPE, EXPRESSION, AND POSE, WITH WHICH WE GENERATE UV MAPS.
utt_0048 utt 219.01 223.56 -X AN ENCODER MAPS THE MASKED INPUT IMAGE TO A LATENT GAUSSIAN DISTRIBUTION.
utt_0049 utt 223.56 228.36 -X WE SAMPLE A LATENT CODE AND RUN THE NEURAL RENDERING PIPELINE AS DESCRIBED BEFORE.
utt_0050 utt 229.57 235.69 -X THE FINAL OBJECTIVE FUNCTION CONSISTS OF SELF-SUPERVISED RECONSTRUCTION TERMS, A DISCRIMINATOR LOSS
utt_0051 utt 235.75 240.97 -X AND A REGULARIZATION TERM FOR THE LATENT SPACE.
utt_0052 utt 241.06 245.48 -X NOW LET’S SEE SOME RESULTS FOR CONTROLLED AND IDENTITY CONSISTENT FACE SYNTHESIS.
utt_0053 utt 246.34 249.74 -X THE FACE MODEL GIVES US ARTISTIC CONTROL OVER THE OUTPUT.
utt_0054 utt 250.12 254.83 -X WE RENDER TWO IDENTITIES WITH FRONTAL POSE AND A NEUTRAL EXPRESSION.
utt_0055 utt 254.83 256.72 -X WE THEN CHANGE EXPRESSION AND POSE.
utt_0056 utt 257.90 265.48 -X IT IS ALSO POSSIBLE TO RENDER FACES WITH EXPRESSION EXTRACTED FROM REFERENCE IMAGES.
utt_0057 utt 265.48 274.99 -X WE CONDUCT EXTENSIVE COMPARISONS, AS WELL AS A PERCEPTUAL USER STUDY AND SHOW THAT OUR METHOD CLEARLY OUTPERFORMS RELATED WORKS FOR IDENTITY-CONSISTENCY.
utt_0059 utt 275.56 281.20 -X WE ALSO PROVIDE A DEMO NOTEBOOK, MAKE SURE TO CHECK IT OUT.
utt_0060 utt 281.20 293.78 -X TO SUMMARIZE: UV MAPPING AND A DIFFERENTIABLE RENDERING PIPELINE ENABLE CONSISTENT RENDERINGS OF EXTREME POSES, EVEN WHEN TRAINED ON MOSTLY FRONTAL FACE IMAGES.
utt_0062 utt 293.78 296.50 -X PLEASE CHECK OUT OUR PROJECT PAGE FOR ALL RESOURCES AND A DEMO.
utt_0063 utt 296.75 299.50 -5.4865 THANK YOU FOR WATCHING.
