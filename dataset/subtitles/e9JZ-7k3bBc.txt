utt_0000 utt 0.81 14.99 -X HELLO, EVERYBODY, I'M FELIX NEUTATZ, AND TODAY I'M EXCITED TO SHARE OUR WORK ON DECLARATIVE FEATURE SELECTION, AND THIS IS JOINED WORK WITH FELIX BIESSMANN AND ZIAWASCH ABEDJAN. NOWADAYS, MACHINE LEARNING IS NOT ONLY ABOUT MODEL ACCURACY
utt_0003 utt 14.99 24.27 -X ANYMORE. THERE ARE MANY MORE DIMENSIONS. ONE EXAMPLE IS NETFLIX. NETFLIX HAD A COMPETITION ON FINDING THE BEST POSSIBLE RECOMMENDATION ALGORITHM,
utt_0005 utt 24.36 35.50 -X BUT THEY WERE NOT ABLE TO ACTUALLY DEPLOY THIS ALGORITHM BECAUSE OF ENGINEERING COST AND THEREFORE DEPLOYMENT CONSTRAINTS. ANOTHER EXAMPLE IS AMAZON. AMAZON HAD
utt_0007 utt 35.50 39.89 -X AN AI RECRUITING TOOL, BUT IT WAS DISCRIMINATING AGAINST WOMEN. SO,
utt_0008 utt 39.89 45.36 -X ANOTHER IMPORTANT REQUIREMENT OR CONSTRAINT IS FAIRNESS. AND THIRD,
utt_0009 utt 45.52 52.34 -X MICROSOFT DEPLOYED AN AI CHATBOT, WHICH WAS FED BAD DATA FROM SOME ADVERSARIES.
utt_0010 utt 52.69 58.74 -X SO, THE THIRD EXAMPLE IS AN EXAMPLE FOR SAFETY CONSTRAINTS. SAFETY IS IMPORTANT.
utt_0011 utt 61.84 73.07 -X ONE WAY TO ENFORCE THESE CONSTRAINTS IS TO ENFORCE THESE CONSTRAINTS IN THE MACHINE LEARNING MODEL, AND HERE WE HAVE TWO EXAMPLES. SO, YOU CAN ENFORCE FAIRNESS
utt_0013 utt 73.07 84.82 -X AND DIFFERENTIAL PRIVACY CONSTRAINTS BY ADJUSTING THE MODEL OBJECTIVES OR THE MODEL ARCHITECTURE. THE PROBLEMS WITH THIS APPROACH IS THAT IT REQUIRES ML
utt_0015 utt 84.82 95.76 -X EXPERTISE TO DESIGN THESE ARCHITECTURES AND OBJECTIVES ACCORDING TO THE CONSTRAINTS, AND WHENEVER THERE'S A NEW CONSTRAINT UPCOMING, WE MIGHT NEED
utt_0017 utt 95.76 110.50 -X TO REDESIGN THE MODEL ARCHITECTURE OR OBJECTIVE FROM SCRATCH. INSTEAD OF ENFORCING THE CONSTRAINTS IN THE MODEL, WE WERE ASKING OURSELVES, CAN WE ALSO ENFORCE THESE CONSTRAINTS IN THE DATA? AND MORE SPECIFICALLY, WE LOOKED INTO FEATURE
utt_0020 utt 110.50 121.76 -X SELECTION. SO, HERE, IN THESE TWO CHARTS, YOU SEE EACH POINT CORRESPONDING TO ONE FEATURE SUBSET OF THE COMPAS DATASET. THE COMPAS DATASET IS A WELL-KNOWN DATASET
utt_0022 utt 121.76 128.82 -X IN FAIRNESS LITERATURE, WHICH CONTAINS RECORDS OF OFFENDERS AND WHETHER THEY WILL
utt_0023 utt 129.01 140.21 -X RELAPSE BEFORE TRIAL OR NOT. SO, IF WE NOW LOOK AT THESE DIFFERENT FEATURE SUBSETS ACCORDING TO DIFFERENT METRICS, MORE SPECIFICALLY Fone SCORE AND EMPIRICAL
utt_0025 utt 140.21 151.73 -X ROBUSTNESS AGAINST ADVERSARIAL EXAMPLES AND ON THE OTHER HAND, Fone SCORE AND EQUAL OPPORTUNITY, WHICH IS A FAIRNESS SCORE, WE CAN NOW LOOK AT THE ORIGINAL FEATURE SET.
utt_0027 utt 152.37 163.72 -X SO, HERE YOU CAN SEE IT HAS A RELATIVELY LOW EMPIRICAL ROBUSTNESS AND ALSO RATHER LOW EQUAL OPPORTUNITY. SO BY ADDING AND REMOVING FEATURES, WE CAN BOTH INCREASE
utt_0029 utt 163.72 175.35 -X THE EMPIRICAL ROBUSTNESS AND ALSO THE EQUAL OPPORTUNITY. SO BY THIS, WE SHOWED THAT INDEED, WE CAN LEVERAGE FEATURE SELECTION TO ADDRESS A LARGE NUMBER OF ML
utt_0031 utt 175.35 186.13 -X APPLICATION CONSTRAINTS. IT WOULD BE GREAT IF YOU COULD SPECIFY THE PROBLEM OF FEATURE SELECTION IN THE DECLARATIVE WAY. SO, THE USER WOULD SPECIFY
utt_0033 utt 186.13 197.27 -X THE CONSTRAINTS, FOR EXAMPLE, FAIRNESS AND ADVERSARIAL ROBUSTNESS, AND OUR SYSTEM WOULD FIND THE FEATURES THAT SATISFY ALL THESE CONSTRAINTS. AND THE BIG ADVANTAGE
utt_0035 utt 197.27 208.08 -X OF THIS APPROACH IS THAT WE DO NOT REQUIRE ML EXPERTISE AND WE CAN ALSO SIMULTANEOUSLY SATISFY MULTIPLE CONSTRAINTS. BUT NOW THE QUESTION IS,
utt_0037 utt 208.62 213.81 -X WHICH IS THE RIGHT FEATURE SELECTION STRATEGY TO ACTUALLY ACHIEVE THIS GOAL?
utt_0038 utt 215.47 220.15 -X AND AS YOU CAN SEE HERE, THERE'S A LARGE NUMBER OF FEATURE SELECTION STRATEGIES,
utt_0039 utt 220.98 225.29 -X FOR EXAMPLE, WE HAVE MULTI-OBJECTIVE AND SINGLE-OBJECTIVE STRATEGIES
utt_0040 utt 225.33 237.69 -X FOR MULTI-OBJECTIVE APPROACHES. ONE EXAMPLE WOULD BE THE EVOLUTIONARY ALGORITHM, NSGA-II. WHILE SINGLE-OBJECTIVE APPROACHES ARE MORE COMMON. SO,
utt_0042 utt 237.69 250.81 -X FOR EXAMPLE, WE CAN EVALUATE ALL POSSIBLE COMBINATIONS OF FEATURES IN AN EXHAUSTIVE MANNER. HOWEVER, FOR A LARGE NUMBER OF FEATURES, THIS IS NOT A VIABLE APPROACH.
utt_0044 utt 250.81 260.05 -X THEN, THERE IS SEQUENTIAL FEATURE SELECTION, WHERE WE START EITHER WITH THE EMPTY OR THE FULL FEATURE SET AND THEN INCREMENTALLY ADD OR REMOVE FEATURES.
utt_0046 utt 261.23 265.49 -X AND FINALLY, THERE IS RANDOMIZED APPROACHES, FOR EXAMPLE,
utt_0047 utt 265.49 269.46 -X RANKING STRATEGIES THAT ARE BASED ON SIMILARITY, INFORMATION THEORY,
utt_0048 utt 269.46 280.76 -X SPARSE LEARNING, OR STATISTICS. OR, WITHOUT RANKING WOULD BE AN EXAMPLE OF SIMULATED ANNEALING. SO, HAVING ALL OF THESE STRATEGIES, THE QUESTION IS,
utt_0050 utt 280.82 295.16 -X WHICH ONE SHOULD WE ACTUALLY CHOOSE? AND THERE ARE TRADE-OFFS BETWEEN THE STRATEGIES, FOR EXAMPLE, RANKING FEATURE SELECTION STRATEGIES ARE FAST BECAUSE OF THEIR COMPLEXITY OF O(N) AND WHERE N IS THE NUMBER
utt_0053 utt 295.16 301.81 -X OF FEATURES. BUT THEY MOSTLY DO NOT WORK WELL WITH MANY COMPLEX CONSTRAINTS,
utt_0054 utt 301.81 314.70 -X SUCH AS FAIRNESS. WHILE SEQUENTIAL FEATURE SELECTION STRATEGIES ARE RATHER SLOW BECAUSE OF THEIR COMPLEXITY OF O(N^two), BUT THEY FIT WELL FOR MULTIPLE CONSTRAINTS
utt_0056 utt 314.70 326.79 -X AND ALSO COMPLEX CONSTRAINTS SUCH AS FAIRNESS. TO THIS END, WE MAKE THE FOLLOWING CONTRIBUTION. WE ANALYZE WHICH FEATURES SELECTION STRATEGIES
utt_0058 utt 326.79 334.33 -X ARE SUITABLE, IN WHICH CASES ACROSS NOVEL ML APPLICATION CONSTRAINTS, AND WE PROPOSE
utt_0059 utt 334.36 346.68 -X A DFS OPTIMIZER THAT CAN CHOOSE THE FEATURE SELECTION STRATEGY THAT IS MOST LIKELY TO SATISFY THE GIVEN SCENARIO. AND IN ORDER TO MAKE THESE CONTRIBUTIONS,
utt_0061 utt 346.68 351.58 -X WE PROPOSE THE FOLLOWING DECLARATIVE FEATURE SELECTION WORKFLOW. AS INPUT,
utt_0062 utt 351.58 356.09 -X WE GET THE FEATURES, FOR EXAMPLE, EDUCATION, GENDER, EXPERIENCE, AND RACE
utt_0063 utt 356.50 361.11 -X THEN, THE CLASSIFICATION TARGET: SHOULD WE HIRE THIS APPLICANT OR NOT?
utt_0064 utt 361.52 367.48 -X SOME APPLICATION CONSTRAINTS. THEN, WE SPLIT THE DATA INTO TRAINING, VALIDATION,
utt_0065 utt 367.48 374.26 -X AND TEST. WE HAVE A ML MODEL AND SOME ML MODEL HYPERPARAMETERS. IN THE NEXT STEP,
utt_0066 utt 374.52 386.68 -X WE PROVIDE THIS INPUT TO THE DFS OPTIMIZER AND THEN MAGICALLY - I WILL DESCRIBE LATER HOW EXACTLY - THE DFS OPTIMIZER PROPOSES A FEATURE SELECTION STRATEGY, WHICH THEN
utt_0068 utt 386.68 399.77 -X PROPOSES SOME FEATURE SUBSET, WHICH WE USE THEN TO TRAIN THE MACHINE LEARNING MODEL USING THE TRAINING DATA. AND WE WILL OPTIMIZE THE MODEL PARAMETERS
utt_0070 utt 399.86 414.57 -X ON THE VALIDATION SET BASED ON ACCURACY. AND FINALLY, WE WILL EVALUATE ALL THE CONSTRAINTS AGAIN ON THE VALIDATION SET. AND HERE FOR SINGLE-OBJECTIVE
utt_0072 utt 414.68 426.30 -X APPROACHES, WE WILL MEASURE THE DISTANCE TO SATISFYING ALL THE DIFFERENT CONSTRAINTS TO THE BEST SATISFIED. AND THIS DISTANCE, WE WILL THEN AGAIN PROVIDE
utt_0074 utt 426.30 439.39 -X BACK TO THE FEATURES SELECTION STRATEGY, WHICH WILL THEN AGAIN PROPOSE A NEW FEATURE SUBSET. AND IN THE END, WE WILL GET A FEATURE SET THAT SATISFIES ALL
utt_0076 utt 439.39 449.91 -X THE CONSTRAINTS ON THE VALIDATION DATA AND WE WILL VERIFY WHETHER THAT'S ALSO THE CASE ON THE TEST DATA. AND FINALLY, IF THAT'S THE CASE, WE WILL GET THE FEATURES
utt_0078 utt 449.91 462.39 -X THAT SATISFIED ALL OUR USER'S CONSTRAINTS. THE CHALLENGES OF THIS APPROACH ARE THAT FEATURE SELECTION IS KNOWN TO BE HARD, IN FACT, NP HARD AND PICKING A SUCCESSFUL
utt_0080 utt 462.39 472.68 -X FEATURE SELECTION STRATEGY FROM THE MULTITUDE OF STRATEGIES IS ALSO EXTREMELY HARD. TO ACHIEVE OUR VISION OF DECLARATIVE FEATURE SELECTION, WE FIRST LOOKED INTO ML
utt_0082 utt 472.68 484.04 -X APPLICATION CONSTRAINTS AND MORE SPECIFICALLY, WHAT CONSTRAINTS HAPPEN IN DAY-TO-DAY ML APPLICATIONS. AND THESE CONSTRAINTS DIFFER
utt_0084 utt 484.76 495.16 -X IN THEIR CHARACTERISTICS. SOME OF THEM ARE EVALUATION DEPENDENT - MEANING, WE REQUIRE MODEL TRAINING, FOR EXAMPLE, MINIMUM ACCURACY. SOME OF THEM ARE NOT.
utt_0086 utt 495.16 507.26 -X FOR THE MAXIMUM FEATURE SET SIZE, WE DO NOT NEED TO TRAIN A MODEL TO VERIFY WHETHER THIS CONSTRAINT IS SATISFIED. ANOTHER CHARACTERISTIC IS THE DEPENDENCE
utt_0088 utt 507.26 517.66 -X TO THE NUMBER OF FEATURES. SO WE SAW THAT MORE FEATURES ARE USUALLY BENEFICIAL FOR MINIMUM ACCURACY CONSTRAINTS. WHILE LESS FEATURES ARE USUALLY BENEFICIAL
utt_0090 utt 517.66 524.19 -X FOR MINIMUM PRIVACY BECAUSE THE LIKELIHOOD THAT DATA IS LEAKED IS LOWER. AND FINALLY,
utt_0091 utt 524.19 535.00 -X THEY ALSO DIFFER IN THEIR REQUIRED INPUTS. SO, AGAIN, FOR THE MAXIMUM FEATURE SET SIZE CONSTRAINT, WE ONLY REQUIRE THE FEATURES IN ORDER TO UNDERSTAND WHETHER
utt_0093 utt 535.00 545.47 -X THE CONSTRAINT IS SATISFIED OR NOT. NOW THAT WE UNDERSTAND THE ML APPLICATION CONSTRAINTS, THE QUESTION IS HOW CAN WE ACTUALLY DESIGN A DFS OPTIMIZER THAT CAN
utt_0095 utt 545.47 556.81 -X MAP AN ML SCENARIO TO A FEATURE SELECTION STRATEGY THAT CAN SATISFY ALL THE CONSTRAINTS? SO IN ORDER TO MAKE THE DECISION TO CHOOSE THE RIGHT FEATURE
utt_0097 utt 556.81 567.20 -X SELECTION STRATEGY, WE NEED THE MAIN COMPONENTS OF THE ML SCENARIO AND THESE ARE THE FOLLOWING. WE NEED THE DATA SET. FOR EXAMPLE, BEFORE WE ALREADY SAW THAT
utt_0099 utt 567.20 572.38 -X THE DATASET SHAPE HAS AN IMPACT ON THE FEATURE SELECTION STRATEGY COMPLEXITY.
utt_0100 utt 574.20 581.08 -X THEN, WE HAVE THE ML MODEL. HERE, ONE EXAMPLE IS THAT SOME MODELS HAVE
utt_0101 utt 581.14 592.73 -X THE ASSUMPTION OF FEATURE INDEPENDENCE AND DEPENDING ON WHETHER THE FEATURE SELECTION STRATEGIES HAVE THE SAME ASSUMPTION, THEY WORK WELL TOGETHER OR NOT. AND FINALLY,
utt_0103 utt 592.73 602.22 -X WE HAVE TO CONSTRAINTS THEMSELVES. AND LIKE I SAID BEFORE, IF YOU HAVE MULTIPLE CONSTRAINTS, THAT MIGHT BE AN ISSUE FOR SOME OF THE STRATEGIES THAT ARE NOT AS
utt_0105 utt 602.22 609.47 -X FLEXIBLE. BUT WE ALSO HAVE SOME REQUIREMENTS FOR THIS DFS OPTIMIZER.
utt_0106 utt 609.47 623.07 -X FIRST, WE DO NOT ALLOW TRIAL AND ERROR BECAUSE WE DO NOT WANT TO RUN MULTIPLE FEATURE SELECTION STRATEGIES AND THEN KNOW THE RESULTS. WE WANT TO BE FAST. SO TRIAL
utt_0108 utt 623.07 637.37 -X AND ERRROR IS NOT ALLOWED. SECONDLY, WE REQUIRE EXTENSIBILITY TO MORE CONSTRAINTS AND STRATEGIES. AND RELATED TO THIS REQUIREMENT, WE REQUIRE NO HUMAN
utt_0110 utt 637.37 642.53 -X SUPERVISION BECAUSE WHENEVER THERE'S NEW CONSTRAINTS OR STRATEGIES ADDED,
utt_0111 utt 642.53 652.19 -X THERE SHOULD BE NO HUMAN THAT HAS TO LABEL OR ADD ANY RULES TO THE SYSTEM. BASED
utt_0112 utt 652.19 658.11 -X ON THESE REQUIREMENTS, WE HAVE TO SPECIFY THE PROBLEM AS A CLASSIFICATION TASK. SO,
utt_0113 utt 658.11 668.89 -X AGAIN, WE HAVE AS INPUT THE ML SCENARIO, NAMELY THE DATASET, THE ML MODEL AND THE CONSTRAINTS. AND BASED ON THIS SCENARIO, WE WILL PREDICT WHETHER A GIVEN
utt_0115 utt 668.89 681.73 -X STRATEGY WILL SATISFY THAT SCENARIO OR NOT. SO FOR EACH STRATEGY, WE HAVE ONE ML MODEL THAT PREDICTS THE LIKELIHOOD OF SATISFYING THE CONSTRAINTS AND THEN WE CAN
utt_0117 utt 681.73 693.89 -X JUST PICK THE STRATEGY THAT YIELDS THE HIGHEST ESTIMATED LIKELIHOOD. SO IN THIS CASE STRATEGY THREE. NOW, YOU MIGHT WONDER HOW DO WE ACTUALLY GET THE TRAINING DATA
utt_0119 utt 693.89 705.95 -X TO TRAIN ALL THESE CLASSIFICATION MODELS? HERE, OUR APPROACH IS TO FIRST SPECIFY A TEMPLATE FOR THE SEARCH SPACE, SO THE SEARCH SPACE BASED ON THE CLASSIFIER,
utt_0121 utt 705.95 717.20 -X THE CONSTRAINTS SUCH AS, FOR EXAMPLE, MAXIMUM SEARCH TIME BETWEEN ten SECONDS AND THREE HOURS, AND WE WILL SAMPLE FROM THIS SPACE AND THEN EXECUTE ALL
utt_0123 utt 717.20 728.08 -X THE FEATURE SELECTION STRATEGIES WHICH YIELDS US THE TRAINING SET WE NEED. SO NOW THE QUESTION IS, HOW CAN WE ACTUALLY FEATURIZE OUR ML SCENARIO. FOR THE DATA
utt_0125 utt 728.08 738.69 -X SET, WE CAN TAKE THE NUMBER OF ROWS AND COLUMNS. FOR THE MODEL, WE ONE-HOT ENCODE ALL AVAILABLE MODELS, AND FOR THE CONSTRAINTS, WE TAKE THE THRESHOLDS HERE,
utt_0127 utt 739.29 749.89 -X eighty AND ninety-five PERCENT AND WE APPLY LANDMARKING. WHY WE NEED LANDMARKING I WILL DISCUSS IN A MOMENT. BUT THE GOOD THING ABOUT THESE FEATURES IS THAT
utt_0129 utt 749.89 760.06 -X THEY PROVIDE EXTENSIBILITY TO MORE MODELS AND CONSTRAINTS. SO IF WE HAVE ANOTHER MODEL, WE CAN SIMPLY ADD ONE MORE ONE-HOT ENCODING FEATURE, OR IF WE HAVE MORE
utt_0131 utt 760.06 770.88 -X CONSTRAINTS, WE CAN ADD MORE THRESHOLD OR LANDMARKING FEATURES. TO CHOOSE THE RIGHT FEATURE SELECTION STRATEGY, OUR DFS OPTIMIZER HAS TO UNDERSTAND HOW
utt_0133 utt 770.88 785.03 -X RESTRICTIVE CERTAIN CONSTRAINTS ACTUALLY ARE. SO HERE WE HAVE AN EXAMPLE OF SOME USER CONSTRAINTS WHERE THE FAIRNESS IS GREATER ninety PERCENT AND ACCURACY IS GREATER eighty PERCENT. SO, FOR A LINEARLY SEPARABLE DATASET,
utt_0136 utt 785.21 796.74 -X AN ACCURACY OF GREATER eighty PERCENT WOULD BE AN EASY TASK TO ACHIEVE, WHEREAS IF WE HAVE MORE COMPLEX CLASSIFICATION TASKS. THIS MIGHT BE ACTUALLY REALLY HARD
utt_0138 utt 796.74 807.71 -X TO ACHIEVE. SO, IT REALLY DEPENDS ON THE DATASET WHETHER THESE CONSTRAINTS ARE RESTRICTIVE OR NOT. AND IN ORDER TO UNDERSTAND HOW RESTRICTIVE THEY ACTUALLY
utt_0140 utt 807.71 820.29 -X ARE, WE LEVERAGE LANDMARKING. SO MORE SPECIFICALLY, WE TAKE A SMALL SAMPLE OF THE DATASET. THEN, WE APPLY A FAST MODEL HERE, LOGISTIC REGRESSION,
utt_0142 utt 820.61 832.71 -X AND WE GET THE CORRESPONDING SCORES ON THIS VERY SMALL SAMPLE HERE FAIRNESS OF eighty PERCENT AND ACCURACY OF ninety PERCENT. SO WE CAN ACTUALLY CLEARLY SEE ALREADY THAT
utt_0144 utt 832.71 843.59 -X THE ACCURACY CONSTRAINT IS NOT THE PROBLEM HERE. WE ALREADY ACHIEVED VERY GOOD ACCURACY ON THE SMALL SAMPLE. WHILE THE DIFFERENCE TO THE FAIRNESS CONSTRAINT
utt_0146 utt 843.59 855.59 -X IS HIGHER, IT'S AROUND ten PERCENT. SO HERE, THE FAIRNESS CONSTRAINT IS MORE RESTRICTIVE. SO IT TURNS OUT THE LANDMARKING IS A FAST AND EFFECTIVE WAY
utt_0148 utt 855.59 867.91 -X TO ESTIMATE THE DIFFICULTY OF SATISFYING THE CONSTRAINTS. TO EVALUATE OUR OPTIMIZER, WE DESIGNED A BENCHMARK WHICH CONSISTS OUT OF three thousand, three hundred and eighteen SCENARIOS
utt_0150 utt 870.02 874.87 -X AND nineteen DATASETS, six ML APPLICATION CONSTRAINTS, THREE CLASSIFICATION MODELS
utt_0151 utt 874.94 882.28 -X AND sixteen FEATURE SELECTION STRATEGIES. AND THE DATASETS VARY ACROSS INSTANCES,
utt_0152 utt 882.28 895.94 -X ATTRIBUTES AND FEATURES AND ALSO THE CORRESPONDING SENSITIVE ATTRIBUTE WHICH WE USE FOR FAIRNESS. THE RESEARCH QUESTIONS THAT WE ANSWER IN THESE BENCHMARKS ARE THE FOLLOWING: WHICH STRATEGY CAN COVER MOST SCENARIOS
utt_0155 utt 895.94 907.91 -X AND WHICH STRATEGY IS THE FASTEST? CAN WE LEARN TO CHOOSE THE BEST STRATEGY USING OUR DFS OPTIMIZER? CAN WE COMBINE MULTIPLE STRATEGIES AND BE EFFECTIVE. AND OTHER
utt_0157 utt 907.91 918.47 -X QUESTIONS ARE HOW IS THE STRATEGIES' PERFORMANCE AFFECTED BY DIFFERENT ML MODELS, DATASET AND CONSTRAINTS. AND WHICH STRATEGY IS ACTUALLY BEST IF WE OPTIMIZE
utt_0159 utt 918.47 923.88 -X A UTILITY? AND FINALLY, CAN WE REUSE FEATURES FOR OTHER MODELS. THE BOLD
utt_0160 utt 923.90 935.94 -X QUESTIONS I WILL ANSWER IN THIS TALK WHILE THE OTHER ONES I WOULD POINT YOU TO THE PAPER. AND THESE ARE SOME RESULTS. SO HERE WE LOOK AT TWO METRICS,
utt_0162 utt 935.94 945.83 -X FASTEST AND COVERAGE. FASTEST IS THE FRACTION OF SCENARIOS THAT A STRATEGY X WAS THE FASTEST AND COVERAGE IS THE FRACTION OF SCENARIOS THAT A STRATEGY
utt_0164 utt 946.27 961.03 -X SATISFIED. AS WE CAN SEE, NONE OF THE STRATEGIES ARE ALWAYS THE FASTEST AND NONE OF THE STARTEGIES CAN COVER one hundred PERCENT OF THE SCENARIOS. THE SECOND THING WE CAN SEE
utt_0166 utt 961.03 972.71 -X IS THAT INDEED OUR DFS OPTIMIZER REACHES A ten PERCENT HIGHER COVERAGE THAN ANY SINGLE STRATEGY IN THIS CASE, A TREE PARZEN ESTIMATOR WITH RANKING OF FAST
utt_0168 utt 972.71 986.79 -X CORRELATION-BASED FILTERING. BUT WE ALSO SEE THAT THERE'S STILL A LOT SPACE FOR IMPROVEMENT TO ACHIEVE THE THEORETICAL OPTIMUM OF one hundred PERCENT OF THE SCENARIOS.
utt_0170 utt 986.79 999.40 -X INSTEAD OF RUNNING JUST A SINGLE STRATEGY, ONE COULD ALSO RUN MULTIPLE STRATEGIES SIMULTANEOUSLY. AND WE DID EXACTLY THAT AND WE LOOKED AT WHICH OF THE COMBINATIONS
utt_0172 utt 999.52 1011.30 -X YIELD THE OPTIMAL COVERAGE OR THE OPTIMAL SPEED. SO, FOR EXAMPLE, HERE TREE PARZEN ESTIMATOR WITH FAST CORRELATION-BASED FILTERING AS RANKING TOGETHER WITH
utt_0174 utt 1011.30 1015.91 -X SEQUENTIAL FLOATING FORWARD SELECTION YIELDS ALREADY eighty-three PERCENT COVERAGE.
utt_0175 utt 1015.91 1028.84 -X THAT'S REALLY GOOD. AND THE SAME IS TRUE FOR SPEED. SO IF WE JUST RUN FIVE STRATEGIES SIMULTANEOUSLY, WE ALREADY GET IN fifty-two PERCENT OF THE CASES, THE FASTEST
utt_0177 utt 1028.84 1042.44 -X RESULT. AND IN THIS IMPLEMENTATION, WE DO NOT YET LEVERAGE ANY SYNERGY EFFECTS THAT COULD BE LEVERAGED. BUT WE ALREADY SEE THESE REALLY GOOD NUMBERS, SO THERE'S
utt_0179 utt 1042.44 1051.14 -X STILL POTENTIAL FOR FUTURE RESEARCH TO CLOSE THIS GAP. SO, TO CONCLUDE RUNNING
utt_0180 utt 1051.14 1063.37 -X COMPLEMENTARY STRATEGIES IS HIGHLY EFFECTIVE. TO CONCLUDE THE PROPOSED ARTICLE TO FEATURE SELECTION, WHICH ALLOWS A USER TO SPECIFY MULTIPLE DIVERSE ML
utt_0182 utt 1063.37 1067.11 -X APPLICATION CONSTRAINTS THAT ARE THEN SATISFIED BY FEATURE SELECTION,
utt_0183 utt 1067.33 1077.48 -X AND WE PROPOSE AN OPTIMIZER THAT LEVERAGES META LEARNING TO CHOOSE THE FEATURE SELECTION STRATEGY THAT MOST LIKELY SATISFIES THE USER'S CONSTRAINTS.
utt_0185 utt 1077.57 1086.44 -X AND YOU CAN FIND THE CODE OPENLY AVAILABLE ON GITHUB. AND WITH THAT, I WOULD LIKE TO THANK YOU FOR YOUR ATTENTION AND GOODBYE.
