utt_0000 utt 0.84 6.74 -X HI, THIS VIDEO IS TO PRESENT OUR CHI two thousand and twenty PAPER TITLED QUESTIONING THE AI
utt_0001 utt 6.80 19.65 -X INFORMING DESIGN PRACTICES FOR EXPLAINABLE AI USER EXPERIENCES. MY NAME IS VERA LIAO. I'M A RESEARCHER WORKING AT IBM RESEARCH. THIS IS JOINT WORK WITH MY COLLEAGUES DAN GRUEN AND SARAH MILLER
utt_0004 utt 21.80 30.71 -X ARTIFICIAL INTELLIGENCE TECHNOLOGIES ESPECIALLY THOSE USING MACHINE LEARNING ARE INCREASINGLY USED EVERYWHERE INCLUDING HIGH-STAKES TASKS SUCH AS
utt_0006 utt 30.71 43.87 -X SUPPORTING DECISION MAKING IN HEALTHCARE, FINANCE AND SOCIAL JUSTICE. ACCOMPANYING THIS TREND IS A QUEST FOR EXPLAINABLE AI. THAT IS, MAKING AI MORE TRANSPARENT AND
utt_0008 utt 43.87 54.10 -X UNDERSTANDABLE BY PEOPLE SO PEOPLE CAN FEEL MORE CONFIDENT OR BETTER EXERCISE CAUTIONS WITH AI'S DECISIONS, AND ULTIMATELY BETTER WORK AND LIVE TOGETHER WITH AI
utt_0010 utt 56.33 67.57 -X BUT EXPLAINABLE AI IS HARD. IT INVOLVES A LOT OF TECHNICAL WORK. THERE ARE MANY DIFFERENT MACHINE LEARNING ALGORITHMS AND NOT ALL A STRAIGHTFORWARD EXPLAINABLE. IT
utt_0012 utt 67.57 78.32 -X IS ALSO COMMONLY RECOGNIZED THAT POPULAR, HIGH-PERFORMING ALGORITHMS SUCH AS THOSE USING NEURAL NETWORKS ARE ESPECIALLY COMPLEX, OPAQUE AND ALMOST IMPOSSIBLE TO
utt_0014 utt 78.32 91.54 -X EXPLAIN THE INNER WORKING DIRECTLY. SO OFTEN A SEPARATE SET OF TECHNIQUES OR ALGORITHM HAVE TO BE USED TO GENERATE EXPLANATIONS THAT CAN BE CONSUMED BY PEOPLE.
utt_0016 utt 91.54 102.26 -X DEVELOPING THESE TECHNIQUES IS THE MAIN FOCUS OF THE RESEARCH FIELD EXPLAINABLE AI, OR XAI, WHICH STARTED AS A SUB-FIELD OF AI RESEARCH. THESE ARE JUST
utt_0018 utt 102.26 113.24 -X SOME RECENT REVIEW PAPERS ON THE TOPIC. THERE ARE AT THE SCALE OF HUNDREDS IF NOT MORE PAPERS PUBLISHED ON THE TOPIC. ANOTHER NOTABLE TREND IS THAT VERY
utt_0020 utt 113.24 127.25 -X RECENTLY A GROWING NUMBER OF TOOLKITS ARE MAKING THESE XA TECHNIQUES ACCESSIBLE FOR PRACTITIONERS. SO WE ARE SEEING EXPLANATIONS BECOMING AN INSTRUMENTAL PART, AND LIKELY INCREASING SO, IN REAL-WORLD AI SYSTEMS.
utt_0023 utt 130.03 143.92 -X EXPLAINABLE AI IS ALSO HARD BECAUSE EXPLANATION HAS TO BE MEANINGFUL TO THE PEOPLE DEMANDING IT. SIMPLY EXPOSING A MODEL'S INNER WORKING DOES NOT GUARANTEE THE INFORMATION IS UNDERSTANDABLE OR USEFUL TO THE USERS.
utt_0026 utt 144.78 159.14 -X THERE ARE ALSO MANY DIFFERENT TYPE OF USER WHO MAY HAVE DIFFERENT REASONS AND REQUIREMENTS TO SEEK EXPLANATIONS. SO CREATING EXPLAINABLE AI SYSTEMS SHOULD FOLLOW A USER-CENTERED PROCESS TO BRIDGE TECHNICAL CAPABILITIES AND THE FULFILLMENT
utt_0029 utt 159.14 172.23 -X OF USER NEEDS. IN PRODUCT PRACTICES THIS KIND OF WORK OFTEN FALLS ON DESIGN AND USER EXPERIENCE PRACTITIONERS, WHOSE JOB INVOLVES IDENTIFYING USER NEEDS
utt_0031 utt 172.23 186.33 -X COMMUNICATING WITH DATA SCIENTISTS, DEVELOPERS AND STAKEHOLDERS AND CREATING DESIGN SOLUTIONS BASED ON DEMANDS AND CONSTRAINTS ON BOTH SIDES. THEREFORE IN THIS WORK WE LOOK INTO THE DESIGN PRACTICES AROUND THE CURRENT AND
utt_0034 utt 186.33 191.97 -X UPCOMING EXPLAINABLE AI TECHNOLOGIES. OUR GOAL IS TO IDENTIFY OPPORTUNITIES TO
utt_0035 utt 192.05 197.08 -X BETTER SUPPORT SUCH WORK HENCE THE CREATION OF USER CENTERED EXPLAINABLE AI.
utt_0036 utt 198.26 208.15 -X BY TALKING TO DESIGN PRACTITIONERS ACROSS MANY AI PRODUCTS WE ALSO HOPE TO UNDERSTAND REAL-WORLD USER NEEDS FOR EXPLAINABLE AI AND THE DESIGN SPACE,
utt_0038 utt 208.18 212.66 -X WHICH COULD HELP INFORM FUTURE DIRECTIONS FOR THE RESEARCH FIELD OF XAI.
utt_0039 utt 216.02 229.51 -X BUT VERY QUICKLY WE RAN INTO THE CHALLENGE OF HOW TO TALK ABOUT A TECHNICAL SPACE THAT PEOPLE ARE NOT QUITE IN THERE YET, SINCE WE JUST BEGAN INTRODUCING WHAT'S PRODUCED IN THE ACADEMIC WORLD TO PRACTITIONERS. OUR INFORMANTS
utt_0042 utt 229.51 241.08 -X MAY NOT BE FAMILIAR WITH DIFFERENT XAI ALGORITHMS OR HAVE AN ESTABLISHED FRAMEWORK TO TALK ABOUT USER NEEDS FOR EXPLAINABILITY. SO WE DECIDED TO CREATE
utt_0044 utt 241.08 253.00 -X A STUDY PROBE--A LIST OF ALGORITHM INFORMED XAI QUESTIONS. THE PROBE IS BASED ON THE FOLLOWING ASSUMPTIONS: FIRST, USER NEEDS FOR EXPLAINABILITY CAN BE
utt_0046 utt 253.00 263.51 -X REPRESENTED BY PROTOTYPICAL QUESTIONS SUCH AS WHY, WHAT IF, HOW. THIS IS BOTH BASED ON PRIOR WORK ON EXPLAINING COMPUTING SYSTEMS,
utt_0048 utt 263.51 269.24 -X AND FUNDAMENTALLY, THE DEFINITION THAT EXPLANATION IS AN ANSWER TO A QUESTION.
utt_0049 utt 270.16 279.90 -X WE ALSO ASSUME THAT A PROTOTYPICAL QUESTIONS CAN BE ANSWERED BY ONE OR MULTIPLE XAI METHODS, WHICH CAN BE IMPLEMENTED BY ONE OR MULTIPLE XAI
utt_0051 utt 279.90 290.84 -X ALGORITHMS. THE KEY IDEA HERE IS THAT EVEN THOUGH THERE ARE HUNDREDS OF XAI ALGORITHMS MANY OF THEM PRODUCE THE SAME KIND OF OUTPUT OR METHOD TO EXPLAIN, SO
utt_0053 utt 290.84 302.71 -X THERE IS A MUCH MORE FINITE LIST OF XAI METHODS. FOR EXAMPLE, A WHY QUESTION ASKING ABOUT A PARTICULAR AI DECISION CAN BE EXPLAINED BY A POPULAR METHOD
utt_0055 utt 302.97 313.34 -X CALLED LOCAL FEATURE IMPORTANCE, WHICH HIGHLIGHTS THE MOST IMPORTANT FEATURES OF THE INSTANCE THAT CONTRIBUTED TO THE AI'S DECISION. IN THIS CASE, PIXELS THAT
utt_0057 utt 313.34 322.71 -X THE IMAGE CLASSIFIER USED TO DETERMINE THIS IS A WOLF BY MISTAKE. MEANWHILE THERE ARE MANY POPULAR ALGORITHMS TO IMPLEMENT THIS LOCAL FEATURE IMPORTANCE
utt_0059 utt 322.71 334.62 -X METHOD. BASED ON THIS REASONING WE STARTED WITH A LITERATURE REVIEW OF TECHNICAL XAI WORK AND ARRIVED AT A TAXONOMY OF EXPLANATION METHODS. THEN
utt_0061 utt 334.62 339.96 -X WE MAP THEM TO A TOTAL OF SIX CATEGORIES OF PROTOTYPICAL QUESTIONS SUCH AS WHY
utt_0062 utt 339.99 351.00 -X WHAT IF, HOW. WE ALSO DECIDED TO TAKE A BROAD VIEW OF EXPLAINABLE AI AND ADDED THREE MORE DESCRIPTIVE CATEGORIES OF QUESTIONS BASED ON PRIOR WORK. THESE ARE
utt_0064 utt 351.00 362.40 -X QUESTIONS REGARDING AI'S INPUT, OUTPUT AND PERFORMANCE. FOR EACH CATEGORY OF THE PROTOTYPICAL QUESTION WE CREATED A QUESTION CARD. IT INCLUDES THE LEADING
utt_0066 utt 362.40 375.68 -X QUESTION AND COMMENT EXAMPLES. THEN WE BROUGHT THESE QUESTION CARDS TO THE INFORMANTS. IN TOTAL WE INTERVIEWED TWENTY DESIGN PRACTITIONERS WORKING ON sixteen DIFFERENT AI PRODUCTS. IN EACH INTERVIEW WE ASKED
utt_0069 utt 375.68 383.48 -X THE INFORMANT TO FIRST WALK THROUGH THE AI SYSTEM, THEN DISCUSS WHAT ARE THE COMMON QUESTIONS USERS MIGHT ASK TO UNDERSTAND THE AI.
utt_0071 utt 383.99 397.60 -X AFTER THAT WE WALK THROUGH EACH QUESTION CARD AND DISCUSS WHETHER THEY APPLY AND IF THERE ARE ANY MISSING QUESTIONS. WE CLOSED THE INTERVIEWS BY DISCUSSING WHAT ARE THE CHALLENGES DESIGN PRACTITIONERS AND THEIR TEAMS
utt_0074 utt 397.60 408.51 -X FACE TO CREATE EXPLAINABLE AI SYSTEMS. THROUGH STEP TWO AND STEP THREE WE GATHERED A LIST OF USER QUESTIONS. WE PERFORMED CONTENT ANALYSIS ON THESE
utt_0085 utt 453.57 459.92 -X USER EXPERIENCE. THE FIRST CHALLENGE DESIGNERS FACE IS THE VARIABILITY OF
utt_0086 utt 460.03 471.17 -X USERS' EXPLAINABILITY NEEDS. FIRST OF ALL THERE ARE DIVERSE MOTIVATIONS FOR PEOPLE TO DEMAND EXPLANATIONS. WE SUMMARIZED FIVE MAIN CATEGORIES WITH MORE DETAILS IN THE
utt_0088 utt 471.17 482.58 -X PAPER. FOR EXAMPLE SOME USERS DEMAND EXPLANATION TO GAIN FURTHER INSIGHTS FOR THEIR DECISIONS. AS THE EXAMPLE GIVEN BY THIS INFORMANT, IT WAS NOT ENOUGH FOR THE
utt_0090 utt 482.58 495.81 -X AI TO GIVE A PREDICTION TO SUPPLY CHAIN MANAGEMENT WORKERS THAT A DELIVERY MIGHT BE DELAYED. MORE IMPORTANTLY USERS WANT TO UNDERSTAND THE REASON FOR THE POTENTIAL DELAY, WHETHER IT IS BECAUSE OF THE WEATHER, OR SOMEWHERE THEY COULD
utt_0093 utt 495.81 506.66 -X MAKE A QUICK CALL TO. SO THEY CAN TAKE ACTIONS BASED ON THE EXPLANATIONS. IN THIS CONTEXT USER MAY ASK A WHY-QUESTION, WHY THE DELIVERY IS PREDICTED TO BE LATE,
utt_0095 utt 506.66 519.27 -X AND HOW TO REDUCE THE DELAY. A DIFFERENT MOTIVATION FOR DEMANDING EXPLANATION IS TO APPROPRIATELY EVALUATE THE CAPABILITY OF THE AI. FOR EXAMPLE A DOCTOR IS INTRODUCED
utt_0097 utt 519.27 527.84 -X TO A NEW AI SYSTEM FOR MEDICAL IMAGING. THE DOCTOR MAY WANT TO UNDERSTAND BOTH HOW WELL THE SYSTEM PERFORMS AND HOW THE SYSTEM MAKES ITS JUDGMENT.
utt_0099 utt 529.63 538.98 -X THESE ARE TWO OUT OF THE FIVE TYPES OF MOTIVATION WE IDENTIFIED. WE ALSO IDENTIFIED OTHER FACTORS MENTIONED BY THE INFORMANTS THAT COULD VARY USERS' EXPLAINABILITY
utt_0101 utt 538.98 549.83 -X NEEDS INCLUDING USER GROUP, USAGE POINTS, ALGORITHM AND DATA TYPE, AND THE DECISION CONTEXTS. A SECOND CHALLENGE THAT WE SAW
utt_0103 utt 549.83 559.65 -X INFORMANTS STRUGGLE WITH IS THE GAPS BETWEEN EXPLANATION AS A COMMON ELEMENT IN HUMAN COMMUNICATION AND WHAT CURRENT AI TECHNOLOGY CAN PRODUCE. THEY MENTIONED SOME
utt_0105 utt 559.65 571.51 -X COMMON CRITERIA OF HUMAN EXPANSIONS, THUS WHAT USERS MIGHT EXPECT TO SEE, SUCH AS BEING SELECTIVE, CONTRASTIVE, INTERACTIVE AND TAILORED FOR THE RECIPIENTS. HOWEVER
utt_0107 utt 571.51 576.39 -X IT IS OFTEN NOT POSSIBLE TO GENERATE EXPLANATIONS THAT SATISFY THESE CRITERIA
utt_0108 utt 576.64 588.26 -X BOTH CONSTRAINED BY CURRENT TECHNICAL CAPABILITIES AND THE INHERENT DISCRENPENCY BETWEEN HOW HUMAN AND AI MAKES DECISIONS. LASTLY, INFORMANTS DISCUSSED SOME
utt_0110 utt 588.26 602.21 -X PROCESS-ORIENTED CHALLENGES FOR AI PRODUCT TEAMS TO INVEST ON OR PRIORITIZE EXPLAINABILITY. ONE CHALLENGE IS FOR DESIGNERS TO NAVIGATE THE TECHNICAL CAPABILITIES TO EXPLAIN AI, PARTLY DUE TO THE SKILL
utt_0113 utt 602.21 612.95 -X GAPS, AND ALSO IT IS CHALLENGING TO KEEP TRACK OF THE QUICKLY GROWING LANDSCAPE OF XAI. THERE ARE ALSO BARRIERS FOR DESIGNERS TO EFFECTIVELY COMMUNICATE
utt_0115 utt 612.95 626.60 -X WITH DATA SCIENTISTS AND OTHER STAKEHOLDERS AROUND EXPANDABILITY, EVEN THOUGH EXPLAINABLE AI SOLUTIONS SHOULD BE JOINTLY SOUGHT FROM A USER PERSPECTIVE AND MODELING PERSPECTIVE. THIS COMMUNICATION COST COMBINED WITH
utt_0118 utt 626.60 638.47 -X PROTOTYPING COST TO EXPLORE DESIGN SOLUTIONS OFTEN DISCOURAGE AI PRODUCT TEAMS TO PRIORITIZING EXPLAINABILITY, WHICH COULD BE AT ODDS WITH OTHER PRODUCT GOALS.
utt_0120 utt 638.47 643.24 -X MANY BELIEVED THAT THESE PROBLEMS CAN BE MITIGATED BY HAVING STRUCTURED GUIDANCE
utt_0121 utt 643.27 652.93 -X THAT HELPS THE TEAM EFFICIENTLY NAVIGATE TO DESIRED EXPLAINABILITY SOLUTIONS. WE SUMMARIZED THE DESIRED SUPPORT IN TWO AREAS:
utt_0123 utt 652.93 657.96 -X ONE IS TO SUPPORT THE NEEDS SPECIFICATION WORK. WHAT ARE THE EXPLAINABILITY NEEDS
utt_0124 utt 658.08 669.64 -X SPECIFIC TO A PRODUCT, A USER GROUP, EVEN A PARTICULAR INTERACTION. SECOND IS AFTER NEEDS SPECIFICATION, GUIDELINES OR RECOMMENDATIONS TO ADDRESS THE NEEDS,
utt_0126 utt 670.05 680.81 -X IDEALLY WITH EXAMPLE ARTIFACTS SUCH AS MODEL OUTPUT OR UI PATTERNS TO SAVE THE PROTOTYPING COST. YOU MAY CONSIDER THE TWO AREAS AS ANSWERING WHAT TO EXPLAIN,
utt_0128 utt 680.81 695.72 -X AND HOW TO EXPLAIN, RESPECTIVELY. NOW COMING BACK TO THE XAI QUESTION BANK. WE SUGGEST THAT THIS LIST OF PROTOTYPICAL USER QUESTIONS CAN BE LEVERAGED FOR NEEDS SPECIFICATION WORK, WHETHER AS A CHECKLIST OR IN USER RESEARCH TO
utt_0131 utt 695.72 699.94 -X ENUMERATE ON AND PRIORITIZE DIFFERENT TYPES OF USER NEEDS FOR AI EXPLAINABILITY,
utt_0132 utt 699.94 710.73 -X FOR EXAMPLE THROUGH A CAR SORTING EXERCISE. IN OUR PAPER THE QUESTION BANK AND INFORMANTS' DISCUSSIONS AROUND IT ALSO SERVED TWO OTHER FUNCTIONS, WHICH I WILL NOT
utt_0134 utt 710.73 724.62 -X GO INTO DETAIL BUT POINT YOU TO THE PAPER. ONE IS TO GROUND OUR UNDERSTANDING ON WHY THESE USE QUESTIONS ARE ASKED IN REAL WORLD CONTEXTS. BASED ON THAT WE DERIVED A SET OF GUIDELINES TO ADDRESS EACH CATEGORIES OF USER NEEDS FOR
utt_0137 utt 724.62 739.19 -X EXPANDABILITY. SECOND, UNDERSTANDING WHERE THESE QUESTIONS EMERGE, ESPECIALLY THE NEWLY IDENTIFIED QUESTIONS THAT WERE NOT IN THE ALGORITHM INFORMED QUESTION LIST, WE IDENTIFY GAPS IN CURRENT TECHNICAL WORK
utt_0140 utt 739.19 749.61 -X OF XAI AND OPPORTUNITIES FOR FUTURE WORK. BACK TO TACKLING THE PROCESS-ORIENTED CHALLENGES, AT END OF THE PAPER, WE PROPOSE A QUESTION DRIVEN
utt_0142 utt 749.61 760.79 -X DESIGN PROCESS THE CENTERS THE DESIGN OF THE EXPLAINABLE AI AROUND USER QUESTIONS. WE SUGGEST, FROM USER RESEARCH, TO IDENTIFY KEY USER QUESTIONS
utt_0144 utt 760.79 764.91 -X FOR UNDERSTANDING AI, AND ALSO THE REQUIREMENTS TO ANSWER THESE QUESTIONS
utt_0145 utt 765.57 775.58 -X THEN WORK WITH DATA SCIENTISTS TO MAP THESE QUESTIONS TO CANDIDATE XAI TECHNIQUES THAT CAN ANSWER THESE QUESTIONS. STARTING FROM WHAT THESE
utt_0147 utt 775.58 786.51 -X TECHNIQUES PRODUCE, ITERATIVELY DESIGN AND EVALUATE THE EXPLAINABLE AI USER EXPERIENCE AGAINST THE USER REQUIREMENTS. BESIDES
utt_0149 utt 786.51 791.34 -X PROVIDING AN XAI QUESTION BANK TO SUPPORT IDENTIFYING KEY USER QUESTIONS,
utt_0150 utt 791.94 801.05 -X THE KIND OF MAPPING WE DID IN THE BEGINNING, FROM USER QUESTIONS TO XAI METHODS AND ALGORITHMS CAN BE USED TO SUGGEST CANDIDATE SOLUTIONS TO DATA
utt_0152 utt 801.05 811.32 -X SCIENTISTS. ESSENTIALLY THIS PROCESS ALLOWS USER QUESTIONS TO BECOME THE BOUNDARY OBJECTS TO SUPPORT JOINT DISCUSSIONS BETWEEN DESIGNERS AND DATA
utt_0154 utt 811.32 820.70 -X SCIENTISTS. AS FOLLOW-UP WORK FOR THIS PAPER, WE'RE CURRENTLY PRACTICING AND VALIDATING THIS QUESTION DRIVEN DESIGN PROCESS WITH AI TEAMS, AND WE HOPE TO
utt_0156 utt 820.70 831.53 -X SHARE THE RESULTS IN THE NEAR FUTURE. I WANT TO THANK YOU FOR VIEWING THIS PRESENTATION. TO SUMMARIZE OUR two thousand and twenty PAPER BY INTERVIEWING twenty DESIGN
utt_0158 utt 831.94 842.59 -X PRACTITIONERS, SET OUT TO UNDERSTAND REAL WORLD USER NEEDS FOR NINE CATEGORIES OF AI EXPLAINBILITY, WE PRODUCE INSIGHTS TO ADDRESS THEM AND INFORM OPPORTUNITIES
utt_0160 utt 842.59 852.99 -X FOR FUTURE XAI WORK. WE ALSO IDENTIFY KEY CHALLENGES FACED BY DESIGN PRACTITIONERS TO CREATE EXPLAINABLE AI USER EXPERIENCES. TO HELP TACKLING THESE
utt_0162 utt 852.99 858.11 -X CHALLENGES WE SUGGEST AN XAI QUESTION BANK AND A QUESTION DRIVEN DESIGN PROCESS
utt_0163 utt 858.63 866.67 -X I WOULD LIKE TO INVITE YOU TO READ OUR PAPER AND I'LL BE HAPPY TO ANSWER YOUR QUESTION AND HEAR ANY FEEDBACK YOU HAVE. THANK YOU FOR YOUR TIME AND ATTENTION
