utt_0000 utt 0.65 4.78 -X HELLO EVERYONE, I AM AGUS GUNAWAN, WHO WILL TALK IN THIS VIDEO ABOUT OUR RECENT WORK
utt_0001 utt 4.81 9.90 -X “MODERNIZING OLD PHOTOS USING MULTIPLE REFERENCES VIA PHOTOREALISTIC STYLE TRANSFER”.
utt_0002 utt 9.90 14.08 -X THIS IS A WORK WITH SOO YE KIM, HYEONJUN SIM, JAE-HO LEE, AND MUNCHURL KIM
utt_0005 utt 23.60 29.30 -X TO MAKE THESE PHOTOS LOOK LIKE MODERN PHOTOS, PREVIOUS WORK MAINLY FOCUS ON DEGRADATION RESTORATION,
utt_0006 utt 29.30 32.75 -X AND MODERNIZATION BY IMPLICIT ENHANCEMENT.
utt_0007 utt 33.23 43.63 -X HOWEVER, ENHANCING THE COLOR IS INADEQUATE TO ENSURE OLD PHOTOS LOOK MODERN SINCE THE OVERALL LOOK AND STYLE STILL REMAIN SIMILAR TO THOSE OF OLD PHOTOS.
utt_0009 utt 43.63 49.20 -X THIS PROBLEM MOTIVATES US TO MODERNIZE OLD PHOTOS BY CHANGING THEIR STYLES AND ENHANCING THEM.
utt_0010 utt 50.06 59.44 -X TO ACHIEVE THIS GOAL, WE PROPOSE A NOVEL UNIFIED FRAMEWORK THAT LEVERAGES MULTIPLE MODERN PHOTOS AS REFERENCES TO GUIDE THE MODERNIZATION PROCESS.
utt_0012 utt 60.08 65.30 -X AS A RESULT, OUR FRAMEWORK CAN MODERNIZE OLD PHOTOS BETTER THAN THE SOTA OLD PHOTO RESTORATION METHOD
utt_0013 utt 66.13 68.95 -X EVEN WITHOUT USING ANY OLD PHOTOS DURING TRAINING.
utt_0014 utt 69.58 81.17 -X OUR FRAMEWORK IS INSPIRED BY PHOTOREALISTIC STYLE TRANSFER (PST), WHICH HAS SHOWN ITS UNIVERSAL ABILITY TO PERFORM STYLE TRANSFER FOR ANY PHOTOS WITHOUT RETRAINING TO PREDEFINED STYLES.
utt_0016 utt 82.06 88.05 -X HOWEVER, THREE MAIN PROBLEMS ARE HINDERING US FROM USING PST DIRECTLY FOR THE MODERNIZATION TASK.
utt_0017 utt 88.37 100.09 -X FIRST, PREVIOUS PST WORK CAN ONLY USE A SINGLE REFERENCE WHERE IT’S DIFFICULT TO FIND A SINGLE MODERN PHOTO AS A REFERENCE THAT CAN WELL MATCH THE WHOLE SEMANTICS OF THE NATURAL OLD PHOTO.
utt_0020 utt 100.09 106.81 -X SECOND, PREVIOUS PST WORK REQUIRES ADDITIONAL SEMANTIC SEGMENTATION MASKS TO PERFORM LOCAL STYLE TRANSFER,
utt_0021 utt 107.15 112.41 -X WHERE UNRELIABLE SEGMENTATION MASKS CAN PRODUCE UNNATURAL PST RESULTS.
utt_0022 utt 112.85 119.22 -X THIRD, PREVIOUS PST WORK CAN PRODUCE UNNATURAL GLOBAL STYLE TRANSFER AND CANNOT PERFORM AN ENHANCEMENT.
utt_0023 utt 120.18 129.08 -X TO SOLVE THESE ISSUES, IN THIS WORK, WE PROPOSE A MULTIPLE-REFERENCE-BASED OLD PHOTO MODERNIZATION FRAMEWORK THAT CONSISTS OF TWO MAIN PARTS.
utt_0025 utt 129.33 133.82 -X THE FIRST PART IS MROPM-NET WHICH CONSISTS OF TWO SUB-NETWORKS:
utt_0026 utt 133.84 136.81 -X A SINGLE STYLIZATION SUBNET THAT CAN PERFORM
utt_0027 utt 137.40 142.26 -X BOTH GLOBAL AND LOCAL PST WITHOUT ANY SEMANTIC SEGMENTATION MASK.
utt_0028 utt 142.26 149.66 -X AND A MERGING-REFINEMENT SUBNET THAT MERGES MULTIPLE STYLIZATION RESULTS AND FURTHER REFINES THE MERGING RESULTS.
utt_0030 utt 150.10 161.82 -X THE SECOND PART IS A NOVEL TRAINING STRATEGY THAT GENERATES SYNTHETIC TRAINING DATA TO TRAIN OUR NETWORK ENABLING THE NETWORK TO UTILIZE MULTIPLE REFERENCES FOR MODERNIZATION.
utt_0032 utt 161.97 164.66 -X LET’S DIVE INTO THE DETAILS OF OUR NETWORK.
utt_0033 utt 164.72 177.48 -X IN THE FIRST STEP, WE PERFORM STYLE TRANSFER FROM EACH MODERN PHOTO REFERENCE TO OLD PHOTO INPUT RESULTING IN N, TWO IN THIS CASE, DIFFERENT STYLIZATION FEATURES AND CORRELATION MATRICES
utt_0035 utt 177.56 182.14 -X BY UTILIZING A SHARED SINGLE STYLIZATION SUBNET.
utt_0036 utt 182.14 186.27 -X GIVEN FEATURES EXTRACTED FROM THE PRETRAINED BACKBONE PST NETWORK,
utt_0037 utt 186.27 192.54 -X THE KEY IDEA OF OUR SINGLE STYLIZATION SUBNET IS TO PREDICT STYLE CODE TO PERFORM BOTH GLOBAL AND LOCAL PST.
utt_0038 utt 193.75 202.49 -X FIRST, WE COMPUTE THE LOCAL STYLE CODE THROUGH LOCAL FILTER OPERATION AND THE GLOBAL STYLE CODE THROUGH CHANNEL-WISE COMPUTATION.
utt_0040 utt 202.71 210.52 -X THEN, THE LOCAL STYLE CODE IS ALIGNED BY USING NON-LOCAL ATTENTION BETWEEN DEEP FEATURES OF OLD AND MODERN PHOTOS.
utt_0042 utt 211.42 216.52 -X THE LOCAL AND GLOBAL STYLE CODES ARE THEN FUSED THROUGH CHANNEL-WISE CONCATENATION
utt_0043 utt 217.40 227.74 -X THEN, WE PERFORM STYLE TRANSFER BY USING ADAPTIVE INSTANCE NORMALIZATION TO MODULATE THE DECODER’S FEATURES OF THE OLD PHOTO.
utt_0045 utt 227.74 238.36 -X IN THE NEXT STEP, WE USE THE MERGING-REFINEMENT SUBNET TO MERGE MULTIPLE STYLIZED FEATURES AND REFINE THE MERGING RESULTS TO PRODUCE THE MODERNIZED VERSION OF THE OLD PHOTO.
utt_0047 utt 238.62 250.75 -X SPECIFICALLY, WE BOOST OR DAMPEN EACH STYLIZED FEATURE DEPENDING ON THE CORRELATION MATRIX BY USING SPATIAL ATTENTION, WHICH THEN WILL BE SUMMED AND REFINED BY USING U-NET.
utt_0049 utt 250.91 259.55 -X THE NEXT CORE IDEA OF OUR WORK IS A SYNTHETIC DATA GENERATION SCHEME SINCE THERE IS NO GROUND TRUTH FOR OLD PHOTO MODERNIZATION TASKS.
utt_0051 utt 260.70 267.90 -X TO GENERATE THE DATA, WE NEED A DATASET THAT HAS A DENSE SEMANTIC SEGMENTATION MASK FOR EACH IMAGE.
utt_0052 utt 269.18 278.33 -X THE MAIN IDEA OF OUR DATA GENERATION SCHEME IS TO USE TWO DIFFERENT TRANSFORMATIONS WHICH ARE STYLE VARIANT AND INVARIANT TRANSFORMATION, WHERE THE INVARIANT-NESS PROPERTY
utt_0054 utt 278.33 284.19 -X DEPENDS ON WHETHER THE TRANSFORMATION ALTERS THE STYLE CODE OF ANY SEMANTIC REGION.
utt_0055 utt 284.19 287.74 -X GIVEN AN IMAGE THAT WILL BE THE GROUND TRUTH AND SEMANTIC SEGMENTATION MASK.
utt_0056 utt 288.38 293.47 -X WE SPLIT THE LABEL OF THE SEMANTIC SEGMENTATION MASK INTO TWO UNIQUE SETS TO MAKE BINARY MASKS.
utt_0057 utt 294.33 297.95 -X THEN, WE MULTIPLY THE BINARY MASKS AND THE GROUND TRUTH IMAGE.
utt_0058 utt 298.65 304.42 -X TO MAKE THE SYNTHETIC REFERENCE, WE APPLY SIT AND FILL THE UNMASKED REGION WITH A RANDOM IMAGE.
utt_0059 utt 305.28 308.80 -X MEANWHILE, WE APPLY SVT TO MAKE THE SYNTHETIC OLD PHOTO.
utt_0060 utt 309.47 316.70 -X FOR THE BENCHMARK, WE PROPOSE A CULTURAL HERITAGE DATASET CONSISTING OF OLD COLOR PHOTOS PRODUCED IN THE twentyTH CENTURY.
utt_0062 utt 317.53 326.69 -X DIFFERENT FROM PREVIOUS PUBLIC OLD PHOTOS DATASET WHICH MAINLY CONSISTS OF PORTRAIT PHOTOS, OUR DATASET CONTAINS INDOOR AND OUTDOOR SCENES OF CULTURAL HERITAGE.
utt_0064 utt 326.94 333.67 -X SINCE OUR TASK USES REFERENCES, WE FURTHER COLLECT MODERN PHOTOS AS REFERENCES BY CRAWLING IMAGES FROM THE INTERNET.
utt_0066 utt 334.14 337.38 -X FIRST, WE EVALUATE THE METHOD USING SYNTHETIC DATA.
utt_0067 utt 337.38 342.95 -X AS CAN BE SEEN, OUR METHOD ACHIEVES THE BEST PSNR AND LPIPS AND COMPARABLE SSIM SCORE,
utt_0068 utt 342.95 353.22 -X WHICH SHOWS THAT THE METHOD CAN EFFECTIVELY UTILIZE THE REFERENCES TO JOINTLY STYLIZE AND ENHANCE THE SYNTHETICALLY DEGRADED IMAGES, WHILE PRESERVING THE STRUCTURE.
utt_0070 utt 353.22 358.18 -X THE SECOND EVALUATION IS REAL OLD PHOTOS EVALUATION BY USING NO REFERENCE METRICS.
utt_0071 utt 358.18 365.67 -X OUR METHOD OUTPERFORMS OTHER BASELINES SIGNIFICANTLY USING A SINGLE REFERENCE AND FURTHER IMPROVES THE PERFORMANCE BY USING MULTIPLE REFERENCES.
utt_0075 utt 372.90 374.31 -X TO STUDY THE EFFECTIVENESS OF OUR NETWORK,
utt_0078 utt 381.19 385.51 -X ADDING THE FUSION MODULE FURTHER IMPROVES THE PERFORMANCE RESULTING IN SMOOTHER STYLIZATION BOTH LOCALLY AND GLOBALLY.
utt_0080 utt 385.51 390.50 -X NEXT, WE STUDY THE EFFECTIVENESS OF THE MERGING-REFINEMENT SUBNET BOTH ON REAL OLD PHOTOS AND SYNTHETIC DEGRADED PHOTOS.
utt_0082 utt 390.50 393.32 -X BOTH REAL AND SYNTHETIC DATA EVALUATION SHOWS THAT
utt_0084 utt 396.01 398.28 -X TO TRANSFER THEIR STYLES TO THE CORRESPONDING REGION IN THE INPUT.
utt_0088 utt 406.82 408.29 -X WHEN FACED WITH UNRELATED REFERENCES.
utt_0089 utt 408.29 410.89 -6.2972 IN ADDITION, WE ALSO SHOW THE RESULTS FOR OLD PHOTOS IN THE WILD,
