utt_0000 utt 6.06 10.58 -X HELLO EVERYONE, I'M ZHICHENG SUN FROM PEKING UNIVERSITY. TODAY,
utt_0001 utt 10.58 17.23 -X I WOULD LIKE TO SHARE OUR CVPR WORK “REGULARIZING SECOND-ORDER INFLUENCES FOR CONTINUAL LEARNING”.
utt_0002 utt 17.23 28.56 -X FIRST, WE BEGIN WITH A QUICK PREVIEW. IN THIS PAPER, WE ADDRESS THE PROBLEM OF CONTINUAL LEARNING ON LONG TASK SEQUENCES, WHICH FACES THE MAIN CHALLENGE OF CATASTROPHIC FORGETTING.
utt_0004 utt 28.91 41.11 -X TO ADDRESS THIS CHALLENGE, THE PREVALENT METHOD RETAINS KNOWLEDGE BY REHEARSING ON A SMALL REPLAY BUFFER, WHICH REQUIRES CAREFUL SAMPLE SELECTION. HOWEVER, EXISTING SELECTION
utt_0006 utt 41.11 54.57 -X STRATEGIES ARE PRIMARILY DESIGNED FOR SINGLE-ROUND SELECTION, WHICH NEGLECTS THE INTERACTIONS BETWEEN SELECTION STEPS. MOTIVATED BY THIS, WE PROPOSE TO MODEL THE INTERACTIONS WITH INFLUENCE FUNCTIONS
utt_0008 utt 54.71 60.82 -X AND ADDRESS IT WITH A REGULARIZED SECTION STRATEGY. NEXT, LET'S DELVE INTO DETAILS.
utt_0009 utt 61.27 65.27 -X WHILE MACHINE LEARNING MODELS HAVE BEEN WIDELY ADOPTED IN MANY FIELDS,
utt_0010 utt 65.62 77.50 -X THEY HAVE YET TO ACCUMULATE KNOWLEDGE LIKE WE HUMANS DO THROUGHOUT OUR LIVES. CONTINUAL LEARNING HAS HENCE EMERGED TO STUDY THE TRAINING OF MODELS ON LONG TASK SEQUENCES WITH POTENTIAL
utt_0012 utt 77.50 82.59 -X DATA DISTRIBUTION SHIFT. IT IS KNOWN FOR SUFFERING FROM CATASTROPHIC FORGETTING,
utt_0013 utt 82.59 87.35 -X WHERE THE MODEL ABRUPTLY FORGETS PAST KNOWLEDGE AFTER BEING UPDATED ON NEW TASKS.
utt_0014 utt 88.31 93.82 -X TO MITIGATE FORGETTING, THE MOST EFFECTIVE METHOD BY FAR IS BASED ON MEMORY PLAY,
utt_0015 utt 93.94 106.24 -X WHICH BUFFERS A SMALL CORESET OF TRAINING DATA FOR LATER REHEARSAL. DUE TO THE MEMORY CONSTRAINT ON THE REPLAY BUFFER, A CAREFUL SEMI SELECTION STRATEGY IS NEEDED DURING THE PROCESS.
utt_0017 utt 107.16 113.89 -X HOWEVER, EXISTING SECTION STRATEGIES ARE PRIMARILY FOCUSED ON REFINING SINGLE-ROUND PERFORMANCE,
utt_0018 utt 114.11 120.16 -X WHICH NEGLECTS THE INTERACTIONS BETWEEN SELECTION STEPS THROUGH THE DATA FLOW.
utt_0019 utt 120.16 132.72 -X THE MAIN CONTRIBUTION OF OUR WORK IS THAT WE MODEL THE INTERACTIONS BETWEEN CONSECUTIVE SELECTION STEPS IN CONTINUAL LEARNING WITH THE TOOL OF INFLUENCE FUNCTIONS AND IDENTIFY A NEW CLASS OF
utt_0021 utt 132.72 139.78 -X SECOND-ORDER INFLUENCES. THEN A NOVEL REGULARIZER IS PROPOSED TO MITIGATE SECOND-ORDER INFLUENCES,
utt_0022 utt 139.78 145.15 -X WHICH ALSO HAS CLEAR CONNECTIONS TO TWO OTHER POPULAR SELECTION CRITERIA.
utt_0023 utt 145.21 158.69 -X WE START WITH A FORMULATION OF REPLAY-BASED CONTINUAL LEARNING. CONSIDER LEARNING ON A STREAM OF DATA WITH A SMALL CORESET. THE GOAL OF CORESET SELECTION IS TO PRESERVE PERFORMANCE ON
utt_0025 utt 158.69 172.77 -X ALL AVAILABLE DATA BY REPLAYING ON THAT CORSET, WHICH IS FORMULATED A BILEVEL OPTIMIZATION PROBLEM. IN THE FOLLOWING, WE WILL FIRST PRESENT A GREEDY SOLUTION BASED ON INFLUENCE FUNCTIONS,
utt_0027 utt 172.77 179.08 -X THEN SHOWCASE ITS LIMITATIONS AND PROPOSE OUR IMPROVED VERSION.
utt_0028 utt 179.08 187.65 -X TO SOLVE THE BILEVEL OPTIMIZATION PROBLEM, WE LINEARLY APPROXIMATE THE EFFECT OF SELECTING EACH SAMPLE BY PERTURBING ITS WEIGHT.
utt_0030 utt 188.19 194.41 -X THEN A CLASSIC RESULT GIVES THE INFLUENCE OF UPWEIGHTING THAT SAMPLE ON THE OUTER LOSS.
utt_0031 utt 195.01 207.98 -X TO MINIMIZE THE OUTER LOSS, ONE SHOULD GREEDILY SELECT THE SAMPLES WITH THE LOWEST NEGATIVE INFLUENCES, WHICH YIELDS A SOLUTION THAT IS OPTIMAL UNDER LINEAR APPROXIMATIONS.
utt_0033 utt 208.58 222.54 -X WHILE THIS GREEDY SELECTION STRATEGY IS QUALIFIED IN MANY EVALUATIONS, IT OVERLOOKS THE INTERACTION BETWEEN SELECTION STEPS. HERE IS AN INTUITIVE ILLUSTRATION OF THE SECOND-ORDER EFFECT.
utt_0036 utt 226.86 239.44 -X INNER-PRODUCT FORM), THE CORSET WILL GRADUALLY BECOME MORE BIASED AND LESS DIVERSIFIED OVER TIME, LEADING TO INACCURATE INFLUENCE ESTIMATES AND DEGRADATION OF FUTURE SELECTION.
utt_0038 utt 240.39 253.61 -X TO MODEL SUCH AN EFFECT, WE ARE INSPIRED BY THE DERIVATION OF INFLUENCE FUNCTIONS, AND UPWEIGHT TWO SAMPLES FROM CONSECUTIVE SELECTION STEPS. THE UPWEIGHTING OF THE PREVIOUS SAMPLE WOULD
utt_0040 utt 253.67 267.92 -X INFLUENCE SUBSEQUENT SELECTION BY INTERFERING WITH THE INFLUENCE ESTIMATION. SPECIFICALLY, THERE ARE TWO CASES THAT DEPEND ON WHETHER THE TWO SAMPLES ARE JOINTLY OPTIMIZED IN THE NEXT ROUND OR NOT,
utt_0042 utt 268.33 281.26 -X RESULTING IN TWO CASES OF SECOND-ORDER INFLUENCES. SINCE THESE SECOND-ORDER INFLUENCES INTERFERES WITH FUTURE SELECTION, WE NATURALLY WANT TO MINIMIZE THEIR TOTAL INTERFERENCE,
utt_0044 utt 281.74 295.06 -X WHICH CAN BE REPRESENTED AS THEIR WEIGHTED SUM WITH A COEFFICIENT MU. WHILE THE TOTAL INFERENCE IS INTRACTABLE, IT TURNS OUT THAT ITS UPPER BOND CAN BE EFFECTIVELY OPTIMIZED.
utt_0046 utt 295.44 302.00 -X WE THEN DERIVE A NEW REGULARIZER THAT CAN BE COMBINED WITH THE FIRST ORDER INFLUENCE
utt_0047 utt 302.25 308.82 -X TO SERVE AS OUR FINAL SELECTION CRITERIA. TO UNDERSTAND THIS REGULARIZER MORE INTUITIVELY,
utt_0048 utt 309.04 315.25 -X WE INTERPRET IT BY CONNECTING TO TWO WIDELY USED SELECTION CRITERIA. WHEN THE HYPERPARAMETER MU
utt_0049 utt 315.44 321.64 -X IS zero, IT IS EQUIVALENT TO THE RULE OF GRADIENT MATCHING. AND IN THE MORE GENERAL CASE WHERE MU
utt_0050 utt 321.91 328.47 -X IS GREATER THAN zero, WE SIMPLIFY THE FORMULATION BY ASSUMING AN IDENTICAL HESSIAN ACROSS ALL SAMPLES,
utt_0051 utt 328.79 333.08 -X FROM WHICH ONE CAN SEE THAT OUR REGULARIZER PROMOTES SAMPLE DIVERSITY.
utt_0052 utt 333.71 343.96 -X MOREOVER, THE PROPOSED REGULARIZER EXCELS IN INCORPORATING ADDITIONAL HAITIAN-RELATED INFORMATION, WHICH PROVES TO BE USEFUL IN EXPERIMENTS.
utt_0054 utt 344.82 350.46 -3.5577 THE PROPOSED METHOD IS EVALUATED ON THREE CONTINUAL LEARNING BENCHMARKS INCLUDING SPLIT
