utt_0000 utt 0.06 8.88 -X HI EVERYONE, I AM MATAN AND I AM A PHD STUDENT AT THE WEIZMANN INSTITUTE OF SCIENCE I WILL PRESENT OUR WORK NAMED SAL: SIGN AGNOSTIC LEARNING OF SHAPES FROM RAW DATA
utt_0002 utt 9.04 11.86 -X THIS IS A JOINT WORK WITH MY ADVISOR YARON LIPMAN
utt_0003 utt 12.97 20.69 -X RECENTLY NEURAL NETWORKS HAVE DONE A GOOD JOB IN LEARNING threeD SHAPES WHERE ONE POPULAR APPROACH FOR REPRESENTING SHAPES IS BY SURFACES
utt_0005 utt 21.01 28.27 -X IN PARTICULAR, IMPLICIT REPRESENTATIONS WHERE THE IDEA IS THAT A SURFACE IS DEFINED AS A LEVEL SET OF SOME VOLUMETRIC FUNCTION
utt_0007 utt 29.74 34.16 -X ONE OPTION IS TO DEFINE THE IMPLICIT VOLUMETRIC FUNCTION OVER A FIXED GRID
utt_0008 utt 35.12 43.06 -X THE SECOND OPTION IS THAT INSTEAD OF WORKING WITH A DISCRETIZED AMBIENT SPACE, WE CAN USE A NEURAL NETWORK TO MODEL A CONTINUOUS VOLUMETRIC FUNCTION
utt_0011 utt 43.47 51.83 -X THEN THE SHAPE IS DEFINED AS A LEVEL SET OF A NEURAL NETWORK I WILL REFER TO THIS TYPE OF SHAPE MODELING AS IMPLICIT NEURAL REPRESENTATIONS
utt_0013 utt 52.94 66.56 -X SO FOR TRAINING, WHAT PREVIOUS WORKS SUGGESTED IS TO TREAT IT AS A REGRESSION OR CLASSIFICATION PROBLEM THAT IS, TRAINING IS DONE ON SAMPLES OF POINTS IN SPACE, USING SUPERVISION ABOUT EACH POINT INDICATING IF IT'S INSIDE OR OUTSIDE THE SHAPE
utt_0017 utt 67.06 69.64 -X EXTRACTING THESE SAMPLES FOR REGRESSION
utt_0018 utt 69.65 72.44 -X IS POSSIBLE WHEN WE HAVE threeD SUPERVISION
utt_0019 utt 73.23 77.75 -X HOWEVER, WHAT ABOUT RAW threeD DATA SUCH AS POINT CLOUDS?
utt_0020 utt 77.75 85.57 -X TRYING TO PROCEED WITH THE SAME APPROACH INTRODUCES THE QUESTION OF HOW TO DETERMINE FOR THE REGRESSION SAMPLE POINTS IF THEY ARE INSIDE OR OUTSIDE THE SHAPE
utt_0022 utt 85.94 89.30 -X CLEARLY, THIS IS A HARD QUESTION WITH MANY POSSIBLE SOLUTIONS
utt_0023 utt 89.49 95.13 -X HOWEVER, WE SUGGEST A DEEP LEARNING APPROACH THAT OVERCOMES THIS ISSUE AS PART OF THE LEARNING PROCESS
utt_0029 utt 113.59 117.24 -X SO NOW LET'S TRY TO UNDERSTAND OUR METHOD BY CONSIDERING THIS
utt_0030 utt 117.91 125.98 -X twoD TOY EXAMPLE. AS WE ARE WORKING WITH RAW DATA WE CAN ONLY UTILIZE UNSIGNED INFORMATION SUCH AS THE Lzero DISTANCE TO THE POINT CLOUD
utt_0033 utt 126.71 129.72 -X THAT IS ZERO ON THE POINT CLOUD AND ONE EVERYWHERE ELSE
utt_0035 utt 130.23 137.18 -X ANOTHER OPTION IS THE Ltwo DISTANCE TO THE POINT CLOUD WE WILL GENERALLY DENOTE AN UNSIGNED DISTANCE FUNCTION BY H
utt_0038 utt 137.81 140.22 -X CLEARLY, REGRESSING A NEURAL NETWORK F
utt_0039 utt 140.37 143.32 -X TO APPROXIMATE ANY UNSIGNED DISTANCE FUNCTION H
utt_0041 utt 143.61 145.82 -X DOES NOT YIELD AN IMPLICIT SURFACE
utt_0042 utt 146.36 147.93 -X IN MORE SIMPLE WORDS,
utt_0043 utt 147.93 154.36 -X THE NERUAL ZERO LEVEL SET WOULD CONCENTRATE ON THE GIVEN POINT CLOUD AND DOES NOT CONNECT THE DOTS IN SOME PLAUSIBLE WAY
utt_0047 utt 155.57 158.11 -X SO WE SUGGEST THE FOLLOWING SIMPLE IDEA
utt_0048 utt 158.39 160.51 -X GIVEN THE UNSIGNED DISTANCE FUNCTION H
utt_0049 utt 160.85 165.56 -X WE SUGGEST A LOSS FUNCTION THAT ENCOURAGES THE NEURAL NETWORK F TO APPROXIMATE H
utt_0052 utt 166.10 170.55 -X WHILE BEING AGNOSTIC TO THE SIGN THAT IS THE ROLE OF THE FUNCTION TAU
utt_0054 utt 171.48 174.27 -X HERE IS SOME PARTICULAR CHOICE FOR TAU
utt_0055 utt 174.93 180.38 -X NOTE THAT ONE COULD COME UP WITH A DIFFERENT CHOICE FOR TAU AS LONG AS SOME REASONABLE PROPERTIES ARE SATISFIED
utt_0058 utt 181.11 186.35 -X SO LET'S UNDERSTAND WHAT THIS CHOICE OF TAU DOES LET'S CONSIDER A SIMPLE oneD EXAMPLE
utt_0060 utt 187.80 189.37 -X GIVEN A SINGLE POINT Xzero
utt_0061 utt 190.49 192.89 -X HERE IS THE UNSIGNED DISTANCE FUNCTION TO Xzero, H
utt_0062 utt 194.10 196.41 -X AND LET'S ASSUME THAT THE NEURAL NETWORK F
utt_0063 utt 196.54 198.06 -X LOOKS LIKE THE RED CURVE
utt_0064 utt 198.84 207.90 -X SO IN THIS SITUATION, OUR LOSS STRIVES TO MINIMIZE THE WHITE AREA AND F WOULD CONVERGE TO THE SIGNED DISTANCE FUNCTION TO Xzero
utt_0068 utt 208.47 212.19 -X WHICH IS A GOOD THING THAT IS EXACTLY WHAT WE WERE LOOKING FOR
utt_0070 utt 213.05 226.40 -X SO WE SEE OUR SAL LOSS INTRODUCES A NEW DESIRED LOCAL MINIMUM HOWEVER, IT DEPENDS ON HOW THE NETWORK F IS INITIALIZED AS THE UNSIGNED DISTANCE FUNCTION H IS ALSO A POSSIBLE LOCAL MINIMUM
utt_0076 utt 228.54 235.23 -X TO ADDRESS THIS ISSUE, WE DERIVE THE FOLLOWING NETWORK INITIALIZATION WHICH IS CRUCIAL TO OUR ALGORITHM
utt_0079 utt 235.64 240.10 -X HOWEVER, IT IS ONLY A SLIGHT MODIFICATION OF EXISTING INITIALIZATION SCHEMES
utt_0081 utt 240.60 245.06 -X A NEURAL NETWORK INITIALIZED WITH OUR GEOMETRIC INITIALIZATION IS APPROXIMATING
utt_0083 utt 245.34 250.00 -X A SPHERICAL SIGNED DISTANCE GOING BACK TO OUR twoD TOY EXAMPLE
utt_0085 utt 251.04 256.83 -X AFTER TRAINING WITH SAL, WE CAN SEE THAT WE ARE ABLE TO CONVERGE TO PLAUSIBLE NEURAL IMPLICIT REPRESENTATIONS
utt_0087 utt 258.14 261.47 -X SO NOW LET'S GO OVER SOME OF OUR EXPERIMENTS
utt_0088 utt 262.59 268.64 -X FOR LEARNING A SHAPE SPACE FROM THE DYNAMIC FAUST RAW SCANS DATASET WE USE A VARIATIONAL AUTO-ENCODER
utt_0091 utt 269.82 271.86 -X AND HERE WE CAN SEE OUR RESULTS
utt_0092 utt 272.16 276.35 -X TEST SCANS RECONSTRUCTIONS ARE THE RIGHT SHAPE IN EACH GRAY PAIR
utt_0094 utt 276.83 280.51 -X GOLDEN SHAPES ARE GENERATED BY LATENT SPACE INTERPOLATION
utt_0096 utt 284.03 287.49 -X IN FACT, SAL CAN ALSO BE TRAINED ON A SINGLE RAW POINT CLOUD
utt_0097 utt 288.00 294.02 -X WE QUALITATIVELY COMPARE SAL TO NON DEEP LEARNING IMPLICIT SURFACE RECONSTRUCTION METHODS AND HERE ARE THE RESULTS
utt_0100 utt 295.20 300.16 -X SO THANK YOU ALL FOR LISTENING, I'LL BE HAPPY TO DISCUSS OUR WORK SO PLEASE REACH OUT THANKS AGAIN
