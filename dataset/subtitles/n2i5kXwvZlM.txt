utt_0000 utt 0.46 12.30 -X HELLO EVERYONE TODAY I'M GOING TO PRESENT TO YOU OUR WORK ABOUT OPTIMAL CONDITION TRAINING FOR TARGET SOURCE SEPARATION. MY NAME IS EFTHYMIOS TZINIS AND THIS IS A JOINT WORK WITH GORDON WITCHERN, PARIS SMARAGDIS AND JONATHAN LE ROUX.
utt_0003 utt 13.16 24.93 -X SO, THE GENERAL TASK OF AUDIO SEARCH SEPARATION IS EFFECTIVELY WHEN WE HAVE THE CO-OCCURRENCE OF MULTIPLE SOUNDS INSIDE THE MIXTURE AND ONE WANTS TO RECONSTRUCT THE INDEPENDENT SOURCES
utt_0005 utt 24.93 29.84 -X WHEN WE WANT TO RECONSTRUCT ALL OF THE SOURCES INSIDE THE MIXTURE WE USUALLY CALL THIS PROBLEM
utt_0006 utt 29.90 43.68 -X UNCONDITIONAL SEPARATION WHEREAS IF WE HAVE SOME OTHER INFORMATION TO CONDITION THE SYSTEM WE CAN CALL THIS PROBLEM CONDITIONAL OR TARGET SOURCE SEPARATION. SO WE FOCUS ON THIS SETUP WITH THE
utt_0008 utt 44.37 54.28 -X MULTI-CONDITION NETWORKS AS WE SEE HERE. ONE OF THE PRIOR WORKS IN MULTI-CONDITION SEPARATION
utt_0009 utt 54.28 59.84 -X FRAMEWORKS IS CALLED HETEROGENEOUS TARGET SPEECH SEPARATION WHERE WE CAN SEE HERE THAT WE CAN USE
utt_0010 utt 60.14 65.04 -X DIFFERENT OR HETEROGENEOUS CONDITION CONCEPTS IN ORDER TO TARGET LET'S SAY THE FIRST SPEAKER
utt_0011 utt 65.14 78.95 -X INSIDE THE ROOM SO WE CAN HAVE THIS KIND OF TARGET SPEAKER BY QUERYING THE NETWORK TO RECONSTRUCT THE FEMALE OR THE SPEAKER WHO IS THE CLOSEST DISTANCE FROM THE MICROPHONE OR THE SPEAKER WHO SPEAKS
utt_0013 utt 78.95 93.45 -X FRENCH. SO, INSTEAD OF PERFORMING PERMUTATION INVARIANT TRAINING THAT WE USE CONVENTIONALLY IN THE UNCONDITIONAL SEPARATION TRAINING WE GENERATE A MIXTURE FROM A SET OF SOURCES AND WHAT WE DO IS
utt_0015 utt 93.45 106.58 -X THAT FOR THIS KIND OF TARGET WAVEFORM WE SAMPLE A DISCRIMINATIVE CONCEPT WHICH IS ASSOCIATED WITH THIS TARGET WAVEFORM AND WHAT WE DO IS THAT WE BACKPROPAGATE THE ERROR BY USING THIS KIND OF
utt_0017 utt 106.58 113.37 -X SAMPLED DISCRIMINATIVE CONCEPT AND WE UPDATE THE PARAMETERS OF OUR CONDITIONAL SEPARATION NETWORK
utt_0018 utt 113.52 124.02 -X SO ONE OF THE CONTRIBUTIONS OF OUR PAPER IS FIRST OF ALL TO EXPAND THIS HETEROGENEOUS SEPARATION FRAMEWORK FOR UNIVERSAL SOUND SEPARATION SO WE HAVE MORE GENERAL ATTRIBUTES THAN THE SPEAKER
utt_0020 utt 124.02 138.92 -X CHARACTERISTICS AS WE HAD BEFORE SO FOR EXAMPLE WE CAN ASK THE NETWORK TO RECONSTRUCT THE MOST HARMONIC OR THE MOST PERCUSSIVE WAVEFORM OR FOR EXAMPLE THE HIGHER ENERGY ONE OR THE THE SOURCE
utt_0022 utt 138.92 145.40 -X THAT APPEARS SECOND IN ORDER IN TERMS OF TIME AND AND THE FREEST WAY TO DESCRIBE SOUNDS IN GENERAL
utt_0023 utt 145.69 150.46 -X WHICH IS QUERYING USING NATURAL LANGUAGE LIKE I WANT TO SEPARATE THE DOG BARKING
utt_0024 utt 151.48 165.72 -X SO INSTEAD OF HAVING THIS HETEROGENEOUS CONDITION TRAINING WHERE WE HAVE THE SET OF AVAILABLE CONDITION VECTORS AND WE SAMPLE ONE OF THESE CONDITIONS TO BACKPROPAGATE THE ERROR OUR METHOD IS CALLED OPTIMAL CONDITION TRAINING AND WHAT WE DO IS THAT FIRST WE PERFORM AN
utt_0027 utt 165.72 177.44 -X INFERENCE STEP USING ALL THESE AVAILABLE CONDITION VECTORS WE FIND THE MAXIMALLY PERFORMING ONE WITH RESPECT TO RECONSTRUCTING THE TARGET WAVEFORM AND WE UPDATE THE MODEL PARAMETERS USING THAT
utt_0029 utt 178.14 190.59 -X WE ALSO PROVIDE A REFINED WAY OF PERFORMING OPTIMAL CONDITION TRAINING ESPECIALLY FOR CASES WHERE WE FOCUS ON ONE CONDITION VECTOR LET'S SAY WE HAVE THIS KIND OF FIXED CONDITION
utt_0031 utt 190.59 197.21 -X VECTOR AND WHAT WE DO IS THAT WE ALSO TRY TO REFINE THIS THIS INPUT VECTOR AND MAKE
utt_0032 utt 198.30 205.44 -X IT LOOK CLOSER TO THE OPTIMAL OR THE IDEAL ONE FOR THIS CONDITIONAL SEPARATION TASK
utt_0033 utt 206.78 217.57 -X YOU CAN SEE MORE UH IN THE IN THE PAPER IF YOU'RE INTERESTED BUT EFFECTIVELY WE USE A CONDITIONAL SUDO RM -RF AS OUR SEPARATION NETWORK WHERE WE GRADUALLY MODULATE THE INPUT SIGNAL USING
utt_0035 utt 217.66 226.03 -X SEVERAL FILM LAYERS SO, WE'RE GONNA SEE WHY THIS IS REALLY IMPORTANT USING THE DIFFERENT CONDITIONS
utt_0036 utt 226.03 235.73 -X WE HAVE CONDUCTED OUR EXPERIMENTS USING FSDfiftyK AND WE HAVE HERE DIFFERENT PARTITIONS USING SOURCES IN
utt_0037 utt 235.73 247.10 -X THE MIXTURE WHICH ARE DRAWN FROM RANDOM CLASSES OF THE OUT OF THE two hundred CLASSES AVAILABLE OR FOR EXAMPLE WE FORCE THESE CLASSES TO BE DRAWN FROM DIFFERENT SUPER CLASSES OR THE HARDEST CASE WHICH
utt_0039 utt 247.10 257.18 -X EFFECTIVELY IS WHEN WE FORCE AN INTRA-SUPERCLASS SEPARATION FRAMEWORK WHICH EFFECTIVELY WE SAY WE
utt_0040 utt 258.65 269.83 -X SAY WHETHER TO RECONSTRUCT THE ACOUSTIC GUITAR FROM THE FROM A MIXTURE OF ACOUSTIC GUITAR AND ELECTRIC GUITAR FOR EXAMPLE SO WE SEE HERE THAT THERE ARE SOME CONDITIONS SUCH AS HARMONICITY
utt_0042 utt 269.83 282.18 -X AND SOURCE ORDER WHICH PERFORM PRETTY GOOD FOR ALL THESE PARTITIONS BUT THERE ARE OTHER SINGLE CONDITION MODELS LET'S SAY THIS ONE CONDITIONED ON ENERGY WHICH FAILED MISERABLY MAINLY BECAUSE NEAR
utt_0044 utt 282.72 296.19 -X zero DB IT'S REALLY HARD TO TO SAY WHICH SOURCE IS THE HIGHEST ENERGY ONE FOR THE MOST GENERAL WAY OF DESCRIBING SOUNDS WHICH IS TEXT-BASED DESCRIPTION WE SEE THAT ALL THE RANDOM CLASSES IT PERFORMS
utt_0046 utt 296.19 310.40 -X REALLY WELL FOR THE HARDEST CASE OF EXTRACTING LET'S SAY THE ELECTRICAL GUITAR FROM THE FROM THE ACOUSTIC GUITAR WE SEE THAT THE TEXT-BASED DESCRIPTION IS NOT THAT WELL MAINLY BECAUSE THOSE
utt_0048 utt 310.40 324.45 -X EMBEDDINGS ARE REALLY CLOSE TO EACH OTHER UH AND THE FINAL THING THAT WE WANT TO SEE IS WHY WOULD YOU GET THIS PERFORMANCE BOOST IS THE OCT ORACLE WHICH IS A A MODEL WHICH IS TRAINED WITH TRAINED
utt_0050 utt 324.45 335.99 -X AND EVALUATED WITH THE BEST OR THE MAXIMALLY PERFORMING CONDITION YIELDS A HIGHER UPPER BOUND IN CONDITIONAL SEPARATION EVEN COMPARED AGAINST THE ORACLE SYMBOL OF ALL THESE SINGLE CONDITION
utt_0052 utt 335.99 346.42 -X MODELS SO THAT MEANS THIS EXTRA INFORMATION WHICH COMES IN FOR FREE FROM OUR METADATA FROM DIFFERENT CONDITIONS HELPS US I UNDERSTAND HOW TO PERFORM THIS CONDITIONAL SEPARATION BETTER
utt_0054 utt 347.36 358.01 -X FOCUSING ONLY ON TEXT-BASED SEPARATION WE SEE THE PERFORMANCE OF ORACLE OPTIMAL CONDITION TRAINING AND THE ORACLE UNCONDITIONAL PERMUTATION INVARIANT TRAINING COMPARED TO THE
utt_0056 utt 358.15 368.39 -X PREVIOUS STATE-OF-THE-ART TEXT-BASED SEPARATION WE SEE WHAT WE CAN DO WITH OUR MODEL USING THE HETEROGENEOUS CONDITION TRAINING SETUP WHICH IS LIKE A LITTLE BIT BETTER THAN THAT BUT WE
utt_0059 utt 371.43 374.66 -6.9131 FOCUSING ON THESE UPDATES USING OUR OPTIMAL THE OPTIMAL CONDITION TRAINING AND WE CAN ALSO DO
