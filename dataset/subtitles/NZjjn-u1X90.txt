utt_0000 utt 0.91 6.06 -X HI, I'M ANELISE, AND I'M HERE TO TELL YOU ABOUT A NEW TOOLBOX FOR CAPTURING ATTENTION DATA.
utt_0002 utt 6.99 11.92 -X HUMAN ATTENTION PROVIDES INSIGHT INTO WHAT ASPECTS OF AN IMAGE ARE MORE RELEVANT OR ENGAGING
utt_0003 utt 12.56 22.61 -X FOR EXAMPLE--IF I HAD A LOT OF DATA ABOUT WHERE ON AN IMAGE PEOPLE TENDED TO LOOK, I COULD TRAIN AN AUTOMATIC CROPPING SYSTEM THAT PRESERVED THE MOST RELEVANT PARTS OF THE IMAGE.
utt_0005 utt 22.83 29.26 -X IF I KNEW WHAT ASPECTS OF A GRAPHIC DESIGN WERE MOST IMPORTANT, I COULD DO DESIGN RETARGETING.
utt_0006 utt 29.26 36.24 -X IF I COULD MEASURE ATTENTION AT MULTIPLE SCALES, THAT COULD GIVE ME INSIGHT INTO HOW PEOPLE EXPLORE COMPLEX IMAGES LIKE DATA VISUALIZATIONS.
utt_0008 utt 37.42 44.24 -X AND IF I KNEW WHERE PEOPLE TENDED TO LOOK AT DIFFERENT VIEWING DURATIONS, THAT COULD HELP ME PRIORITIZE CONTENT TO DISPLAY OR RENDER.
utt_0010 utt 45.33 48.40 -X DESPITE BEING SO VALUABLE, HUMAN ATTENTION HAS A DRAWBACK.
utt_0011 utt 49.45 52.18 -X IT HAS HISTORICALLY BEEN DIFFICULT TO COLLECT AT SCALE.
utt_0012 utt 53.07 55.67 -X SAY I WANTED TO GATHER ATTENTION ON THIS IMAGE.
utt_0013 utt 55.89 61.46 -X THE TYPICAL WAY TO DO IT IS TO BRING SOMEONE INTO THE LAB AND THEN TRACK THEIR EYES USING DEDICATED HARDWARE.
utt_0015 utt 62.22 71.89 -X I WOULD MEASURE THE POINTS ON THE IMAGE THEY LOOKED AT, AND THEN BY COMBINING THESE GAZE POINTS OVER MANY STUDY PARTICIPANTS AND BLURRING THEM, I COULD CREATE AN ATTENTION HEATMAP.
utt_0017 utt 72.49 77.86 -X IN THIS HEATMAP, HIGHER VALUES CORRESPOND TO REGIONS OF THE IMAGE PEOPLE LOOK AT MORE FREQUENTLY OR FOR LONGER
utt_0019 utt 78.73 82.45 -X HOWEVER, THIS METHOD OF COLLECTING ATTENTION DOES NOT SCALE.
utt_0020 utt 82.86 90.58 -X BRINGING SUBJECTS INTO LAB IS TIME-INTENSIVE, AND, DURING A GLOBAL PANDEMIC, PROBABLY NOT POSSIBLE.
utt_0022 utt 90.58 99.57 -X SO IN THIS WORK, WE PRESENT TURKEYES, A TOOLBOX OF four INTERFACES FOR GATHERING ATTENTION DATA USING JUST A LAPTOP OR MOBILE PHONE, WITHOUT EYE TRACKING.
utt_0024 utt 99.66 104.82 -X INSTEAD, WE MAKE USE OF INTERACTION METHODOLOGIES THAT ARE CORRELATED WITH ATTENTION.
utt_0025 utt 104.88 111.06 -X WITH ZOOMMAPS, PARTICIPANTS USE THE PINCH-ZOOM GESTURE ON A MOBILE PHONE TO EXPLORE AN IMAGE AT MULTIPLE SCALES.
utt_0027 utt 112.43 117.43 -X WITH CODECHARTS, PARTICIPANTS SELF-REPORT WHERE THEY GAZED USING A GRID OF THREE-LETTER CODES.
utt_0029 utt 118.70 123.25 -X IMPORTANNOTS LETS PARTICIPANTS PAINT OVER REGIONS OF A DESIGN THAT THEY CONSIDER IMPORTANT.
utt_0030 utt 123.92 130.39 -X AND FINALLY, BUBBLEVIEW REQUIRES PARTICIPANTS TO CLICK TO UNBLUR SMALL BUBBLE REGIONS OF A BLURRED IMAGE.
utt_0032 utt 130.42 136.92 -X WE DO A DEEP DIVE ON THESE INTERFACES TO DEVELOP GUIDELINES FOR HOW AND WHEN TO USE THEM TO CAPTURE ATTENTION.
utt_0034 utt 137.01 138.64 -X LET'S INTRODUCE THE INTERFACES.
utt_0035 utt 140.27 145.91 -X ZOOM-BASED INTERFACES USE A VIEWER’S ZOOM PATTERNS AS A SIGNAL OF INTEREST IN REGIONS THAT ARE VIEWED OR ZOOMED.
utt_0037 utt 146.64 156.76 -X PREVIOUS WORK HAS EXPLORED THE CORRELATION BETWEEN EYE MOVEMENTS AND THE ZOOMABLE VIEWPORT OF A MOBILE PHONE, AND HAS PROPOSED USING VIEWPORT DATA TO MEASURE INTEREST IN AN INTERFACE
utt_0039 utt 157.01 160.95 -X OR EVEN TO CREATE AN ATTENTION HEATMAP OVER A WEBPAGE.
utt_0040 utt 160.95 166.80 -X HOWEVER, AS FAR AS WE KNOW, ZOOMMAPS IS THE FIRST GENERAL INTERFACE FOR CREATING ATTENTION HEATMAPS ON IMAGES USING ZOOM.
utt_0042 utt 168.30 170.80 -X HERE'S A DEMONSTRATION OF HOW THE INTERFACE WORKS.
utt_0043 utt 170.86 177.97 -X PARTICIPANTS ARE SENT TO A LANDING PAGE THAT CONTAINS A QR CODE AND A URL THAT THEY CAN USE TO OPEN AN IMAGE GALLERY IN THEIR MOBILE BROWSER.
utt_0045 utt 178.07 184.85 -X THEY CAN THEN EXPLORE THE IMAGES IN A MOBILE IMAGE GALLERY USING THE FAMILIAR PAN AND ZOOM GESTURE.
utt_0047 utt 187.38 191.45 -X WE CAN THEN CONVERT THE ZOOMED VIEWPORT DATA INTO AN ATTENTION HEATMAP AS FOLLOWS:
utt_0048 utt 191.95 199.45 -X FOR EACH PIXEL, WE TAKE THE AVERAGE ZOOM LEVEL OVER THE VIEWING DURATION, WHERE THE ZOOM LEVEL IS DEFINED AS THE FULL IMAGE AREA OVER THE ZOOMED AREA.
utt_0050 utt 200.11 207.19 -X SO A PIXEL THAT IS VIEWED UP-CLOSE LIKE PIXEL B WILL HAVE A HIGHER HEATMAP VALUE THAN ONE THAT IS ONLY VIEWED WHILE ZOOMED-OUT, LIKE PIXEL A.
utt_0052 utt 207.19 211.67 -X THUS, WE GET A MEASURE OF WHERE THE VIEWER SPENT THE MOST TIME LOOKING IN THE MOST DETAIL.
utt_0053 utt 214.55 219.35 -X WE CAN THEN COMBINE THE VIEWPORT DATA GATHERED FROM MULTIPLE INDIVIDUALS TO OBTAIN A ZOOM MAP.
utt_0055 utt 221.84 230.61 -X MOVING ON, SELF-REPORTING INTERFACES LIKE CODECHARTS SHOW AN IMAGE FOR A LIMITED TIME AND ASK THE VIEWER TO REPORT WHERE THEY WERE LOOKING USING A VISUAL GUIDE.
utt_0057 utt 230.74 235.09 -X OUR IMPLEMENTATION OF CODECHARTS IS BASED ON AN INTERFACE PRESENTED BY RUDOY ET. AL.
utt_0058 utt 235.09 239.00 -X HERE IS A TASK FLOW DIAGRAM FOR THE CODECHARTS INTERFACE.
utt_0059 utt 239.28 243.67 -X FIRST AN IMAGE APPEARS FOR A SPECIFIC DURATION, USUALLY A FEW SECONDS.
utt_0060 utt 244.47 249.72 -X ONCE THE IMAGE DISAPPEARS, IT IS REPLACED BY A CODECHART, A JITTERED GRID OF THREE-CHARACTER CODES.
utt_0062 utt 251.67 258.84 -X ONCE THE CODECHART DISAPPEARS, THE SUBJECT WRITES DOWN THE CODE THEY REMEMBER SEEING WHEN THE IMAGE DISAPPEARED, WHICH LOCATES WHERE THEY WERE LOOKING AT THAT TIME.
utt_0064 utt 260.40 262.84 -X THIS VIDEO SHOWS THE INTERFACE IN REAL TIME.
utt_0065 utt 263.54 266.49 -X THE CODECHART GOES BY REALLY FAST, AND THAT'S ON PURPOSE.
utt_0066 utt 266.49 270.78 -X WE WANT TO GIVE PEOPLE ENOUGH TIME TO READ A CODE BUT NOT ENOUGH TIME THAT THEIR EYES WANDER.
utt_0068 utt 272.12 284.82 -X AFTER WE'VE COLLECTED GAZE POINTS FROM MULTIPLE PARTICIPANTS, WE AGAIN CONVERT THAT DATA INTO AN ATTENTION HEATMAP BY BLURRING THE GAZE POINTS WITH A GAUSSIAN, SIMILARLY TO HOW EYE FIXATIONS ARE PROCESSED.
utt_0071 utt 287.06 292.28 -X NEXT, NNOTATION INTERFACES ALLOW USERS TO EXPLICITLY SEGMENT REGIONS THAT THEY THINK ARE IMPORTANT.
utt_0073 utt 292.76 297.51 -X ONE EXAMPLE IS THE LABELME INTERFACE, USED FOR COLLECTING SEMANTIC SEGMENTATION LABELS
utt_0074 utt 298.45 304.95 -X IMPORTANNOTS REFERS TO THE INTERFACE OF O'DONOVAN ET AL USED FOR COLLECTING IMPORTANCE ANNOTATIONS ON GRAPHIC DESIGNS.
utt_0076 utt 306.10 311.77 -X PARTICIPANTS ARE PRESENTED WITH A SERIES OF IMAGES ONE AT A TIME AND ASKED TO ANNOTATE THE MOST IMPORTANT REGIONS.
utt_0078 utt 311.77 314.17 -X WE DON'T DEFINE WHAT SHOULD BE CONSIDERED IMPORTANT
utt_0079 utt 315.73 327.07 -X EVEN THOUGH THERE IS CONSIDERABLE VARIABILITY IN THE ANNOTATIONS OBTAINED FROM INDIVIDUAL SUBJECTS, BY AVERAGING OVER MANY STUDY PARTICIPANTS, WE CAN OBTAIN A SURPRISINGLY CONSISTENT MEASURE OF IMPORTANCE.
utt_0082 utt 328.79 333.47 -X AND THIS TECHNIQUE ALSO WORKS FOR NATURAL IMAGES, ALTHOUGH THE SEGMENTATIONS MIGHT NOT BE AS CLEAN.
utt_0084 utt 335.19 344.38 -X FINALLY, CURSOR-BASED INTERFACES LEVERAGE CORRELATIONS BETWEEN MOUSE MOVEMENTS AND EYE MOVEMENTS, OFTEN BY INCENTIVIZING THE VIEWER TO CLICK/HOVER TO EXPLORE POINTS OF INTEREST.
utt_0086 utt 345.27 354.55 -X FOR EXAMPLE THE MOVING WINDOW METHODOLOGY, LIKE BUBBLEVIEW OR SALICON, REVEALS PORTIONS OF AN OTHERWISE-OBSCURED IMAGE DEPENDING ON WHERE USERS PLACE THEIR CURSOR.
utt_0088 utt 355.54 364.70 -X PARTICIPANTS ARE ASKED TO EXPLORE ONE IMAGE AT A TIME USING THEIR MOUSE CURSOR TO CLICK AND DEBLUR SMALL REGIONS OF AN IMAGE.
utt_0090 utt 364.79 372.95 -X HEATMAP GENERATION IS THEN VERY SIMILAR TO CODE CHARTS WE BLUR THE COLLECTED MOUSE POINTS TO CREATE A HEATMAP.
utt_0092 utt 373.01 379.80 -X NOW I'VE JUST THROWN A LOT OF INFORMATION AT YOU, SO MIGHT BE WONDERING: WHICH TOOL IS BEST? WHICH ONE SHOULD I BE USING?
utt_0094 utt 380.44 383.83 -X TO TRY TO ANSWER THAT QUESTION, WE RAN EXPERIMENTS ON MECHANICAL TURK.
utt_0095 utt 383.99 394.20 -X WE GATHERED DATA ON A VARIETY OF STIMULI TYPES: NATURAL IMAGES, INFOGRAPHICS, VISUALIZATIONS--TO DETERMINE WHAT INSIGHTS ABOUT ATTENTION WE COULD GATHER FROM EACH TOOL.
utt_0097 utt 394.20 397.18 -X HERE'S WHAT WE FOUND.
utt_0098 utt 397.18 401.60 -X ONE THING WE REALIZED IS THAT NOT ALL INTERFACES WORK EQUALLY WELL WITH EACH TYPE OF STIMULI.
utt_0099 utt 402.14 411.36 -X FOR EXAMPLE, ZOOMMAPS WORKS UNIQUELY WELL WITH LARGE, MULTISCALE STIMULI, BECAUSE OF THE REALLY NATURAL SUPPORT FOR PANNING AND ZOOMING.
utt_0101 utt 411.36 416.70 -X WHILE YOU CAN USE IMPORTANNOTS WITH NATURAL IMAGES, IT'S REALLY BEST SUITED FOR GRAPHIC DESIGNS.
utt_0103 utt 417.21 425.18 -X ON THE OTHER HAND, ALL OF THE IMAGES WE STUDIED SUPPORT GRAPHIC DESIGNS -- AS YOU CAN SEE IN THE RESUME ON THE RIGHT.
utt_0105 utt 425.27 433.37 -X AND FINALLY, ALTHOUGH WE DID NOT TRY THIS IN OUR EXPERIMENTS, CODECHARTS CAN BE USED FOR VIDEOS BY REPLACING THE IMAGE WITH A SHORT VIDEO CLIP.
utt_0107 utt 435.77 438.91 -X COST IS ANOTHER IMPORTANT FACTOR THAT WE CONSIDERED.
utt_0108 utt 438.91 442.65 -X TTHE COST OF DATA COLLECTION WITH EACH INTERFACE REALLY CAME DOWN TO TWO THINGS.
utt_0109 utt 443.00 448.64 -X HOW MUCH DATA DOES IT COLLECT PER PARTICIPANTS? AND HOW MUCH WORK IS IT TO USE THE INTERFACE?
utt_0110 utt 449.69 452.99 -X OUT OF THE INTERFACES WE STUDIED, BUBBLEVIEW WAS THE CHEAPEST.
utt_0111 utt 453.02 459.96 -X ONE REASON IS THAT BUBBLEVIEW GIVES A RELATIVELY HIGH AMOUNT OF DATA PER VIEWER, AS YOU CAN SEE IN THE IMAGE ON THE RIGHT.
utt_0113 utt 459.96 466.53 -X WE GET ABOUT fifteen CLICKS PER VIEWER, WHICH MEANS WE NEED ABOUT fifteen VIEWERS PER IMAGE TO GET CONSISTENT DATA.
utt_0115 utt 467.74 469.57 -X THE NEXT CHEAPEST IS ZOOMMAPS.
utt_0116 utt 469.63 478.43 -X WE NEED SLIGHTLY MORE PEOPLE, AROUND twenty, TO GET CONSISTENT ZOOMMAPS DATA FOR AN IMAGE.
utt_0117 utt 479.32 483.93 -X CODECHARTS IS SIGNIFICANTLY MORE EXPENSIVE THAN EITHER OF THE TWO PREVIOUS INTERFACES,
utt_0118 utt 483.93 485.21 -X SO WHY IS THAT??
utt_0119 utt 485.98 492.86 -X WHEREAS WITH BUBBLEVIEW WE GET MANY ATTENTION POINTS PER PARTICIPANT, FOR CODECHARTS WE ONLY GET ONE.
utt_0121 utt 492.89 497.85 -X THAT MEANS THAT WE NEED A LOT MORE CODECHARTS PARTICIPANTS TO GET A CONSISTENT HEATMAP--AROUND
utt_0122 utt 499.90 500.41 -X fifty.
utt_0123 utt 500.41 502.94 -X FINALLY, IMPORTANNOTS IS THE MOST EXPENSIVE INTERFACE.
utt_0124 utt 503.58 512.29 -X ALTHOUGH IT REQUIRES FEWER PEOPLE THAN CODECHARTS, THEY NEED TO DO THE ADDITIONAL WORK OF ACTUALLY SEGMENTING THE ELEMENTS IN THE IMAGE, WHICH DRIVES UP THE PRICE.
utt_0126 utt 514.81 519.33 -X WE ALSO COMPUTED SIMILARITY TO EYE MOVEMENTS BY COLLECTING DATA FOR ALL OF OUR INTERFACES
utt_0127 utt 519.71 525.02 -X ON thirty-five IMAGES FROM THE CATtwo thousand EYE TRACKING DATASET.
utt_0128 utt 525.05 531.77 -X WE COMPUTED THE PEARSON'S CORRELATION COEFFICIENT BETWEEN THE HEATMAPS GENERATED BY OUR INTERFACES AND THE GROUND TRUTH ATTENTION HEATMAPS.
utt_0130 utt 532.86 538.59 -X WE SEE THAT CODECHARTS BEST APPROXIMATES EYE MOVEMENTS, ACCOUNTING FOR eighty-eight% OF HUMAN CONSISTENCY
utt_0131 utt 539.29 546.11 -X IT'S FOLLOWED BY BUBBLEVIEW AND ZOOMMAPS IMPORTANNOTS, UNSURPRISINGLY, IS LEAST SIMILAR TO EYE MOVEMENTS.
utt_0133 utt 547.48 551.90 -X THIS FIGURE SHOWS SOME QUALITATIVE SIMILARITIES AND DIFFERENCES BETWEEN THE INTERFACES.
utt_0134 utt 552.67 555.52 -X CODECHARTS BEST APPROXIMATES HUMAN EYE MOVEMENTS.
utt_0135 utt 555.71 561.15 -X IT SHOWS THINGS LIKE EXPLORATION PATTERNS, OR SINGLE FIXATIONS RESULTING FROM EXPLORATION,
utt_0136 utt 561.15 562.94 -X WHICH IS CHARACTERISTIC OF EYE MOVEMENTS.
utt_0137 utt 564.16 569.54 -X EYE MOVEMENTS, CODECHARTS AND BUBBLEVIEW FALL ON CERTAIN REGIONS ONLY, LIKE FACES, HANDS,
utt_0138 utt 569.54 574.21 -X AND POINTS OF CONTENT, BASICALLY SALIENT POINTS IN THE IMAGE.
utt_0139 utt 574.21 582.56 -X ZOOMMAPS OCCASIONALLY OVER-FOCUSES ON DISTANT BACKGROUND ELEMENTS (LIKE THE TENT IN THE SECOND ROW) AND IN GENERAL IS A COARSER MEASURE OF ATTENTION.
utt_0141 utt 584.54 587.39 -X IMPORTANNOTS SEGMENTS SEMANTICALLY IMPORTANT ELEMENTS.
utt_0142 utt 587.39 593.01 -X IT OFTEN FOCUSES ON A SINGLE CENTRAL OBJECT, AND IT IN GENERAL HIGHLIGHTS LARGE PORTIONS OF THE IMAGE
utt_0144 utt 595.10 599.84 -X SO WHAT MIGHT ACCOUNT FOR DIFFERENCES IN HOW WELL THESE INTERFACES APPROXIMATE EYE MOVEMENTS?
utt_0145 utt 600.51 610.82 -X OUR INTERFACES CAN BE ORGANIZED ON AN “INTENTIONALITY” SCALE BASED ON THE DEGREE TO WHICH THEY MEASURE SALIENCY (WHICH IS MORE SPONTANEOUS) OR IMPORTANCE (WHICH IS MORE INTENTIONAL).
utt_0147 utt 610.82 619.20 -X SALIENCY IS A BOTTOM-UP MEASURE OF WHAT PARTS OF AN IMAGE ARE MOST ATTENTION-GRABBING, WHEREAS IMPORTANCE IS A TOP-DOWN MEASURE OF WHICH ELEMENTS IN AN IMAGE ARE MORE RELEVANT.
utt_0149 utt 619.87 624.26 -X INTUITIVELY, YOU CAN THINK OF SALIENCY AS LIKE WHEN YOU'RE SCROLLING THROUGH INSTAGRAM,
utt_0150 utt 624.26 635.01 -X AND IMAGES ARE POPPING OUT AT YOU, WHEREAS YOU CAN THINK OF IMPORTANCE AS MORE LIKE WHEN YOU'RE ANNOTATING YOUR TEXTBOOK, AND YOU'RE ACTUALLY REFLECTING ON THE CONTENT AND THEN ANNOTATING IT SOMEHOW.
utt_0153 utt 635.01 641.79 -X WE THINK THAT AN INTERFACE’S PLACE ON THE SALIENCY-IMPORTANCE CONTINUUM IS A FUNCTION OF ITS “INTENTIONALITY”
utt_0155 utt 643.52 649.09 -X EYE MOVEMENTS CAPTURE SALIENCY, BECAUSE IT REQUIRES NO EXPLICIT USER INTERACTION.
utt_0156 utt 649.21 656.13 -X CODECHARTS IS NEXT BECAUSE IT DOESN'T DISTORT THE IMAGE OR REQUIRE USER INTERACTION WHILE VIEWING THE IMAGE.
utt_0158 utt 656.22 667.17 -X BUBBLEVIEW STILL CAPTURES IMAGE LOCATIONS THAT DRAW PEOPLE'S ATTENTION, BUT IT'S MORE INTENTIONAL BC IT SLOWS DOWN VIEWING TIME, DISTORTS THE IMAGE, AND REQUIRES PEOPLE TO CLICK TO EXPLORE AREAS OF INTEREST.
utt_0161 utt 668.73 677.80 -X ZOOMMAPS REQUIRES THE USER TO INTERACT WITH THE IMAGE TO GATHER ATTENTION DATA, BUT IT DOES USE A FAMILIAR SECOND-NATURE MECHANISM.
utt_0163 utt 677.80 686.92 -X FINALLY, IMPORTANNOTS MEASURES IMPORTANCE INSTEAD OF SALIENCY PARTICIPANTS ARE GIVEN AMPLE TIME TO CONSIDER THE IMAGE BEFORE ANNOTATING ANYTHING AND ARE ASKED TO SELECT REGIONS,
utt_0165 utt 686.92 691.81 -X NOT GAZE POINTS, THAT THEY FIND IMPORTANT FOR UNDERSTANDING.
utt_0166 utt 691.81 699.49 -X THESE EXAMPLES DEMONSTRATE SOME OF THE SIMILARITIES AND DIFFERENCES BETWEEN SALIENCY AND IMPORTANCE BY COMPARING THE INTERFACES ON EITHER END OF THE SPECTRUM.
utt_0168 utt 699.94 704.77 -X IN THE TOP ROW, YOU SEE AN EXAMPLE WHERE THE TWO INTERFACES PRODUCE DIFFERENT OUTCOMES.
utt_0169 utt 705.12 710.44 -X CODECHARTS IS MORE SIMILAR TO EYE MOVEMENTS, SHOWING CENTER BIAS AND EXPLORATION PATTERNS.
utt_0170 utt 713.60 721.03 -X ON THE BOTTOM ROW, THE CENTRAL OBJECTS ARE MORE SALIENT, SO YOU SEE AN ALLIGNMENT BETWEEN THE TWO INTERFACES.
utt_0172 utt 721.03 726.60 -X THAT BRINGS US BACK TO THE QUESTION: WHICH TOOL SHOULD I USE?
utt_0173 utt 731.78 735.11 -X ZOOMMAPS IS GREAT FOR MULTISCALE CONTENT.
utt_0174 utt 735.11 736.84 -X IT HAS A NATURAL INTERACTION MECHANISM.
utt_0175 utt 736.84 740.58 -X HOWEVER, IT IS A COARSER APPROXIMATION OF ATTENTION.
utt_0176 utt 740.58 745.61 -X THIS MAKES IT GOOD FOR SOMETHING LIKE VISUALIZATION DEBUGGING.
utt_0177 utt 745.61 757.96 -X WHILE CODECHARTS CAN BE EXPENSIVE, IT'S A GOOD APPROXIMATION OF EYE TRACKING, ESPECIALLY AT PRECISE VIEWING DURATIONS, WHICH MAKES IT IDEAL FOR AN APPLICATION LIKE GRADUAL RENDERING.
utt_0179 utt 757.96 767.08 -X IMPORTANNOTS PRODUCES CLEAN SEGMENTATIONS, AND IT'S REALLY WELL-SUITED FOR GRAPHIC DESIGN ELEMENTS, WHICH MAKES IT IDEAL FOR GRAPHIC DESIGN RETARGETING.
utt_0181 utt 767.08 779.75 -X AND WHILE BUBBLEVIEW CAN DISTORT THE STIMULI AND THE VIEWING EXPERIENCE, IT DOES APPROXIMATE EYE TRACKING WELL AND IT'S CHEAP, WHICH MAKES IT GREAT FOR SOMETHING LIKE TRAINING A MACHINE LEARNING MODEL TO DO AUTOMATIC CROPPING.
utt_0184 utt 780.55 786.57 -X IF YOU HAVE YOUR OWN IDEAS FOR PROJECTS THAT REQUIRE ATTENTION DATA, YOU CAN USE OUR TOOLBOX TO HELP YOU COLLECT IT!
utt_0186 utt 786.57 790.12 -X THE INTERFACE CODE, DATA, AND DEMOS ARE AVAILABLE ON OUR WEBSITE.
utt_0187 utt 790.12 793.25 -5.1575 THANK YOU FOR YOUR ATTENTION.
