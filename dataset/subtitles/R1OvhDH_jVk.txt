utt_0000 utt 0.11 11.89 -X HELLO, EVERYONE. I'M JUNYOUNG BYUN FROM KAIST, PRESENTING OUR PAPER TITLED 'INTRODUCING COMPETITION TO BOOST THE TRANSFERABILITY OF TARGETED ADVERSARIAL EXAMPLES THROUGH CLEAN FEATURE MIXUPâ€™. DEEP NEURAL NETWORKS ARE KNOWN TO BE
utt_0003 utt 11.89 15.51 -X SUSCEPTIBLE TO ADVERSARIAL EXAMPLES, WHICH TEND TO BE TRANSFERABLE BETWEEN MODELS.
utt_0004 utt 15.51 26.77 -X HOWEVER, TARGETED ATTACKS STILL HAVE LOWER ATTACK SUCCESS RATES DUE TO SIGNIFICANT VARIATIONS IN DECISION BOUNDARIES. IN THIS WORK, OUR GOAL IS TO FURTHER ENHANCE THE TRANSFERABILITY BY LEVERAGING A WIDER RANGE OF ADVERSARIAL FEATURES.
utt_0007 utt 27.25 31.99 -X TO PROMOTE THIS, WE INTRODUCE COMPETITION INTO THE PROCESS WITH TWO TYPES OF COMPETITOR NOISES,
utt_0008 utt 31.99 35.54 -X FORCING ADVERSARIAL PERTURBATIONS TO DIVERSIFY ATTACK STRATEGIES.
utt_0009 utt 35.54 50.04 -X INSTEAD OF OPTIMIZING THE COMPETITOR NOISES SEPARATELY, WE EFFICIENTLY SIMULATE INTERFERENCE FROM THEM IN FEATURE SPACE BY RANDOMLY MIXING UP STORED CLEAN FEATURES AT EACH INFERENCE AND NAMED THIS METHOD CLEAN FEATURE MIXUP, OR CFM. WE DESIGNED CFM MODULES TO FACILITATE THIS.
utt_0012 utt 51.09 54.71 -X WE INSERT THESE MODULES INTO A SOURCE MODEL TO IMPLEMENT CFM.
utt_0013 utt 55.28 59.99 -X OUR EXPERIMENTAL RESULTS SHOW THAT CFM OUTPERFORMS THE BASELINES WITH A CLEAR MARGIN.
utt_0016 utt 68.21 80.03 -X ONE MAJOR HURDLE IN TRANSFER-BASED ADVERSARIAL ATTACKS IS THAT ADVERSARIAL EXAMPLES CAN OVERFIT THE SOURCE MODEL, LEADING TO REDUCED EFFECTIVENESS WHEN APPLIED TO THE TARGET MODELS.
utt_0018 utt 81.30 90.36 -X THEREFORE, VARIOUS INPUT DIVERSIFICATION TECHNIQUES HAVE BEEN PROPOSED TO PREVENT THIS OVERFITTING AND IMPROVE THE TRANSFERABILITY OF ADVERSARIAL
utt_0020 utt 90.36 96.70 -X EXAMPLES. SOME PRIOR WORKS ARE ILLUSTRATED HERE.
utt_0021 utt 96.70 110.33 -X HOWEVER, IN EXISTING ATTACK METHODS, AN ADVERSARIAL EXAMPLE MAY BE OPTIMIZED TO INTENSELY DISTRACT A LIMITED NUMBER OF FEATURES IDENTIFIED IN THE EARLY STAGES. BUT THE TARGET MODEL MIGHT
utt_0023 utt 110.33 115.90 -X BE INSENSITIVE TO SUCH FEATURE DISTRACTIONS, LEADING TO THE FAILURE OF TRANSFER-BASED ATTACKS.
utt_0024 utt 117.40 125.36 -X THEREFORE, WE CONJECTURE THAT PERTURBING MORE DIVERSE FEATURES CAN LEAD TO IMPROVE THE TRANSFERABILITY OF ADVERSARIAL EXAMPLES
utt_0026 utt 127.93 133.57 -X TO PROMOTE THIS, WE PROPOSE INTRODUCING COMPETITION INTO THEIR OPTIMIZATION PROCESS.
utt_0027 utt 133.85 145.23 -X WE INTRODUCE TWO TYPES OF COMPETITOR NOISES: ADVERSARIAL PERTURBATIONS TOWARDS DIFFERENT TARGET CLASSES AND FRIENDLY PERTURBATIONS TOWARDS THE CORRECT CLASS. EACH OF THESE COMPETITOR NOISES
utt_0029 utt 145.23 158.56 -X CAN BE VIEWED AS A CONTENDER TRYING TO STEER THE CLASSIFICATION TOWARDS ITS OWN TARGET CLASS. SO NOW, EVEN IF AN ADVERSARIAL EXAMPLE DECEIVES THE SOURCE MODEL INTO EXTRACTING CERTAIN FEATURES THAT
utt_0031 utt 158.56 164.32 -X LEAD TO THE TARGET CLASS, THIS DISTURBANCE MAY BE SUPPRESSED BY INTERFERENCE FROM THE COMPETITORS.
utt_0032 utt 164.86 170.60 -X CONSEQUENTLY, ADVERSARIAL PERTURBATIONS SHOULD TAKE MORE DIVERSE ATTACK STRATEGIES,
utt_0033 utt 170.60 174.88 -X LEVERAGING A WIDER RANGE OF FEATURES TO OVERCOME THE INTERFERENCE,
utt_0034 utt 175.33 179.11 -X WHICH ENHANCES THEIR TRANSFERABILITY TO DIFFERENT MODELS.
utt_0035 utt 182.82 188.71 -X CONSIDERING THE COMPUTATIONAL COMPLEXITY, INSTEAD OF OPTIMIZING THE COMPETITOR NOISES SEPARATELY,
utt_0036 utt 188.71 198.79 -X WE EFFICIENTLY SIMULATE INTERFERENCE FROM THE TWO TYPES OF COMPETITORS IN FEATURE SPACE BY RANDOMLY MIXING UP STORED CLEAN FEATURES IN THE MODEL INFERENCE AND NAMED
utt_0038 utt 198.79 210.52 -X THIS METHOD CLEAN FEATURE MIXUP (CFM). THIS BEHAVIOR IS IMPLEMENTED THROUGH OUR SPECIALLY DESIGNED CFM MODULES. FIRST, CFM MODULE STORES THE
utt_0040 utt 210.52 221.39 -X CLEAN FEATURES OF IMAGES IN A BATCH DURING FORWARD PASS. THEN, IT SHUFFLES THE STORED CLEAN FEATURES IMAGE-WISE AND MIXES THE FEATURES ACCORDING TO RANDOM CHANNEL-WISE MIXING RATIOS.
utt_0042 utt 224.58 230.48 -X WITH THESE CFM MODULES, WE FIRST INSERT THEM INTO A PRE-TRAINED SOURCE MODEL.
utt_0043 utt 230.48 240.84 -X AFTER THAT, WE LET THEM INITIALLY STORE THE CLEAN FEATURES AND SUBSEQUENTLY MIX THE CLEAN FEATURES RANDOMLY DURING THE GENERATION PROCESS OF ADVERSARIAL EXAMPLES.
utt_0045 utt 245.45 248.88 -X CFM IS READILY APPLICABLE TO EXISTING ADVERSARIAL ATTACKS.
utt_0046 utt 249.10 259.37 -X IF WE WANT TO ADD CFM TO AN EXISTING ATTACK, IT'S VERY EASY TO DO SO BY SIMPLY ADDING THE CORRESPONDING CODES TO LINES one AND two OF THIS ALGORITHM.
utt_0048 utt 259.85 265.36 -X OUR EXPERIMENTS WERE CONDUCTED USING THE IMAGENET-COMPATIBLE AND CIFARminus ten DATASETS.
utt_0049 utt 265.68 269.97 -X WE FOLLOWED THE RECENT ODI METHOD FOR MOST OF OUR EXPERIMENTAL SETUPS,
utt_0050 utt 270.00 279.41 -X AND COMPARED CFM WITH SEVERAL COMBINATIONS OF BASELINE METHODS AS SHOWN IN THIS SLIDE.
utt_0051 utt 279.66 285.46 -X ON THE IMAGENET-COMPATIBLE DATASET, CFM OUTPERFORMS THE BASELINES BY A SIGNIFICANT MARGIN,
utt_0052 utt 285.61 299.38 -X PROVIDING CLEAR EVIDENCE OF ITS EFFECTIVENESS. WE ALSO CARRIED OUT ATTACK EXPERIMENTS ON FIVE TRANSFORMER-BASED MODELS AND CFM DEMONSTRATED REMARKABLE ATTACK SUCCESS RATES.
utt_0054 utt 302.00 314.84 -X ON THE CIFARminus ten DATASET, CFM SIGNIFICANTLY AMPLIFIES ATTACK SUCCESS RATES, SHOWCASING ITS SUPERIOR PERFORMANCE EVEN AGAINST ROBUST ENSEMBLE MODELS. NOTE THAT CFM
utt_0056 utt 314.84 321.24 -X ADDS ONLY A MARGINAL AMOUNT OF TIME FOR GENERATING ADVERSARIAL EXAMPLES, INDICATING ITS EFFICIENCY.
utt_0057 utt 322.64 328.79 -X THIS TABLE PRESENTS AN ABLATION STUDY ON THE INNER FUNCTIONS OF THE CFM MODULES. OVERALL,
utt_0058 utt 328.79 338.49 -X IT DEMONSTRATES THAT EACH FUNCTION SIGNIFICANTLY CONTRIBUTES TO ENHANCING THE TRANSFERABILITY OF ADVERSARIAL EXAMPLES.
utt_0060 utt 338.49 349.56 -X IN CONCLUSION, OUR NOVEL TECHNIQUE, CFM, BOOSTS THE TRANSFERABILITY OF TARGETED ADVERSARIAL EXAMPLES, SHOWCASING ITS SUPERIOR PERFORMANCE AND EFFICIENCY ON BOTH THE
utt_0062 utt 349.56 356.75 -3.8173 IMAGENET-COMPATIBLE AND CIFARminus ten DATASETS. THANK YOU FOR WATCHING. I APPRECIATE YOUR
