utt_0000 utt 0.26 6.13 -X HELLO EVERYONE, MY NAME IS OLIVER HAHN AND I'M GOING TO PRESENT OUR PAPER SEMANTIC SELF-ADAPTATION:
utt_0002 utt 6.22 8.85 -X ENHANCING GENERALIZATION WITH A SINGLE SAMPLE.
utt_0003 utt 9.07 13.01 -X THIS IS A JOINT WORK WITH SHERWIN BAHMANI, EDUARD ZAMFIR,
utt_0004 utt 13.01 16.08 -X NIKITA ARASLANOV, DANIEL CREMERS, AND STEFAN ROTH.
utt_0005 utt 16.78 24.15 -X IN THIS WORK, WE CONSIDER SEMANTIC SEGMENTATION THE TASK OF PREDICTING A DISTINCT SEMANTIC CLASS FOR EVERY PIXEL IN AN IMAGE.
utt_0008 utt 24.46 30.52 -X THIS DENSE PREDICTION TASK IS PARTICULARLY CHALLENGING IN THE SETTING OF OUT-OF-DOMAIN GENERALIZATION.
utt_0009 utt 30.52 38.13 -X HEREBY THE TRAINING IS TYPICALLY PERFORMED ON AN INEXPENSIVE SYNTHETIC DATASET, WHEREAS REAL-WORLD DATA IS OBSERVED AT INFERENCE TIME.
utt_0011 utt 38.13 41.75 -X PREVIOUS STUDIES RELY ON THE ASSUMPTION OF A NON-ADAPTIVE MODEL,
utt_0012 utt 41.75 47.00 -X MEANING ONCE THE TRAINING PROCESS IS COMPLETE MODEL PARAMETERS REMAIN FIXED AT TEST TIME.
utt_0014 utt 47.00 50.65 -X WE CHALLENGE THIS PREMISE INSPIRED BY THE IDEA OF ADAPTIVE GRASPING,
utt_0015 utt 50.65 55.90 -X WHERE A ROBOTIC GRIPPER USES AN OBSERVATION INPUT TO ADAPT ITS TECHNIQUE TO THE OBJECT BEING GRASPED.
utt_0016 utt 56.24 66.33 -X SIMILARLY, OUR SELF-ADAPTIVE APPROACH FOR SEMANTIC SEGMENTATION ADJUSTS THE INFERENCE PROCESS TO EACH INPUT SAMPLE OF THE TEST DATA WITHOUT SHARING ANY KNOWLEDGE ACROSS THE TEST SAMPLES.
utt_0018 utt 66.87 75.71 -X WE CHOSE WILDDASH AS OUR VALIDATION SET, WHICH BEARS CLOSER VISUAL RESEMBLANCE TO THE TARGET DOMAINS WHILE STILL HAVING A DISTINCT DISTRIBUTION FROM THE TEST DOMAINS.
utt_0020 utt 76.02 79.45 -X WE TRAIN A MODEL ON THE SYNTHETIC DATASETS GTA AND SYNTHIA
utt_0021 utt 79.54 85.72 -X AND EVALUATE ON FOUR DIFFERENT TEST DOMAINS NAMELY CITYSCAPES, BDD, IDD, AND MAPILLARY.
utt_0022 utt 86.14 93.89 -X BASED ON THE ORIGINAL TEST IMAGE WE CREATE A MINI-BATCH OF AUGMENTED SAMPLES BY USING MULTIPLE SCALES, HORIZONTAL FLIPPING, AND GRAYSCALING.
utt_0024 utt 93.89 98.17 -X WE PASS THIS AUGMENTED MINI-BATCH THROUGH OUR MODEL PRE-TRAINED ONLY ON SYNTHETIC DATA
utt_0025 utt 98.71 100.99 -X USING INVERSE SIMILARITY TRANSFORMS.
utt_0026 utt 100.99 104.48 -X WE PROJECT THE OBTAINED SEMANTIC MAPS BACK TO THE ORIGINAL IMAGE PLANE
utt_0027 utt 104.79 108.90 -X THIS LEADS TO HAVING MULTIPLE PREDICTIONS FOR EACH PIXEL.
utt_0028 utt 108.90 112.88 -X NEXT, WE COMPUTE THE MEAN OF THE SOFTMAX PROBABILITIES ALONG THE BATCH DIMENSION
utt_0029 utt 113.05 115.46 -X AND INTRODUCE A CLASS-DEPENDENT THRESHOLD.
utt_0030 utt 115.77 121.35 -X THIS ALLOWS US TO EXTRACT THE DOMINANT CLASS FOR EACH RESPECTIVE PIXEL IGNORING LOW-CONFIDENCE PREDICTIONS.
utt_0032 utt 121.82 126.50 -X THE GENERATED PSEUDO LABEL IS USED TO FINE-TUNE THE MODEL FOR A FIXED NUMBER OF ITERATIONS.
utt_0034 utt 126.85 128.96 -X AFTER THIS SELF-ADAPTATION PROCESS,
utt_0035 utt 128.96 132.93 -X WE COMPUTE A FINAL PREDICTION FOR THE TEST SAMPLE USING THE UPDATED MODEL.
utt_0036 utt 132.93 135.52 -X TO REMAIN WITHIN THE DOMAIN GENERALIZATION PARADIGM,
utt_0037 utt 135.52 138.82 -X WE DISCARD THE MODEL CHANGES AFTER EVERY TEST SAMPLE.
utt_0038 utt 139.58 142.08 -X WHEN ANALYZING BATCH NORMALIZATION LAYERS,
utt_0039 utt 142.08 146.92 -X RUNNING STATISTICS FROM THE SYNTHETIC SOURCE DATA DIFFERS SUBSTANTIALLY FROM TEST DOMAIN STATISTICS.
utt_0040 utt 147.14 154.92 -X TO MITIGATE THE COVARIATE SHIFT PROBLEM WE INTRODUCE SELF-ADAPTIVE NORMALIZATION WHICH IMPROVES THE TEST TIME BEHAVIOR OF BATCH NORMALIZATION LAYERS.
utt_0043 utt 155.49 163.24 -X WE COMPUTE A WEIGHTED SUM OF MEAN AND VARIANCE ACCUMULATED DURING TRAINING FROM THE SOURCE DOMAIN AND STATISTICS EXTRACTED FROM THE SINGLE TEST SAMPLE.
utt_0046 utt 163.59 178.22 -X OUR SELF-ADAPTIVE NORMALIZATION OR SAN FOR SHORT DOES NOT ONLY LEAD TO BETTER OUT-OF-DOMAIN ACCURACY IN TERMS OF MEAN IOU BUT ALSO TO BETTER MODEL CALIBRATION MEASURED BY THE EXPECTED CALIBRATION ERROR ABBREVIATED AS ECE REPORTED IN THIS TABLE.
utt_0050 utt 178.92 184.07 -X DESPITE HAVING A STRICTER EVALUATION PRACTICE AND A SIMPLER MODEL ARCHITECTURE THAN MOST PUBLISHED WORK,
utt_0052 utt 184.07 188.43 -X SELF-ADAPTATION OVERWHELMINGLY EXCEEDS THE SEGMENTATION ACCURACY OF VERY RECENT WORK.
utt_0053 utt 188.74 193.04 -X ON AVERAGE SELF-ADAPTATION SURPASSES ITS RESNETminus fifty BASELINE BY twelve point seven IOU
utt_0054 utt 194.28 197.90 -X AND IMPROVES THE PREVIOUS BEST METHOD BY one point zero three PERCENT IOU ON AVERAGE.
utt_0055 utt 199.46 203.18 -X MODIFYING THE INFERENCE PROCESS INHERENTLY CHANGES ITS RUNTIME.
utt_0056 utt 203.18 207.21 -X WE PROFILE THE RUNTIME OF THE BASELINE MODEL AND OUR PROPOSED SELF-ADAPTATION.
utt_0057 utt 207.31 213.10 -X WE FURTHER COMPARE OUR APPROACH TO THE TEST TIME AUGMENTATION SHORT TTA AS WELL AS MODEL ENSEMBLES.
utt_0058 utt 213.55 220.30 -X FOR A FAIR COMPARISON, TTA AND MODEL ASSEMBLES USE OUR PROPOSED SELF-ADAPTIVE NORMALIZATION SCHEME.
utt_0059 utt 220.30 223.38 -X FURTHERMORE, WE ALSO INVESTIGATE ENSEMBLES IN COMBINATION WITH TTA.
utt_0060 utt 223.69 229.55 -X WE OBSERVE AN EXPECTED INCREASE IN RUNTIME USING OUR SELF-ADAPTATION DUE TO THE ADDITIONAL MODEL UPDATES,
utt_0061 utt 229.55 235.92 -X BUT SELF-ADAPTATION NATURALLY OFFERS A TRADE-OFF BETWEEN INCREASED RUNTIME AND ACHIEVABLE ACCURACY.
utt_0062 utt 235.92 242.29 -X NEVERTHELESS, OUR SELF-ADAPTATION PROVES TO BE NOT ONLY MORE EFFICIENT THAN THE MODEL ENSEMBLES BUT EVEN MORE ACCURATE.
utt_0063 utt 242.77 249.56 -X IN THE FOLLOWING, WE VISUALIZE THE PERFORMANCE GAIN OF SELF-ADAPTATION ON A VIDEO SEQUENCE TAKEN FROM THE CITYSCAPES DATASET.
utt_0065 utt 249.78 255.54 -X WE OBSERVE A CLEARLY PERCEIVABLE IMPROVEMENT OVER THE BASELINE, ESPECIALLY IN TERMS OF IMAGE BOUNDARY CONSISTENCY.
utt_0066 utt 255.95 261.69 -X OUR APPROACH EXHIBITS MORE HOMOGENEOUS SEMANTIC MASKS WITH VISIBLY FEWER ARTIFACTS THAN THE BASELINE.
utt_0068 utt 262.00 268.02 -X TO SUMMARIZE, WE FIND THAT SELF-ADAPTATION IMPROVES OUT-OF-DOMAIN GENERALIZATION ACCURACY OF STATE-OF-THE-ART METHODS.
utt_0069 utt 268.05 273.81 -X WE FURTHER OBTAIN AN EFFICIENT ACCURACY AND UNCERTAINTY BOOST BY USING OUR SELF-ADAPTIVE NORMALIZATION.
utt_0071 utt 273.81 278.94 -X WE SHOW A ROBUST AND STRONG ACCURACY IMPROVEMENT AGNOSTIC TO THE TRAINING PIPELINE AND MODEL ARCHITECTURE.
utt_0072 utt 278.94 283.61 -X WHILE WE STILL SUFFER FROM INCREASED RUNTIME WE OFFER A COST-EFFECTIVE RUNTIME ACCURACY TRADE-OFF.
utt_0073 utt 283.70 292.63 -X WE HOPE THAT THESE ENCOURAGING RESULTS WILL MOTIVATE OUR RESEARCH COMMUNITY TO STUDY SELF-ADAPTIVE TECHNIQUES IN OTHER APPLICATION DOMAINS AND INCREASE THE EFFICIENCY TOWARDS REAL-TIME.
utt_0075 utt 293.14 299.93 -2.6452 THE CODE AND PRE-TRAINED MODELS ARE PUBLICLY AVAILABLE AND WE HOPE YOU FIND THEM USEFUL IN YOUR WORK. THANK YOU FOR WATCHING!
