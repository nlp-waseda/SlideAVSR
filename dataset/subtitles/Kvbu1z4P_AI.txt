utt_0000 utt 0.27 3.54 -X HI EVERYONE, I'M JENNIFER, A PHD STUDENT FROM CALTECH.
utt_0001 utt 3.95 7.60 -X I’LL BE TALKING ABOUT OUR WORK ON SELF-SUPERVISED KEYPOINT DISCOVERY,
utt_0002 utt 7.72 13.30 -X WHICH ENABLES THE STUDY OF SINGLE OR MULTI-AGENT BEHAVIOR IN VIDEOS WITH QUASI-STATIONARY BACKGROUNDS.
utt_0003 utt 14.32 18.03 -X BEHAVIORAL VIDEO ANALYSIS IS CRUCIAL IN MANY FIELDS,
utt_0004 utt 18.03 21.11 -X SUCH AS FOR STUDYING MODEL ORGANISMS IN SCIENTIFIC EXPERIMENTS.
utt_0005 utt 21.52 28.34 -X THESE BEHAVIORS CAN THEN BE USED TO UNDERSTAND NEURAL ACTIVITY OR THE EFFECTS OF DIFFERENT DRUGS FOR PHARMACOLOGICAL EVALUATIONS.
utt_0007 utt 29.46 35.57 -X FOR USER APPLICATIONS, BEHAVIORAL VIDEOS CAN CAPTURE HUMAN BEHAVIOR FOR HUMAN-ROBOT INTERACTIONS,
utt_0008 utt 35.70 39.03 -X AS WELL AS FOR HEALTHCARE MONITORING.
utt_0009 utt 39.03 45.88 -X IN ALL CASES, VIDEO DATA IS RECORDED AT A LARGE-SCALE, AND THE GOAL IS TO AUTOMATICALLY QUANTIFY BEHAVIOR FROM VIDEO.
utt_0011 utt 47.60 52.12 -X EXISTING METHODS FOR BEHAVIORAL VIDEO ANALYSIS OFTEN PERFORM POSE ESTIMATION,
utt_0012 utt 52.21 54.17 -X THEN MAP POSES TO BEHAVIOR.
utt_0013 utt 54.61 59.96 -X POSE IS A GOOD INTERMEDIATE STEP BECAUSE IT IS LOW DIMENSIONAL, WHICH ENABLES INTERPRETABILITY,
utt_0014 utt 60.02 61.72 -X AS WELL AS MODULARITY.
utt_0015 utt 61.72 67.03 -X THERE ARE MANY WORKS USING POSE FOR BEHAVIOR, GENERALLY WITH SUPERVISED KEYPOINTS.
utt_0016 utt 68.28 74.78 -X ANOTHER RELEVANT DIRECTION IS KEYPOINT DISCOVERY, WHERE CONDITIONAL IMAGE GENERATION IS AN INSPIRATION FOR OUR WORK.
utt_0018 utt 75.16 82.87 -X THIS WORK EXTRACTS APPEARANCE FEATURES FROM IMAGE X AND KEYPOINTS FROM IMAGE X’ IN ORDER TO LEARN INFORMATIVE KEYPOINTS TO CONDITIONALLY GENERATE X’.
utt_0020 utt 82.87 88.03 -X THERE ARE MANY OTHER WORKS IN THIS AREA STUDYING THE RELATIONSHIP BETWEEN POSE AND IMAGE APPEARANCE.
utt_0021 utt 89.27 93.39 -X TO THE BEST OF OUR KNOWLEDGE, THERE HAVE NOT BEEN STUDIES AT THE INTERSECTION OF THESE AREAS.
utt_0022 utt 93.78 97.75 -X BEHAVIORAL VIDEO ANALYSIS GENERALLY USE SUPERVISED POSE ESTIMATION,
utt_0023 utt 97.75 101.85 -X REQUIRING POTENTIALLY TIME-CONSUMING OR EXPENSIVE KEYPOINT ANNOTATIONS.
utt_0024 utt 102.74 110.08 -X ON THE OTHER HAND, MANY WORKS IN KEYPOINT DISCOVERY REQUIRE AGENT BOUNDING BOXES, WHICH REQUIRES A TRAINED DETECTOR ON REAL-WORLD VIDEOS.
utt_0026 utt 110.49 113.05 -X THIS IS ESPECIALLY DIFFICULT FOR MULTIPLE AGENTS.
utt_0027 utt 114.71 125.26 -X OUR WORK ON BEHAVIORAL KEYPOINT DISCOVERY IS AT THE INTERSECTION, WHERE OUR GOAL IS TO DIRECTLY DISCOVER KEYPOINTS FROM BEHAVIORAL VIDEOS WITHOUT MANUAL KEYPOINT OR BOUNDING BOX ANNOTATIONS.
utt_0030 utt 125.26 130.30 -X B-KIND IS ABLE TO DO THIS IN A VARIETY OF SETTINGS, INCLUDING DIVERSE ORGANISMS AND MULTIPLE AGENTS.
utt_0032 utt 131.39 136.99 -X OUR METHOD IS BASED ON THE IDEA OF DISCOVERING LOCATIONS WITH MAXIMUM MOVEMENT INFORMATION.
utt_0033 utt 136.99 149.12 -X LET’S LOOK AT A SIMPLE EXAMPLE: GIVEN A RIGID OBJECT SUCH AS A PENCIL HERE, IF WE HAD two KEYPOINTS, WE CAN RECONSTRUCT THE NEW LOCATION AND ORIENTATION USING THESE KEYPOINTS ALONE.
utt_0035 utt 149.12 160.03 -X WE CAN TRY TO DO THE SAME WITH SCISSORS, HOWEVER, SINCE THE SCISSORS HAVE one JOINT, THESE KEYPOINTS ARE NOT ENOUGH TO DISAMBIGUATE WHETHER IT IS CLOSED OR OPEN.
utt_0037 utt 160.32 163.58 -X WE NEED AN ADDITIONAL KEYPOINT TO FULLY RECONSTRUCT THE MOVEMENT.
utt_0038 utt 163.58 168.03 -X THERE ARE ALSO MANY OTHER OPTIONS ON WHERE TO PLACE THESE three KEYPOINTS.
utt_0039 utt 168.16 176.08 -X ONCE WE MOVE ON TO REAL-WORLD VIDEOS, THERE ARE EVEN MORE DEGREES OF FREEDOM, MAKING IT DIFFICULT TO DEFINE AND ANNOTATE KEYPOINTS.
utt_0041 utt 176.08 178.66 -X B-KIND LEARNS THESE KEYPOINTS USING SELF-SUPERVISION.
utt_0042 utt 178.94 185.57 -X WE START WITH two FRAMES IN A BEHAVIORAL VIDEO AT TIME T AND T+K, AND WE RUN OUR KEYPOINT DISCOVERY MODEL ON BOTH FRAMES.
utt_0044 utt 185.57 190.88 -X THE LOCATION FOR EACH KEYPOINT IS COMPUTED USING A SPATIAL SOFTMAX FOR A HEATMAP CHANNEL.
utt_0045 utt 191.07 195.49 -X THEN THE KEYPOINTS GO THROUGH A DECODER TO RECONSTRUCT MOVEMENT ACROSS FRAMES T AND T+K.
utt_0046 utt 196.42 204.58 -X SINCE THE KEYPOINTS ARE SPARSE AND MAY NOT ENCODE ALL VISUAL DETAILS, WE ALSO ENCODE APPEARANCE FEATURES OF THE IMAGE AT TIME T.
utt_0048 utt 204.58 210.34 -X THE INPUT TO THE MOVEMENT RECONSTRUCTION IS APPEARANCE FEATURES AND KEYPOINTS AT TIME T, AND ONLY KEYPOINTS AT TIME T+K.
utt_0050 utt 211.84 218.28 -X THE MODEL IS SELF-SUPERVISED USING SPATIOTEMPORAL DIFFERENCE RECONSTRUCTION TO THE REAL AGENT MOVEMENT BETWEEN T AND T+K.
utt_0052 utt 220.39 230.38 -X RESULTS SHOW THAT OUR MODEL IS GENERAL, AND WORKS ACROSS A VARIETY OF AGENT TYPES, FROM MICE, TO FLIES, TO HUMANS, JELLYFISH, AS WELL AS TREES.
utt_0054 utt 231.81 241.29 -X COMPARING OUR SPATIOTEMPORAL DIFFERENCE RECONSTRUCTION TO IMAGE RECONSTRUCTION, WE SEE THAT THE KEYPOINTS DISCOVERED BY OUR MODEL QUALITATIVE TRACKS PARTS MORE CONSISTENTLY.
utt_0056 utt 241.67 249.10 -X ADDITIONALLY, FOR DOWNSTREAM BEHAVIOR CLASSIFICATION, OUR KEYPOINTS ARE QUANTITATIVELY COMPARABLE TO SUPERVISED KEYPOINTS TRAINED ON THIS DATASET.
utt_0058 utt 250.15 257.51 -X SINCE B-KIND DOESN’T REQUIRE ANY HUMAN ANNOTATIONS, IT CAN BE APPLIED DIRECTLY TO ANY BEHAVIORAL VIDEO WITH QUASI-STATIONARY BACKGROUND.
utt_0060 utt 257.89 260.62 -X THIS CAN QUICKLY PROVIDE KEYPOINTS FOR PROTOTYPING.
utt_0061 utt 261.13 266.19 -X BUT THERE IS LITTLE CONTROL OVER THE KEYPOINTS AND OUR KEYPOINTS CAN BE SENSITIVE TO OCCLUSION.
utt_0063 utt 267.46 271.12 -X ANOTHER POTENTIAL USE CASE IS B-KIND IN A SEMI-SUPERVISED SETTING.
utt_0064 utt 271.21 276.04 -X THE SELF-SUPERVISED PART FROM B-KIND CAN IMPROVE DATA EFFICIENCY OF THE SUPERVISED ANNOTATIONS.
utt_0065 utt 276.97 288.49 -X HOWEVER, THE BEST LOCATIONS TO TRACK FOR A GIVEN VIDEO SETUP MAY NOT BE CLEAR AHEAD OF TIME THEREFORE, B-KIND CAN ALSO BE USED A HUMAN-IN-THE-LOOP SETUP TO GIVE FEEDBACK ON WHICH KEYPOINTS
utt_0067 utt 288.49 292.65 -X ARE EASILY DISCOVERABLE, THEN USERS CAN ADJUST DISCOVERED KEYPOINTS AND RETRAIN.
utt_0070 utt 297.23 299.15 -4.4888 WE LOOK FORWARD TO SEEING WHAT YOU CAN DO WITH IT!
