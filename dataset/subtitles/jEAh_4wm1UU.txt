utt_0000 utt 0.14 12.02 -X HELLO EVERYONE, I AM GLAD TO INTRODUCE OUR PAPER TITLED “PIXEL DIFFERENCE NETWORKS FOR EFFICIENT EDGE DETECTION”. WE ARE FROM THE UNIVERSITY OF OULU,
utt_0002 utt 12.72 19.06 -X NATIONAL UNIVERSITY OF DEFENSE TECHNOLOGY, HARBIN INSTITUTE OF TECHNOLOGY, AND XIDIAN UNIVERSITY.
utt_0003 utt 19.06 26.42 -X MY NAME IS ZHUO SU, I AM A threeRD YEAR PHD STUDENT IN UNIVERSITY OF OULU, AND MY SUPERVISOR IS LI LIU.
utt_0004 utt 26.42 33.11 -X I AM GOING TO BEGIN WITH A BRIEF INTRODUCTION OF WHAT EDGE DETECTION LOOKS LIKE. FOR EXAMPLE,
utt_0007 utt 46.51 52.43 -X IS TO IDENTIFY IMAGE BRIGHTNESS CHANGES SUCH AS DISCONTINUITIES IN INTENSITY,
utt_0008 utt 52.49 65.71 -X COLOR, TEXTURE, DEPTH, SURFACE ORIENTATION, VARIATIONS IN ILLUMINATION, ETC. IT HAS BEEN A LONGSTANDING RESEARCH TOPIC IN THE COMPUTER VISION COMMUNITY, AND BENEFITS VARIOUS, FROM LOW TO HIGH
utt_0010 utt 65.71 73.33 -X LEVEL VISION APPLICATIONS. LIKE SALIENT OBJECT DETECTION, SUPER RESOLUTION, IMAGE SEGMENTATION,
utt_0011 utt 73.33 86.71 -X OBJECT DETECTION, TRACKING AND MOTION ANALYSIS, MEDICAL IMAGING, threeD RECONSTRUCTION, AND TO SOME MODERN APPLICATIONS LIKE AUTONOMOUS DRIVING. THE APPROACHES ON EDGE DETECTION EVOLVE FROM
utt_0013 utt 86.71 93.62 -X THE TRADITIONAL DETECTORS IN EARLY YEARS, LIKE SOBEL, PREWITT, LAPLACIAN OF GAUSSIAN, AND CANNY,
utt_0014 utt 93.62 99.51 -X TO LATER LEARNING BASED METHODS, LIKE STRUCTURED FORESTS, AND FINALLY, IN THE DEEP LEARNING ERA,
utt_0015 utt 99.51 112.92 -X TO THE CNN BASED METHODS. TRADITIONAL AND LEARNING BASED METHODS USUALLY ENCODE IMAGE GRADIENTS AS THE BASIC FEATURES. FOR EXAMPLE, IN THE WELL-DESIGNED TRADITIONAL OPERATORS,
utt_0017 utt 112.92 118.90 -X THE DIFFERENCES BETWEEN NEIGHBORING PIXELS ARE CALCULATED TO CAPTURE THE GRADIENT INFORMATION,
utt_0018 utt 118.90 124.44 -X WHICH IS SHOWN HIGHLY EFFECTIVE FOR EDGE DETECTION. THERE IS AN EXPLICIT ENCODING OF
utt_0019 utt 125.04 137.33 -X GRADIENT INFORMATION IN THEIR KERNELS. HOWEVER, THESE METHODS SUFFER FROM THEIR SHALLOW STRUCTURES, BEING NOISE SENSITIVE AND HARD TO ACHIEVE SATISFACTORY PERFORMANCE IN ACCURACY.
utt_0021 utt 138.74 150.74 -X FROM THE OTHER SIDE, WE LOOK AT THE MODERN CONVOLUTIONAL NEURAL NETWORKS, WHICH CAN AUTOMATICALLY LEARN ABSTRACT AND SEMANTICALLY MEANINGFUL FEATURES FOR HIGH PREDICTION ACCURACY.
utt_0023 utt 150.96 156.98 -X HOWEVER, CNN KERNELS ARE USUALLY INITIALIZED FROM RANDOM VARIABLES,
utt_0024 utt 156.98 168.21 -X WHICH APPROXIMATELY FOLLOW THE GAUSSIAN DISTRIBUTION, AND WITH NO EXPLICIT ENCODING OF GRADIENT INFORMATION DURING THE TRAINING, MAKING THEM HARD TO FOCUS ON EDGE RELATED FEATURES.
utt_0026 utt 169.36 176.95 -X WHAT IF WE INTEGRATE THE TRADITIONAL OPERATORS WITH THE VANILLA CNN CONVOLUTION? OR WE NAME
utt_0027 utt 176.95 185.06 -X IT AS PIXEL DIFFERENCE CONVOLUTION, OR PDC, WHAT DO WE EXPECT FROM PDC? FIRSTLY, WITH AN EXPLICIT
utt_0028 utt 185.06 198.66 -X ENCODING OF GRADIENT INFORMATION, WE CAN MAKE THE CNN MODEL TO FOCUS ON THE FEATURES THAT FACILITATE EDGE DETECTION. SECONDLY, THE POWERFUL LEARNING ABILITY OF DEEP CNNS CAN STILL BE PRESERVED, TO
utt_0030 utt 198.66 205.53 -X EXTRACT SEMANTICALLY MEANINGFUL REPRESENTATIONS, WHICH LEADS TO ROBUST AND ACCURATE EDGE DETECTION.
utt_0031 utt 206.19 211.67 -X WE GIVE A QUICK VIEW OF THE EFFECT OF PIXEL DIFFERENCE CONVOLUTION AS SHOWN IN THE PICTURE.
utt_0032 utt 211.86 225.27 -X THE FIRST ROW IS THE FEATURE MAPS GENERATED BY VANILLA CONVOLUTION, WHERE WE CAN SEE OBJECT BOUNDARIES IN MANY AREAS DISAPPEARED. WHILE IN THE FEATURES OF PIXEL DIFFERENCE CONVOLUTION,
utt_0034 utt 225.27 237.85 -X WE CAN SAFELY PRESERVE MOST OF THE DETAILED EDGE INFORMATION, WHICH IS PREFERABLE FOR THE FINAL PREDICTION. FROM THE STRUCTURE LEVEL, BECAUSE OF THE LACK OF LARGE SCALE ANNOTATED DATA,
utt_0036 utt 237.85 252.79 -X THE TOP PERFORMING CNN BASED DETECTORS OFTEN USE A PRETRAINED VGG NET AS A BACKBONE, FROM WHICH SEVERAL TASK-SPECIFIC BRANCHES ARE EXTENDED. EACH BRANCH WILL GENERATE AN EDGE MAP, AND A
utt_0038 utt 252.79 266.10 -X CORRESPONDING LOSS WILL BE CALCULATED BASED ON THE EDGE MAP AND THE GROUND TRUTH MAP. THE MODEL IS OFTEN HUGE, MOSTLY BECAUSE OF THE BIG BACKBONE. AND IT CAUSES SOME ISSUES. IT IS MEMORY CONSUMING,
utt_0040 utt 266.58 279.83 -X THE MODEL SIZE IS BIG, ENERGY HUNGRY FOR TRAINING AND INFERENCE, AND LABEL CONSUMING, BECAUSE THEY NEED BIG DATA TO PRETRAIN THE BACKBONE. WE EXPECT OUR MODEL TO HAVE THE FOLLOWING PROPERTIES.
utt_0042 utt 280.34 285.69 -X SMALL MODEL SIZE, HIGH RUNNING EFFICIENCY, NO NEED OF BIG DATA FOR PRETRAINING,
utt_0043 utt 285.69 297.21 -X AND AT THE SAME TIME, BEING ACCURATE. NEXT, I WILL FIRSTLY INTRODUCE PIXEL DIFFERENCE CONVOLUTION FROM THE KERNEL LEVEL, AND THEN I WILL GIVE A BRIEF ILLUSTRATION OF OUR MODEL ARCHITECTURE.
utt_0045 utt 298.49 311.07 -X PIXEL DIFFERENCE CONVOLUTION, OR PDC, IS PRETTY MUCH SIMILAR TO THE VANILLA CONVOLUTION. AND THIS IS THE FORMULATIONS OF THE TWO CONVOLUTIONAL OPERATIONS. THE ONLY DIFFERENCE IS THAT IN PDC,
utt_0047 utt 311.19 316.73 -X INSTEAD OF USING THE ORIGINAL PIXEL VALUES, WE USE THE VALUE DIFFERENCES BETWEEN PIXELS.
utt_0048 utt 317.30 329.53 -X IF WE HAVE A three BY three KERNEL, IN VANILLA CONVOLUTION, THE nine PIXELS IN THE LOCAL PATCH OF THE INPUT FEATURE MAP WILL BE CONVOLVED WITH THE KERNEL WEIGHT. BUT IN PDC, WE FIRSTLY
utt_0050 utt 329.69 337.11 -X SELECT SEVERAL PIXEL PAIRS FROM THE LOCAL PATCH, AND CALCULATE THE PIXEL DIFFERENCE FOR EACH PAIR.
utt_0051 utt 337.21 348.95 -X THEN, WE USE THE PIXEL DIFFERENCES TO CONVOLVE WITH THE KERNEL WEIGHT, AND GENERATE A PIXEL IN THE OUTPUT FEATURE MAP. BECAUSE THERE ARE NUMEROUS WAYS OF SELECTING THE PIXEL PAIRS,
utt_0053 utt 348.95 354.97 -X SO WE CAN ACTUALLY CREATE NUMEROUS PDC TYPES, OR WE CALL PDC INSTANCES. FOR EXAMPLE,
utt_0054 utt 354.97 362.40 -X WE SHOW THREE PDC INSTANCES IN THE PICTURE, CPDC, APDC, AND RPDC. WE ARE INSPIRED FROM THE
utt_0055 utt 362.78 375.00 -X TRADITIONAL LOCAL BINARY PATTERN DESCRIPTORS. THE three PDC INSTANCES ARE FORMED WITH DIFFERENT DIRECTIONS, AND ARE COMPLEMENTARY FOR PRESERVING THE GRADIENT INFORMATION.
utt_0057 utt 376.22 383.31 -X IN DETAIL, TAKE THE APDC AS AN EXAMPLE. THE CONVOLUTION PROCESS IS SHOWN ABOVE. Wone
utt_0058 utt 385.98 395.07 -X TIMES Xone MINUS Xtwo, PLUS Wtwo TIMES Xtwo MINUS Xthree, UNTIL THE MULTIPLICATION OF Wnine. SOME ONE MAY ASK,
utt_0059 utt 395.48 403.77 -X DO WE NEED MORE COMPUTATION FOR PDC COMPARED WITH VANILLA CONVOLUTION? ACTUALLY, WE CAN CONVERT PDC
utt_0060 utt 404.18 416.57 -X TO VANILLA CONVOLUTION WITH SOME SIMPLE MATHEMATIC TRANSFORMATIONS. THEREFORE, IT DOESN’T INTRODUCE EXTRA COMPUTATION. PLEASE REFER TO OUR PAPER FOR A MORE DETAILED ILLUSTRATION IF YOU ARE INTERESTED.
utt_0062 utt 417.79 427.71 -X FOR THE MODEL ARCHITECTURE, WE FOLLOW THE LISTED DESIGN PRINCIPLES. TO MAKE THE BACKBONE AS SLIM AS POSSIBLE, AND INTRODUCE FUNCTIONAL TASK-SPECIFIC BRANCHES FOR COMPENSATION.
utt_0064 utt 428.63 435.68 -X THIS IS THE OVERALL ARCHITECTURE OF OUR MODEL. SPECIFICALLY, WE HAVE four STAGES IN THE BACKBONE,
utt_0065 utt 435.68 448.37 -X EACH STAGE HAS four BLOCKS WITH SHORTCUT, AND A BRANCH WILL BE EXTENDED FROM THE END OF EACH STAGE. INSPIRED FROM MOBILENET, WE USE THE DEPTH-WISE CONVOLUTION, CONNECTED WITH THE
utt_0067 utt 448.37 453.36 -X POINT-WISE CONVOLUTION, TO MAKE THE BACKBONE SMALL. AND WE ADOPT THE PROPOSED PDC IN THE
utt_0068 utt 453.53 460.00 -X DEPTH-WISE CONVOLUTION. IN THE TASK-SPECIFIC BRANCHES, OR THE SIDE STRUCTURES, WE USE
utt_0069 utt 460.12 470.78 -X EXTRA DILATION CONVOLUTIONS WITH DIFFERENT RECEPTIVE FIELDS, CONNECTED WITH A SPATIAL ATTENTION MODULE, AND FINALLY, EACH BRANCH WILL GENERATE AN EDGE MAP. AGAIN, PLEASE REFER TO OUR
utt_0071 utt 470.78 477.15 -X ORIGINAL PAPER FOR MORE DETAILS. THE EXPERIMENTS ARE MOSTLY ON THE BSDSfive hundred DATASET, WHICH HAS A
utt_0072 utt 477.95 484.42 -X TRAINING SET WITH two hundred IMAGES, A VALIDATION SET WITH one hundred IMAGES, AND A TEST SET WITH two hundred IMAGES.
utt_0073 utt 484.51 490.54 -X ADDITIONALLY, WE WILL ALSO USE VOC CONTEXT DATASET DURING THE TRAINING. WE TRAIN FOR
utt_0074 utt 490.72 499.55 -X twenty EPOCHS IF VOC IS USED, AND fourteen EPOCHS IF IT IS NOT USED. WITH ADAM OPTIMIZER AND PYTORCH LIBRARY.
utt_0075 utt 500.73 506.46 -X WE FIRSTLY GIVE SOME ABLATION STUDIES ON THE BACKBONE CONFIGURATION. BECAUSE WE HAVE
utt_0076 utt 506.94 512.74 -X IN TOTAL sixteen BLOCKS IN THE BACKBONE, EACH BLOCK CAN USE THE PDC IN ITS DEPTH-WISE CONVOLUTION.
utt_0077 utt 512.92 527.20 -X THE NUMBER OF COMBINATION IS HUGE. HERE, WE EMPIRICALLY SELECT SOME CONFIGURATION ALTERNATIVES, BY INSERTING DIFFERENT NUMBER OF PDCS TO THE BACKBONE. FOR EXAMPLE, IN THE TABLE,
utt_0079 utt 528.99 535.39 -X C-[V]Xfifteen MEANS THE FIRST BLOCK USES CPDC, AND THE REST fifteen BLOCKS USE VANILLA CONVOLUTION.
utt_0080 utt 536.86 544.87 -X [CVVV]Xfour MEANS FOR EVERY four BLOCKS, THE FIRST BLOCK USES CPDC, THE OTHER three USE VANILLA CONVOLUTION,
utt_0081 utt 544.87 553.38 -X AND IT REPEATS FOR four TIMES. WE FIND THE BEST CONFIGURATION IS [CARV]Xfour, WHICH MEANS WE USE
utt_0082 utt 553.38 562.02 -X CPDC, APDC, RPDC, AND VANILLA CONVOLUTION IN TURN. AND WE NAME IT AS PIDINET. FOR A FURTHER
utt_0083 utt 562.02 575.55 -X COMPARISON BETWEEN PIDINET AND THE BASELINE, WHICH ONLY USES VANILLA CONVOLUTION, WE GIVE MORE EXPERIMENT RESULTS BY ADJUSTING THE NUMBER OF CHANNELS IN THE BACKBONE. IT IS CONSTANTLY
utt_0085 utt 575.55 588.71 -X SHOWN THAT PIDINET IS MORE EFFECTIVE THAN THE BASELINE MODEL. NEXT, WE ALSO DO SOME EXPLORATIONS ON THE SIDE STRUCTURES, BY REMOVING THE DILATION CONVOLUTION MODULE, THE SPATIAL ATTENTION MODULE,
utt_0087 utt 588.71 603.04 -X AND THE SHORTCUT. WE FIND EACH OF THEM TAKES A POSITIVE ROLE IN FINAL PERFORMANCE. THERE ARE SOME VISUALIZATIONS OF THE SIDE STRUCTURE, WHICH ALSO SUPPORTS OUR CONCLUSION. FINALLY, WE GIVE THE
utt_0089 utt 603.04 614.76 -X PERFORMANCE COMPARISON WITH PREVIOUS STATE OF THE ART METHODS, IN TERMS OF INFERENCE SPEED, MODEL SIZE AND ACCURACY. IT CAN BE SEEN THAT OUR MODELS CAN ACHIEVE HIGH RUNNING EFFICIENCY WITH VERY
utt_0091 utt 614.76 627.94 -X SMALL MODEL SIZE, AND AT THE SAME TIME ACHIEVE THE SAME LEVEL OF PREDICTION ACCURACY AMONG THE RECENT CNN MODELS. THERE IS MORE, FOR THE PRECISION RECALL CURVES, AND THE QUALITATIVE COMPARISON.
utt_0093 utt 629.02 641.97 -X TO SUMMARIZE, IN THIS PAPER, FIRSTLY WE DERIVE THE PIXEL DIFFERENCE CONVOLUTION WHICH INTEGRATES THE WISDOM FROM THE TRADITIONAL EDGE DETECTORS AND THE ADVANTAGES OF THE DEEP CNNS, LEADING TO ROBUST
utt_0095 utt 641.97 649.00 -X AND ACCURATE EDGE DETECTION. SECOND, WE PROPOSE A HIGHLY EFFICIENT ARCHITECTURE NAMED PIDINET
utt_0096 utt 649.79 655.14 -X BASED ON PIXEL DIFFERENCE CONVOLUTION, WHICH ARE MEMORY FRIENDLY AND WITH HIGH INFERENCE SPEED.
utt_0097 utt 655.26 660.36 -X FURTHERMORE, PIDINET CAN BE TRAINED FROM SCRATCH ONLY USING LIMITED DATA SAMPLES,
utt_0098 utt 661.02 674.61 -X WHILE ACHIEVING STATE OF THE ART PERFORMANCE. FOR THE FUTURE WORK, THE ARE TWO ASPECTS. FOR OTHER APPLICATIONS: EDGE DETECTION IS A LOW LEVEL TASK FOR MANY MID- OR HIGH-LEVEL VISION TASKS
utt_0100 utt 674.61 680.68 -X LIKE SEMANTIC SEGMENTATION AND OBJECT DETECTION. ALSO, SOME LOW LEVEL TASKS LIKE SALIENT OBJECT
utt_0101 utt 680.71 693.13 -X DETECTION MAY ALSO BENEFIT FROM THE IMAGE BOUNDARY INFORMATION. WE HOPE PIXEL DIFFERENCE CONVOLUTION AND THE PROPOSED PIDINET CAN GO FURTHER AND BE USEFUL IN THESE RELATED TASKS. FOR NEURAL NETWORK
utt_0103 utt 693.13 706.12 -X SEARCH: LIKE VANILLA CONVOLUTION, THE PROPOSED APDC, CPDC, AND RPDC, AND EVEN MORE BY CREATING CUSTOMER PDC INSTANCES, CAN BE REGARDED AS THE BASIC PRIMITIVE CONVOLUTIONAL OPERATIONS, WHICH
utt_0105 utt 706.12 717.83 -X CAN ENRICH THE SEARCHING SPACE IN NAS TECHNOLOGY. WE HAVE ALSO RELEASED OUR CODE AND TRAINED MODELS ON GITHUB. YOU ARE WELCOME TO DISCUSS WITH US IF YOU ARE INTERESTED IN OUR WORK. THANKS.
