utt_0000 utt 0.05 5.17 -X THIS IS PART OF OUR VIDEO SERIES ON HUMAN-CENTERED EVALUATIONS FOR NLP EXPLANATIONS.
utt_0001 utt 5.58 10.35 -X CHECK OUT THE LINK FOR MORE RESOURCES. YOU'RE CURRENTLY HERE ...
utt_0002 utt 10.64 13.97 -X ONCE WE’VE COLLECTED A DATASET OF HUMAN EXPLANATIONS,
utt_0003 utt 13.97 19.03 -X THE NEXT QUESTION IS HOW TO USE THEM AS A GOLD STANDARD FOR MODEL EXPLANATIONS.
utt_0004 utt 19.69 22.77 -X IT’S EASIER TO DO SO WITH RATIONALE-STYLE EXPLANATIONS,
utt_0005 utt 22.77 26.55 -X WHERE EVALUATION IS BASICALLY THE SAME AS ANY SEQUENCE CLASSIFICATION TASK.
utt_0006 utt 27.57 30.03 -X HOWEVER, THERE ARE STILL A FEW NUANCES HERE,
utt_0007 utt 30.03 36.21 -X INVOLVING PROPERTIES OF BOTH THE HUMAN-ANNOTATED RATIONALES AND THE MODEL-GENERATED RATIONALES.
utt_0008 utt 44.43 55.80 -X IN THE SIMPLEST SCENARIO, BOTH THE HUMAN RATIONALE AND MODEL RATIONALE ARE ONE BINARY VALUE PER TOKEN. IN THIS CASE, WE CAN SIMPLY CALCULATE MEASURES OF BINARY TOKENWISE AGREEMENT, SUCH AS PRECISION, RECALL AND Fone.
utt_0011 utt 57.17 61.94 -X HOWEVER, MOST EXPLANATION METHODS OUTPUT CONTINUOUS RATHER THAN DISCRETE VALUES.
utt_0012 utt 62.55 67.51 -X IN CASES WHERE THESE VALUES ARE ON A CONSISTENT SCALE, SUCH AS WITH CERTAIN ATTENTION MECHANISMS,
utt_0013 utt 68.15 74.76 -X WE CAN EITHER CHOOSE A SENSIBLE THRESHOLD FOR BINARIZATION AND THEN APPLY BINARY METRICS, OR
utt_0014 utt 75.25 82.62 -X WE CAN NORMALIZE TO zerominus one AND CALCULATE CONTINUOUS METRICS LIKE MEAN-SQUARED OR MEAN ABSOLUTE ERROR.
utt_0015 utt 82.62 93.34 -X ONE COMMON SCENARIO IS THAT MODEL RATIONALES ARE GENERATED BY SOFTMAXING ACROSS THE LENGTH OF THE INPUT. AN EXAMPLE IS IF WE LOOK AT THE INTERNAL ATTENTION WEIGHTS OF A TRANSFORMER-BASED MODEL,
utt_0017 utt 93.34 97.79 -X WHICH ARE PRODUCED BY THIS OPERATION.
utt_0018 utt 97.79 101.82 -X THIS IS ACTUALLY A TRICKY SITUATION, BECAUSE IT COERCES VARIABLE-DENSITY RATIONALES
utt_0019 utt 102.20 105.59 -X ACROSS VARIABLE LENGTH SEQUENCES TO A CONSISTENT SUM,
utt_0020 utt 105.59 110.27 -X PUTTING THEM ON DIFFERENT SCALES FROM BOTH THE HUMAN-ANNOTATED RATIONALES, AND EACH OTHER.
utt_0021 utt 110.39 120.99 -X A COMMON APPROACH HERE IS TO CHOOSE THE TOP-K TOKENS FROM EACH MODEL RATIONALE AND COMPARE THEM TO THE TOP-K FROM THE HUMAN RATIONALE. BUT THERE ISN’T REALLY A GOOD WAY TO CHOOSE THIS K.
utt_0023 utt 121.75 126.33 -X SETTING IT TO THE LENGTH OF EACH INDIVIDUAL HUMAN RATIONALE REQUIRES TOO MUCH INFORMATION,
utt_0024 utt 126.46 132.22 -X AND SETTING IT TO SOME GLOBAL VALUE DISCOUNTS THE FACT THAT DIFFERENT RATIONALES HAVE DIFFERENT NUMBERS OF CAUSAL TOKENS.
utt_0026 utt 132.95 136.44 -X A BETTER APPROACH, ALTHOUGH NOT ONE THAT I’VE SEEN IN THE LITERATURE,
utt_0027 utt 136.44 139.68 -X IS TO TREAT THE SOFTMAXXED VALUES AS A RANKING OVER THE TOKENS,
utt_0028 utt 139.80 145.41 -X THEN APPLY MEASURES OF RANK AGREEMENT, SUCH AS AVERAGE PRECISION.
utt_0029 utt 145.41 149.63 -X ANOTHER COMMON SCENARIO IS WHERE THE MODEL RATIONALES ARE ON AN ARBITRARY SCALE.
utt_0031 utt 156.09 168.67 -X PRACTICALLY SPEAKING, THIS IS THE SAME SCENARIO AS SOFTMAXXED RATIONALES, AND THE APPROACHES FOR DEALING WITH IT ARE THE SAME–TOP-K IS TYPICALLY, BUT RANKING METRICS ARE PROBABLY MORE APPROPRIATE.
utt_0033 utt 168.67 179.49 -X SOMETIMES WE WANT TO EVALUATE TOKEN-LEVEL MODEL RATIONALES AT THE LEVEL OF SPANS RATHER THAN INDIVIDUAL TOKENS, WHETHER IT BE CONTIGUOUS HUMAN RATIONALE SPANS, SENTENCES, OR SENTENCE-PHRASES.
utt_0035 utt 180.12 190.31 -X THE SIMPLEST APPROACH HERE IS TO AVERAGE OR OTHERWISE AGGREGATE THE MODEL RATIONALES ACROSS THE DESIRED SPANS, THEN DEFINE A CRITERIA FOR WHETHER THE MODEL MATCHED THAT SPAN.
utt_0037 utt 190.31 192.58 -X IN THE ABOVE EXAMPLE, I SIMPLY BINARIZE AT zero point five,
utt_0038 utt 193.50 200.16 -X MEANING THAT IF THE MODEL CAUGHT fifty% OF A GIVEN HUMAN RATIONALE SPAN, IT COUNTS AS A MATCH.
utt_0039 utt 200.16 203.68 -X FINALLY, IN CASES WITH MULTIPLE HUMAN EXPLANATION ANNOTATORS,
utt_0040 utt 204.10 207.27 -X THERE WILL BE UNCERTAINTY IN EACH HUMAN RATIONALE.
utt_0041 utt 207.36 213.41 -X ONE WAY TO DEAL WITH THIS IS TO WEIGHT EACH HUMAN RATIONALE TOKEN BY HOW CLOSE IT WAS TO UNANIMITY,
utt_0042 utt 213.41 216.74 -X AND APPLY THIS WEIGHT TO WHATEVER TOKEN WISE METRICS YOU HAPPEN TO BE USING.
utt_0043 utt 216.74 227.69 -X ALL THE METRICS DISCUSSED ABOVE ARE AVAILABLE IN THE SCIKIT-LEARN METRICS MODULE, AND ALMOST ALL OF THEM HAVE A SAMPLE_WEIGHTS OPTIONAL ARGUMENT FOR DEALING WITH UNCERTAINTY IN THE GROUND TRUTH.
utt_0045 utt 228.87 232.29 -X EVALUATING FREE-TEXT EXPLANATIONS IS HARDER,
utt_0046 utt 232.29 235.65 -X JUST LIKE EVALUATING NATURAL LANGUAGE GENERATION IS HARD GENERALLY.
utt_0047 utt 236.35 246.34 -X A NUMBER OF SIMPLE METHODS HAVE BEEN PROPOSED OVER THE YEARS FOR THE GENERAL TASK OF NATURAL LANGUAGE EVALUATION. THIS RECENT SURVEY BY CRISTINA GARBACEA HAS A NICE OVERVIEW.
utt_0054 utt 263.98 265.74 -X BETTER THAN EITHER HUMAN EXPLANATION).
utt_0057 utt 269.87 281.99 -X ONE VERY COMMON METRIC IS ROUGE, WHICH SIMPLY MEASURES N-GRAM OVERLAP BETWEEN THE GENERATED TEXT AND THE REFERENCE TEXT. THIS WAS ORIGINALLY DESIGNED TO EVALUATE SUMMARIZATION ALGORITHMS,
utt_0059 utt 281.99 287.15 -X BUT IS COMMON ACROSS THE NLG LITERATURE THESE DAYS.
utt_0060 utt 287.15 296.11 -X ANOTHER VERY COMMON METRIC IS BLEU, WHICH COMPUTES CLIPPED N-GRAM PRECISION SCORES BETWEEN THE GENERATED TEXT AND ONE OR MORE REFERENCE TEXTS.
utt_0062 utt 296.84 301.52 -X BLEU WAS CREATED FOR EVALUATING TRANSLATION MODELS, AND IS ALSO ALL OVER THE PLACE.
utt_0063 utt 304.20 307.53 -X A MORE RECENT METRIC IS WORD MOVER’S DISTANCE,
utt_0064 utt 307.91 313.01 -X WHICH INVOLVES PERFORMING AN ALIGNMENT BETWEEN THE TOKENS IN THE GENERATED VERSUS REFERENCE TEXT,
utt_0065 utt 313.01 319.12 -X AND THEN CALCULATING THE AVERAGE COSINE DISTANCE BETWEEN THE WORD EMBEDDINGS OF THE TWO TEXTS.
utt_0066 utt 319.12 329.49 -X FINALLY, A COMMON NON-SIMILARITY-BASED METHOD IS PERPLEXITY, WHICH CALCULATES THE LIKELIHOOD OF THE MODEL’S OUTPUT, EFFECTIVELY MEASURING HOW CERTAIN IT IS OF ITS GENERATED TEXT.
utt_0068 utt 332.59 335.50 -X A VARIANT ON THIS IDEA IS “REVERSE PERPLEXITY”,
utt_0069 utt 335.92 339.34 -X WHERE A SECOND LANGUAGE MODEL IS TRAINED ON OUTPUT FROM THE FIRST,
utt_0070 utt 339.50 344.05 -X AND THEN THE LIKELIHOOD OF THE REFERENCE TEXTS IS CALCULATED RELATIVE TO THIS MODEL.
utt_0072 utt 352.33 359.44 -X RATIONALES IS RELATIVELY EASY. IT JUST TAKES SOME INFORMED DECISION-MAKING ABOUT HOW TO SCALE OR THRESHOLD THE MODEL RATIONALE, AND WHAT METRIC TO USE.
utt_0074 utt 359.44 371.86 -X EVALUATING FREE-TEXT EXPLANATIONS IS MUCH HARDER. NATURAL LANGUAGE GENERATION IS HARD TO EVALUATE AS IT IS, AND EVALUATING FREE-TEXT EXPLANATIONS IS MADE MORE DIFFICULT BY AMBIGUITY OVER THE
utt_0076 utt 371.86 383.38 -X PURPOSE OF THESE EXPLANATIONS? WHAT ARE THEY SUPPOSED TO DO, INFORMATIONALLY SPEAKING? IS TRYING TO MATCH THEM TO HUMAN-ANNOTATED EXPLANATIONS EVEN A VALID OBJECTIVE?
utt_0078 utt 383.41 387.06 -X AND THAT BEGS THE MAIN QUESTION HERE, WHICH APPLIES TO BOTH TYPES OF EXPLANATION:
utt_0079 utt 387.73 398.58 -X SHOULD MODEL EXPLANATIONS BE SIMILAR TO HUMAN EXPLANATIONS? OR IS THAT A FUNDAMENTALLY FLAWED OBJECTIVE, MAKING THE WHOLE IDEA OF PROXY EVALUATIONS KIND OF USELESS IN THIS CONTEXT?
