utt_0000 utt 0.11 4.62 -X HELLO EVERYONE, MY NAME IS EFTHYMIOS TZINIS AND TODAY I'M GOING TO PRESENT TO YOU OUR WORK
utt_0001 utt 4.75 15.98 -X SEPARATE BUT TOGETHER: UNSUPERVISED FEDERATED LEARNING FOR SPEECH ENHANCEMENT FROM NON-IID DATA THIS IS JOINT WORK WITH JONAH AND ZHEPEI, MY LAB MATES, AND MY ADVISOR PARIS SMARAGDIS. SO WE'RE
utt_0003 utt 15.98 22.59 -X GOING TO TALK IN THIS WORK ABOUT THE NEW KIND OF SPEECH ENHANCEMENT. RIGHT NOW WE HAVE TIME DOMAIN
utt_0004 utt 23.47 36.82 -X AUDIO SOURCE SEPARATION WHICH PROVIDES STATE OF THE ART RESULTS USING TIME-DOMAIN MODELS AND OF COURSE SPEECH ENHANCEMENT IS A SPECIFIC INSTANCE OF THIS PROBLEM SO WE USE THOSE MODELS THERE AS WELL.
utt_0006 utt 36.82 48.93 -X OF COURSE WE NEED LOTS OF SUPERVISED DATA IN ORDER TO TRAIN THESE MODELS BUT IT'S IMPOSSIBLE TO CAPTURE ANY KIND OF REAL-WORLD TEST MIXTURE DISTRIBUTION USING SUCH LIMITED SUPERVISED DATA COLLECTION
utt_0008 utt 48.93 56.08 -X SETUP THIS IS WHY WE NEED SELF-SUPERVISED METHODS IN THE FIRST PLACE. ON THE OTHER HAND, WE CAN'T MEET THE
utt_0009 utt 57.42 63.36 -X THE ASSUMPTION THAT ALL OF THE DATA ARE GONNA BE AVAILABLE AT ONCE ON A SINGLE DEVICE SO
utt_0010 utt 64.05 69.22 -X DIFFERENT USERS MIGHT HAVE DIVERSE DATA BUT THEY MIGHT NOT BE WILLING TO SHARE
utt_0011 utt 69.45 76.56 -X THEIR DATA WITH EACH OTHER OR WITH ANY ANY KIND OF SERVER AND THIS IS WHY WE NEED FEDERATED LEARNING
utt_0012 utt 77.42 89.75 -X SO FOR THE FIRST ASPECT OF THE SUPERVISED SPEECH ENHANCEMENT, WE KNOW THAT THERE IS THE MIXTURE INVARIANT TRAINING SETUP WHERE IT CAN PROVIDE A GOOD ALGORITHM FOR SELF-SUPERVISED
utt_0014 utt 89.75 94.32 -X AUDIO SOURCE SEPARATION AND OF COURSE FOR SPEECH ENHANCEMENT AS WELL WHERE WE CREATE
utt_0015 utt 94.80 99.97 -X A MIXTURE OF MIXTURES FROM TWO INDIVIDUAL MIXTURES AND WE LET THE MODEL SEPARATE A FEW SOURCES
utt_0016 utt 100.24 107.27 -X AND WE TAKE THE LOSS AFTER ASSIGNING THESE ESTIMATED SOURCES BACK TO THE INITIAL MIXTURES
utt_0017 utt 107.63 114.90 -X SO FOR THE SPECIFIC CASE OF SPEECH ENHANCEMENT WE CAN CREATE THESE MIXTURES OF MIXTURES USING A NOISY
utt_0018 utt 114.99 121.68 -X MIXTURE (A CLEAN SPEECH PLUS NOISE) AND ONE CLEAN NOISE RECORDINGS WHEREAS THE MODEL WILL HAVE
utt_0019 utt 121.87 128.28 -X THREE OUTPUT SLOTS ONE FOR SPEECH AND THE OTHER TWO FOR THE REST OF THE SOURCES. OF COURSE
utt_0020 utt 128.82 136.44 -X THERE ARE CERTAIN LIMITATIONS ABOUT THIS APPROACH WHICH HAS TO DO THAT ALL OF THE DATA WOULD BE
utt_0021 utt 136.44 144.66 -X AVAILABLE ON THE SAME DEVICE AND HERE COMES THE FEDERATED LEARNING IN ORDER TO FILL THAT GAP WHICH IS
utt_0022 utt 144.66 158.71 -X A DISTRIBUTED TRAINING FRAMEWORK WHERE USERS DO NOT NEED TO SHARE DATA IN ORDER TO COLLABORATEVELY TRAIN A MODEL. SO, FIRST THE SERVER OWNS A GLOBAL VERSION OF THIS MODEL AND DISTRIBUTES IT
utt_0024 utt 158.71 167.03 -X BACK TO EACH ONE OF THOSE USERS AS WE SEE HERE SO THEN EACH ONE OF THE USERS ARE GONNA PERFORM LOCAL
utt_0025 utt 167.89 175.11 -X UPDATES USING THEIR LOCAL DATA AND THEY'RE GONNA SEND BACK THEIR UPDATES TO THE SERVER
utt_0026 utt 176.50 183.16 -X THAT WHERE THE LATTER IS GONNA, ON ITS TURN, IT'S GONNA REDISTRIBUTE BACK THE UPDATED MODEL. OF COURSE,
utt_0027 utt 183.16 193.37 -X WE HAVE SEEN THAT THERE ARE SEVERAL LIMITATIONS WITH SUCH FEDERATED LEARNING APPROACHES FROM WORKS IN THE LITERATURE THAT THEY HAVE SHOWN DIMINISHING PERFORMANCE WHEN WE HAVE NON-IID
utt_0029 utt 193.87 207.57 -X DATA ACROSS THE USERS, WHEN APPLYING HARDER TASKS THAN DETECTION SUCH AS SEPARATION OR ANOTHER ESTIMATION TASK AND THE THE MOST IMPORTANT ONE IS WHAT HAPPENS WHEN YOU HAVE TO TRAIN
utt_0031 utt 207.60 218.97 -X ON A LOCAL LEVEL WITHOUT HAVING GROUND TRUTH SOURCES OR THE GROUND TRUTH LABELS IN GENERAL SO OUR PROPOSED ALGORITHM WHICH IS CALLED FEDENHANCE, IN A NUTSHELL
utt_0033 utt 219.00 232.22 -X WHAT IT DOES IT IS THAT IT PROVIDES SUCH A FEDERATED LEARNING FRAMEWORK THAT IT CAN TRAIN COMPLETELY UNSUPERVISED BUT IT CAN ALSO INCORPORATE SUPERVISED NODES AS WE CAN SEE HERE ON THE RIGHT
utt_0035 utt 232.56 239.35 -X AND EACH ONE OF THOSE NODES PERFORMS LOCAL UPDATES GIVES THE UPDATES BACK TO THE SERVER AND THE
utt_0036 utt 239.35 247.96 -X SERVER PERFORMS THE GLOBAL UPDATE AND SENDS BACK THE MODEL AFTER PERFORMING FEDERATED AVERAGING
utt_0037 utt 248.50 261.69 -X SO IN MORE DETAIL WE'RE GOING TO SEE HOW THE FEDENHANCE WORKS. SO, FIRST WE BEGIN WITH THE RANDOMLY INITIALIZED OR PRE-TRAINED NETWORK THAT THE SERVER HAS WHICH IS REALLY IMPORTANT AND WE'RE GOING TO SEE
utt_0039 utt 261.69 270.52 -X WHY IN A LITTLE BIT AND THE MODEL DISTRIBUTES THIS VERSION OF THE MODEL TO EACH ONE OF THOSE CLIENTS
utt_0040 utt 270.90 284.57 -X SO EACH ONE OF THOSE CLIENTS HAS THE SAME MODEL A SPEECH ENHANCEMENT MODEL RIGHT NOW SO NOW WE NEED TO UPDATE THIS MODEL AND WE HAVE TO PERFORM LOCAL TRAINING SO FOR EXAMPLE IN THE CASE OF THE
utt_0042 utt 285.56 300.35 -X UNSUPERVISED TRAINING WE HAVE A MIXTURE OF CLEAN SPEECH SPEAKER PLUS SOME NOISE AND THEN A SECOND MIXTURE CONTAINING ONLY A NOISE RECORDING AND YOU HAVE A SEPARATION MODEL WITH THREE OUTPUT
utt_0044 utt 300.35 307.00 -X SLOTS AND THE LOSS FUNCTION FOR THIS UNSUPERVISED NODE IS GOING TO BE THE REGULAR MIXTURE
utt_0045 utt 307.00 321.82 -X INVARIANT TRAINING LOSS FUNCTION WHEREAS IN THE SUPERVISED CASE WE HAVE ACCESS TO THE CLEAN SPEECH AS WE SEE HERE IN THE AND THE LEFTMOST POINT OF THIS LOSS FUNCTION SO WE CAN USE THAT IN ORDER TO
utt_0047 utt 321.82 336.28 -X REGRESS OVER IT AND WE CAN USE REGULAR PERMUTATION INVARIANT TRAINING FOR THE REST OF THE TWO SOURCES SO WE SEE HERE THAT AFTER WE PERFORM THOSE LOCAL UPDATES ON EACH ONE OF THE
utt_0049 utt 338.20 343.04 -X DEVICES OF THE LOCAL DEVICES WE CAN PERFORM ASYNCHRONOUS MODEL UPDATES BY SENDING BACK
utt_0050 utt 344.31 351.77 -X OUR MODEL WEIGHTS TO THE SERVER AND OF COURSE THEY'RE GONNA BE USERS THAT THEY HAVEN'T
utt_0051 utt 353.91 360.41 -X THEY COULDN'T UPDATE THEIR MODEL OR SEND IT BACK TO THE SERVER BY THAT TIME
utt_0052 utt 360.95 375.87 -X SO THE SERVER IS RESPONSIBLE FOR PERFORMING THE MODEL UPDATES SO IT'S GONNA AGGREGATE THOSE UPDATES BY A SIMPLE AVERAGING SCHEME SO IT'S GONNA AGGREGATE THOSE MODELS FROM ALL
utt_0054 utt 378.17 391.42 -X THAT IT GOT FROM ALL OF THE NODES THAT CONTRIBUTED TO THIS COMMUNICATION ROUND AND IT'S GONNA GET THE NEW MODEL THAT IS GONNA DISTRIBUTE IT BACK TO EACH ONE OF THE CLIENTS AGAIN IN ORDER TO PERFORM
utt_0056 utt 391.42 405.12 -X THE NEW COMMUNICATION ROUND AND OF COURSE THIS INCLUDES NODES WHICH DID NOT PARTICIPATE IN THE PREVIOUS COMMUNICATION ROUND. FOR THE LOCAL MODULE TRAINING WE COULD USE ANY KIND OF SEPARATION
utt_0058 utt 406.04 420.81 -X MODEL THAT WE WOULD LIKE BUT IN ORDER TO REMAIN TO RESPECT REALISTIC HARDWARE REQUIREMENTS IN TERMS OF SEVERAL DEVICES THAT USERS HAVE WE CHOSE THE SUDO RM -RF MODEL ARCHITECTURE WHICH
utt_0060 utt 421.91 432.70 -X WHICH PERFORMS COMPARABLY TO STATE-OF-THE-ART MODELS BUT USING LESS PARAMETERS AND BEING MORE LIGHTWEIGHT IN TERMS OF MEMORY REQUIREMENTS AND BEING REALLY FAST AND ON TOP OF THE
utt_0062 utt 432.89 445.53 -X OF THE SUDO RM -RF ARCHITECTURE WE USE A MIXTURE CONSISTENCY PROJECTION LAYER AND THE LOSS FUNCTION IN TERMS OF THE SIGNAL THE SIGNAL LEVEL LOSS FUNCTION WITH OUR ESTIMATED SOURCE AND THE
utt_0064 utt 446.39 452.00 -X THE TARGET IS GOING TO BE THE NEGATIVE SCALE INVARIANT SIGNAL TO DISTORTION RATIO (SI-SDR)
utt_0065 utt 452.00 460.25 -X WE ALSO INTRODUCED A NEW DATA SET CALLED LIBRIFSDfiftyK WHICH IS THE CONGLOMERATION OF LIBRISPEECH
utt_0066 utt 460.25 470.00 -X FOR THE SPEECH SAMPLES AND THE FSDfiftyK WITH A DIVERSE SET OF SOUNDS OF NOISE SOURCES AND
utt_0067 utt 470.11 482.53 -X WE CAN SEE HERE THAT WE GET SOME KIND OF REALISTIC INPUT SNR DISTRIBUTIONS FOR ONE OR TWO WHEN ONE OR TWO NOISE SOURCES ARE PRESENT AND THE MOST IMPORTANT ASPECT OF THIS DATA SET IS THAT WE CAN
utt_0069 utt 482.53 496.56 -X WE HAVE MULTIPLE SPEAKER IDS THAT WE CAN DISTRIBUTE TO THE CLIENTS. SO EACH CLIENT DOES NOT HAVE ANY OVERLAP IN TERMS OF THE ID AND PERFORM COMPLETELY NON-IID TRAINING YOU CAN FIND
utt_0071 utt 496.56 504.93 -X THE DATA GENERATION RECIPE ONLINE AND AND YOU CAN USE IT FOR YOUR OWN EXPERIENCE. SO, WE'RE GONNA
utt_0072 utt 505.56 518.98 -X SHOW THREE DIFFERENT EXPERIMENTS. THE FIRST ONE IS TO SHOW THAT WE CAN ACTUALLY PERFORM UNSUPERVISED FEDERATED SPEECH ENHANCEMENT FROM SCRATCH WHERE WE SPLIT THE SPEAKER IDS EQUALLY
utt_0074 utt 518.98 527.78 -X TO THE NUMBER OF CLIENTS AND WE RANDOMLY ASSIGN THE NOISE SOURCES TO THOSE CLIENTS
utt_0075 utt 531.10 542.27 -X SO EACH LOCAL UPDATE IS GONNA HAVE ONE TRAINING EPOCH FOR EACH CLIENT BEFORE THEY COMMUNICATE THEIR UPDATES AND WE ASSUME ALSO THAT ONLY twenty-five% OF THE CLIENTS ARE AVAILABLE AT EACH
utt_0077 utt 542.27 547.99 -X COMMUNICATION ROUTE. THE SECOND EXPERIMENT IS GOING TO BE FOR TRANSFER LEARNING
utt_0078 utt 548.00 554.08 -X WHERE THE INITIAL SPEECH ENHANCEMENT MODEL IS NOT GOING TO BE A RANDOM SEED BUT IT'S GOING
utt_0079 utt 554.40 562.55 -X TO BE A PRE-TRAINED MODEL USING THE WHAM! DATA SET AND WHERE WE PERFORM TRAINING ON A SMALLER
utt_0080 utt 562.75 568.61 -X SET OF NOISE SOURCES SO IT HAS LESS DIVERSITY THAN OUR LIBRIFSDfiftyK
utt_0081 utt 570.05 581.15 -X AND THE LAST ONE IS TO SHOW THAT WE CAN EFFECTIVELY COMBINE SUPERVISED AND UNSUPERVISED CLIENTS AND DIFFERENT LOSS FUNCTIONS UNDER THE SAME FEDERATED LEARNING SETUP
utt_0083 utt 581.89 594.50 -X SO WE SEE HERE THAT WITH SOLID LINES WE HAVE THE CONVERGENCE AS WE INCREASE THE NUMBER OF COMMUNICATION AROUND WHERE EACH ONE OF THE SOLID LINES REPRESENTS THE FEDENHANCE
utt_0085 utt 597.70 600.10 -X WITH DIFFERENT NUMBER OF CLIENTS AS WE SEE HERE
utt_0086 utt 600.93 606.85 -X AND WE CAN SEE THAT WE CAN SCALE PRETTY GOOD IN TERMS OF THE NUMBER OF CLIENTS
utt_0087 utt 608.32 620.48 -X AND WE CAN EFFECTIVELY OBTAIN BETTER PERFORMANCE AS WE SCALE AND THE PROBLEM BECOMES WAY HARDER AND ALL OF THAT IS LEARNING UNDER A COMPLETELY UNSUPERVISED AND A COMPLETELY
utt_0089 utt 620.48 626.63 -X FEDERATED MANNER WITH NON-IID DATA DISTRIBUTION IN TERMS OF OUR MIXTURES
utt_0090 utt 627.68 639.62 -X SO NOW WE CAN WE CAN MEASURE HOW WELL WE PERFORM COMPARED TO THE UPPER BOUND OF THE IID TRAINING SETUP WHICH IS THE DASHED BLACK LINE ON TOP WHICH IS EFFECTIVELY PERFORMING
utt_0092 utt 639.62 645.12 -X MIXTURE INVARIANT TRAINING WHEN WE ASSUME THAT WE HAVE ALL OF THE DATA AVAILABLE ON A SINGLE DEVICE
utt_0093 utt 647.11 652.26 -X AND AND OF COURSE IF WE COMPARE EACH ONE OF THOSE FEDENHANCE SETUPS
utt_0094 utt 654.69 662.68 -X FEDERATED LEARNING SETUPS WITH THE ISOLATED TRAINING WHERE WE HAVE THE SAME AMOUNT OF DATA
utt_0095 utt 662.72 668.17 -X AT EACH LOCAL NODE WE SEE THAT FOR EXAMPLE FOR THE CASE OF two hundred and fifty-six
utt_0096 utt 668.71 682.37 -X CLIENTS, THE ISOLATED TRAINING COMPLETELY FAILS WHEREAS WHEN WE COLLABORATELY TRAIN OUR MODEL WE CAN OBTAIN A SIGNIFICANT IMPROVEMENT OVER THE INPUT MIXTURE WITHOUT HAVING A SINGLE
utt_0098 utt 683.75 689.61 -X GROUND TRUTH SPEAKER WAVEFORM AND STARTING COMPLETELY FROM SCRATCH
utt_0099 utt 690.34 703.88 -X WE NOTICED THAT EXACTLY THE SAME APPLIES WHEN WE HAVE TWO NOISE SOURCES AT OUR EVALUATION MIXTURES INSTEAD OF ONE SO WE SEE THE SAME CONVERGENCE SPEED AND THE SAME BEHAVIOR
utt_0101 utt 704.77 711.42 -X IN TERMS OF THE NON-IID TRAINING AND ALSO FOR THE SECOND EXPERIMENT WE SEE THAT
utt_0102 utt 712.23 721.83 -X OUR MODEL CAN BE SIGNIFICANTLY IMPROVED IN TERMS OF ITS CONVERGENCE SPEED EVEN WHEN
utt_0103 utt 721.83 728.14 -X PRE-TRAINING ON A SMALLER DATA SET SUCH AS WHAM! SO WE SEE FOR EXAMPLE HERE FOR THE CASE OF THE
utt_0104 utt 730.02 742.68 -X two hundred and fifty-six FROM SCRATCH WHICH IS THE SOLID YELLOW LINE AFTER one thousand COMMUNICATION ROUNDS WE ARE PRETTY MUCH AT THE SAME LEVEL AS THE ONE THAT WE WERE
utt_0106 utt 742.72 748.23 -X WHEN PERFORMING WHEN JUST PERFORMING THE PRE-TRAINING AND A SINGLE COMMUNICATION ROUND
utt_0107 utt 749.80 756.54 -X A SINGLE AFTER A SINGLE COMMUNICATION AROUND AND FOR TRAINING OVER HERE SO WE SEE THAT WE CAN
utt_0108 utt 756.80 763.74 -X WE CAN DEVELOP MORE EFFICIENT FEDERATED LEARNING ALGORITHMS WHEN WE EMPLOY AND WE EXPLOIT THIS
utt_0109 utt 764.58 776.23 -X KIND OF TRANSFER LEARNING SETUPS ALSO FOR OUR LAST EXPERIMENTS WE SEE THAT WE THAT FEDENHANCE CAN EFFECTIVELY COMBINE DIFFERENT LOSS FUNCTIONS. WE FIX THE NUMBER OF CLIENTS TO
utt_0111 utt 776.42 790.81 -X sixty-four AND WE SWEEP THE NUMBER OF SUPERVISED NODES SO WE SEE HERE THAT BY JUST ADDING twenty-five% OF THE NODES TO BE SUPERVISED WE CAN BOOST OUR PERFORMANCE FROM THE COMPLETELY UNSUPERVISED SETTING AND WE CAN SEE THE TREND FROM THE COMPLETE UNSUPERVISED TO THE FULLY SUPERVISED SETUP WHERE WE
utt_0114 utt 790.81 795.63 -X CAN INCREASE THE PERFORMANCE AND OUR ALGORITHM IS ABLE TO PERFORM TO SCALE AND PERFORM BETTER
utt_0116 utt 800.36 805.58 -X WHICH IS THE FIRST FEDERATED LEARNING SYSTEM FOR SPEECH ENHANCEMENT BUT MORE GENERALLY
utt_0119 utt 815.21 821.61 -X SHOWN IN OUR EXPERIMENTAL SETUP AND MORE IMPORTANTLY WITH COMPARABLE PERFORMANCE TO
utt_0120 utt 821.67 828.03 -X SINGLE DEVICE IID TRAINING WHERE ALL THE DATA ARE AVAILABLE AT THE SAME TIME AND FINALLY
utt_0122 utt 832.04 842.16 -X SUCH AS SUPERVISED AND UNSUPERVISED LOSS FUNCTIONS WITH THE REGULAR PERMUTATION INVARIANT TRAINING AND MIXTURE INVARIANT TRAINING WE HAVE ALSO INTRODUCED A NEW DATA SET
utt_0124 utt 842.16 851.66 -X THAT CAN BE USED FOR FEDERATED LEARNING SPEECH ENHANCEMENT AND OTHER SPEECH ENHANCEMENT TASKS AND ALSO IN THE FUTURE WE AIM TO EXTEND OUR ALGORITHM IN ORDER TO COVER MULTIPLE OTHER
utt_0126 utt 851.66 857.87 -X SETTINGS SUCH AS MULTI-MODAL SETTINGS AND ALSO REMOVE THE ASSUMPTIONS ABOUT HAVING ACCESS
utt_0127 utt 859.40 872.46 -X TO IN-DOMAIN NOISE SAMPLES WHEN PERFORMING THE MIXTURE INVARIANT TRAINING. SO, I WOULD LIKE TO THANK YOU VERY MUCH FOR WATCHING THIS VIDEO AND ATTENDING THE TALK. YOU CAN FIND THE CODE ONLINE AS
utt_0129 utt 874.12 882.06 -4.6268 WELL AS THE DATA SET AND I WOULD BE MORE HAPPY TO ANSWER YOUR QUESTIONS IN THE Q &AMP A SESSION, THANKS!
