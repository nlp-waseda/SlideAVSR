utt_0000 utt 0.26 3.09 -X I AM PRAFULL, A PHD STUDENT AT MIT,
utt_0001 utt 3.12 7.63 -X AND I WILL BE PRESENTING OUR WORK WHAT YOU CAN LEARN BY STARING AT A BLANK WALL.
utt_0002 utt 8.68 16.37 -X CONSIDER A SCENARIO WHERE YOU ARE INTERESTED IN KNOWING ABOUT THE NUMBER OF PEOPLE OR THEIR ACTIVITY IN THE HIDDEN SCENE.
utt_0004 utt 16.37 21.75 -X FROM OUTSIDE THE ROOM, ALL YOU SEE IS A BLANK WALL INSIDE THE ROOM.
utt_0005 utt 21.75 26.13 -X LOOKING AT THE OBSERVED WALL, IT APPEARS TO BE STATIC TO THE NAKED EYE,
utt_0006 utt 26.13 28.63 -X EVEN THOUGH PEOPLE MIGHT BE MOVING IN THE HIDDEN SCENE.
utt_0007 utt 29.23 43.63 -X IT MIGHT APPEAR THAT THIS TASK IS IMPOSSIBLE AS WE DO NOT SEE ANY CONVINCING SIGNAL, BUT PROCESSING THE VIDEO REVEALS EXTREMELY SMALL VARIATION WHICH CORRELATES WITH THE MOTION IN THE HIDDEN SCENE.
utt_0009 utt 43.63 48.47 -X WE CAN SEE SUBTLE IMPERCEPTIBLE ILLUMINATION EFFECTS CAUSED BY HUMAN MOTION ON THE WALL.
utt_0010 utt 48.88 53.30 -X WHILE THIS LOW INTENSITY SIGNAL IS NOT APPARENT IN THE ORIGINAL OBSERVATION,
utt_0011 utt 53.30 56.53 -X IT CAN BE USED TO INFER INFORMATION ABOUT THE HIDDEN SCENE.
utt_0012 utt 59.73 63.60 -X IN OUR WORK, WE TAKE AS INPUT THE VIDEO OF A BLANK WALL.
utt_0013 utt 64.05 72.82 -X WE EXTRACT THIS SUBTLE IMPERCEPTIBLE SIGNAL AND PERFORM CLASSIFICATION OF THE NUMBER OF PEOPLE AND THEIR ACTIVITY WITHOUT ANY SCENE-SPECIFIC KNOWLEDGE.
utt_0015 utt 75.99 81.53 -X EXISTING NON-LINE-OF-SIGHT METHODS CAN BE CLASSIFIED AS ACTIVE OR PASSIVE METHODS.
utt_0016 utt 82.87 86.55 -X ACTIVE METHODS INTERACT WITH THE ENVIRONMENT USING PROJECTORS,
utt_0017 utt 86.55 91.06 -X LASERS, WIFI SIGNALS, OR SOUND TO EXTRACT INFORMATION ABOUT THE HIDDEN SCENE.
utt_0018 utt 91.38 96.31 -X HOWEVER, INTERACTING WITH THE SCENE MAY NOT BE DESIRABLE IN SOME APPLICATIONS.
utt_0019 utt 96.53 101.56 -X THESE METHODS OFTEN RELY ON EXPENSIVE EQUIPMENT AND EXTENSIVE CALIBRATION.
utt_0020 utt 102.00 109.75 -X IN CONTRAST, PASSIVE METHODS TAKE ADVANTAGE OF THE KNOWLEDGE OF THE SCENE AND THE RESULTING LIGHTING CUES TO INFER ABOUT THE HIDDEN SCENE.
utt_0022 utt 110.07 114.84 -X HAVING LESS CONTROL OVER THE ENVIRONMENT MAKES THE PROBLEM CHALLENGING.
utt_0023 utt 114.84 119.42 -X MANY METHODS TAKE ADVANTAGE OF KNOWN OCCLUDERS SUCH AS CORNERS OR OBJECTS IN THE SCENE.
utt_0024 utt 119.67 122.52 -X THIS INTRODUCES STRUCTURE IN THE LIGHT TRANSPORT,
utt_0025 utt 122.52 126.07 -X ENABLING OBSERVATION OF CLEAN SIGNALS CORRESPONDING TO THE HIDDEN SCENE.
utt_0026 utt 126.39 130.62 -X BUT SOMETIMES KNOWLEDGE OF SUCH OCCLUDERS AND STRUCTURE IS NOT AVAILABLE.
utt_0027 utt 130.84 138.30 -X WE SHOW THAT EVEN IN SUCH CASES, THE INDIRECT LIGHTING CUES CAN BE USED TO INFER INFORMATION ABOUT THE ACTIVITY IN THE HIDDEN SCENE.
utt_0030 utt 142.23 146.04 -X IN OUR IMAGING SETUP, LET US CONSIDER A ROOM WITH TWO PEOPLE.
utt_0031 utt 146.68 150.97 -X THE AMBIENT LIGHT IN THE ROOM DOMINATES THE OBSERVED RADIANCE ON THE WALL.
utt_0032 utt 151.61 155.96 -X BUT, LIGHT TAKES INFINITELY MANY PATHS BEFORE REACHING THE OBSERVED WALL.
utt_0033 utt 156.57 159.77 -X FOR EXAMPLE, LIGHT COULD BOUNCE OFF A PERSON,
utt_0034 utt 159.77 166.75 -X THE BACK WALL, OR AN OBJECT BEFORE REACHING THE OBSERVED WALL, OR EVEN BE OBSTRUCTED BY A PERSON.
utt_0035 utt 167.00 170.75 -X THESE ARE JUST SOME EXAMPLES OF SECOND ORDER EFFECTS.
utt_0036 utt 171.83 185.24 -X ONE CAN IMAGINE LIGHT BOUNCING OFF DIFFERENT SURFACES MULTIPLE TIMES BEFORE REACHING THE OBSERVED WALL. THE MOVEMENT OF PEOPLE IN THE HIDDEN SCENE RESULTS IN CHANGE IN THESE SUBTLE IMPERCEPTIBLE ILLUMINATION EFFECTS.
utt_0039 utt 185.94 196.77 -X TO EXTRACT THIS SIGNAL OF INTEREST, WE START BY SUBTRACTING THE TEMPORAL MEAN OF THE OBSERVED VIDEO FROM EACH FRAME. THE RESIDUAL IS THEN MULTIPLIED BY A CONSTANT
utt_0041 utt 196.77 209.63 -X FACTOR TO ENHANCE THESE PATTERNS ON THE WALL FOR VISUALIZATION PURPOSE. THIS AMPLIFIED VIDEO SHOWS THE CHANGE IN THE OBSERVED PATTERN AS THE PERSON MOVES IN THE HIDDEN SCENE, BUT IT
utt_0043 utt 209.63 216.13 -X IS USUALLY DOMINATED BY CAMERA NOISE, RESULTING IN SIGNAL-TO-NOISE RATIO AS LOW AS minus thirty-five DECIBEL.
utt_0044 utt 226.81 239.34 -X TO REDUCE THE NOISE AND TO SUMMARIZE THE RELEVANT MOTION FEATURES, WE AVERAGE OVER THE HEIGHT OF THE AMPLIFIED VIDEO TO GET A twoD REPRESENTATION OF THE VIDEO, WHICH WE REFER TO AS THE HORIZONTAL
utt_0046 utt 239.34 245.06 -X SPACE-TIME PLOT. THIS SHOWS A SIGNAL CORRESPONDING TO THE MOTION ALONG THE WIDTH OF THE WALL.
utt_0047 utt 246.49 252.18 -X SIMILARLY, WE COMPUTE THE VERTICAL SPACE-TIME PLOTS BY AVERAGING OVER THE WIDTH OF THE VIDEO
utt_0048 utt 252.32 256.45 -X TO GET A SIGNAL CORRESPONDING TO MOTION ALONG THE HEIGHT OF THE WALL.
utt_0049 utt 256.89 261.28 -X WE USE THESE SPACE-TIME PLOTS TO TRAIN A NEURAL NETWORK FOR TWO TASKS
utt_0050 utt 261.66 267.11 -X CLASSIFYING THE NUMBER OF MOVING PEOPLE IN THE HIDDEN SCENE AND ACTIVITY RECOGNITION.
utt_0051 utt 267.58 275.65 -X FOR CLASSIFYING THE NUMBER OF PEOPLE, WE USE THE HORIZONTAL SPACE-TIME PLOT AS IT CAPTURES THE MOTION FEATURES ALONG THE WIDTH OF THE WALL.
utt_0053 utt 276.38 281.51 -X WE USE BOTH HORIZONTAL AND VERTICAL SPACE-TIME PLOTS FOR ACTIVITY RECOGNITION.
utt_0054 utt 281.98 286.95 -X DIFFERENT SIGNATURES CAN BE SEEN IN THESE SPACE-TIME PLOTS FOR THE DIFFERENT ACTIVITIES.
utt_0055 utt 287.87 300.23 -X FOR CLASSIFYING THE NUMBER OF PEOPLE, WE USE A FIVE-LAYER CONVOLUTIONAL FEATURE EXTRACTOR TO COMPUTE A ONE-DIMENSIONAL TEMPORAL SUMMARY. THIS TEMPORAL SUMMARY IS POOLED OVER TIME
utt_0057 utt 300.23 308.04 -X AND FED TO A FULLY CONNECTED NETWORK FOR CLASSIFYING BETWEEN ZERO, ONE, AND TWO PEOPLE.
utt_0058 utt 308.04 311.85 -X WE USE A SIMILAR MODEL FOR ACTIVITY RECOGNITION.
utt_0059 utt 311.85 316.58 -X SINCE WE HAVE ACTIVITIES WHICH INCLUDE MOVEMENT ALONG HORIZONTAL AND VERTICAL DIMENSIONS,
utt_0060 utt 316.61 330.18 -X WE USE BOTH HORIZONTAL AND VERTICAL SPACE-TIME PLOTS AS INPUT. WE HAVE INDIVIDUAL CONVOLUTIONAL BRANCHES TO COMPUTE THE oneD TEMPORAL SUMMARY FOR EACH OF THE SPACE-TIME PLOTS. A SMALL FULLY
utt_0062 utt 330.18 336.33 -X CONNECTED NETWORK THEN USES THE CONCATENATION OF THESE TWO SUMMARIES TO PREDICT THE ACTIVITY.
utt_0063 utt 336.67 342.82 -X THE ACTIVITIES INCLUDE CROUCHING, WAVING HANDS, JUMPING, WALKING, AND NO ACTIVITY.
utt_0064 utt 343.72 357.19 -X BOTH MODELS ARE TRAINED ON twelve HOURS WORTH OF DATA FROM twenty DIFFERENT INDOOR SCENES COLLECTED IN OFFICES, CONFERENCE ROOMS, AND PUBLIC SPACES. THE METHOD WAS TESTED OVER seventeen SECOND TEMPORAL WINDOWS
utt_0066 utt 357.19 364.68 -X ON FIVE HELD-OUT TEST SCENES. WE ACHIEVED ninety-four point four% ACCURACY FOR CLASSIFYING THE NUMBER OF PEOPLE,
utt_0067 utt 366.05 369.70 -X AND ninety-three point seven% PERCENT ACCURACY FOR THE ACTIVITY RECOGNITION TASK.
utt_0068 utt 370.47 374.51 -X WE ALSO TESTED SHORTER WINDOWS OF four AND eight SECONDS.
utt_0069 utt 374.73 380.97 -X INFERENCE OVER THE SHORTER DURATIONS LED TO MODEST DROP IN ACCURACY OF OUR METHOD.
utt_0070 utt 380.97 384.94 -X FURTHER ANALYSIS SUCH AS CONFUSION MATRICES CAN BE FOUND IN THE PAPER.
utt_0071 utt 385.67 394.31 -X IN ADDITION TO THE OFFLINE TESTING, WE PACKAGED OUR CAPTURE AND PREDICTION SYSTEM INTO A PORTABLE SETUP FOR REAL-TIME DEPLOYMENT.
utt_0073 utt 395.05 398.22 -X HERE IS OUR IMAGING SETUP IN AN UNSEEN ROOM.
utt_0074 utt 398.41 403.24 -X THE CAMERA OBSERVES THE BLANK WALL WHILE A PERSON MOVES IN THE HIDDEN SCENE.
utt_0075 utt 404.01 408.65 -X THE REAL-TIME SYSTEM SHOWS THE OBSERVED WALL, THE AMPLIFIED VIDEO,
utt_0076 utt 408.65 420.35 -X AND OPTIONALLY A GROUND TRUTH VIDEO. THE CORRESPONDING SPACE-TIME PLOTS ARE SHOWN ALONG WITH REAL-TIME CLASS PREDICTIONS USING OUR TRAIN MODEL. THE GROUND TRUTH VIDEO IS RECORDED
utt_0078 utt 420.35 425.93 -X AND VISUALIZED JUST FOR VISUAL REFERENCE AND WOULD BE UNAVAILABLE DURING AN ACTUAL DEPLOYMENT
utt_0079 utt 429.00 442.45 -X THIS IS THE REAL-TIME DEMO FOR THE ACTIVITY RECOGNITION WITH THE SAME LAYOUT. WE VISUALIZE BOTH HORIZONTAL AND VERTICAL SPACE-TIME PLOTS WHICH ARE INPUT TO THE MODEL. THE SYSTEM DETECTS
utt_0081 utt 442.45 447.53 -X THE WALKING, AND NOW AS THE PERSON CROUCHES THE SYSTEM IS QUICK TO CHANGE THE PREDICTION.
utt_0082 utt 453.90 457.20 -X EVEN THOUGH OUR MODEL WAS TRAINED ON INDOOR SCENES,
utt_0083 utt 457.20 462.29 -X OUR REAL-TIME SYSTEM ALSO WORKS IN UNSEEN OUTDOOR SCENES FOR BOTH TASKS.
utt_0084 utt 464.01 473.55 -X NOTE THAT IN THIS PARTICULAR TEST SCENE, THERE WAS NO WALL BETWEEN THE OBSERVING CAMERA AND THE HIDDEN SCENE. BUT, THE CAMERA ONLY OBSERVED THE BLANK WALL.
utt_0086 utt 474.48 480.21 -X THIS REAL-TIME APPLICATION RUNS ON A CONSUMER LAPTOP PERFORMING ACQUISITION OF THE DATA,
utt_0087 utt 480.21 492.47 -X PRE-PROCESSING OF THE VIDEO TO SPACE-TIME PLOTS, INFERENCE, AND VISUALIZATION. WE HAVE TESTED THE SYSTEM IN MULTIPLE INDOOR AND OUTDOOR SCENES AND OBSERVED COMPARABLE RESULTS.
utt_0089 utt 495.09 507.65 -X HERE WE PRESENT THE ACTIVITY RECOGNITION TASK IN AN OUTDOOR SETUP. NOTE THAT THIS SETTING IS SOMEWHAT FAVORABLE TO OUR METHOD AS THE PERSON IS WEARING CLOTHES THAT HAVE HIGH CONTRAST AGAINST THE BACKGROUND
utt_0092 utt 507.65 513.43 -X AND IS WALKING CLOSE TO THE WALL. THIS RESULTS IN CLEAN SIGNAL IN THE SPACE-TIME PLOT.
utt_0093 utt 518.99 522.39 -X TO BETTER UNDERSTAND THE EFFECT OF SUCH PARAMETERS,
utt_0094 utt 522.67 529.40 -X WE FORMULATED AN IDEALIZED MODEL OF THE SETUP TO DERIVE A FORMULA FOR THE SIGNAL-TO-NOISE RATIO.
utt_0095 utt 530.61 543.16 -X THE SNR IS INVERSELY PROPORTIONAL TO DISTANCE BUT PROPORTIONAL TO THE AMBIENT LIGHTING AND THE RELATIVE CONTRAST BETWEEN THE BACKGROUND AND THE SUBJECT. THE DERIVATION CAN BE FOUND IN THE PAPER.
utt_0097 utt 544.08 556.97 -X TO VALIDATE THE THEORETICAL TREND, WE RECORDED THE SNR AS A SUBJECT PERFORMED THE FOUR ACTIVITIES AT DIFFERENT DISTANCES WITH THREE DIFFERENT LIGHTING INTENSITIES. WE FIND THAT THE EMPIRICAL
utt_0099 utt 556.97 570.49 -X SNR FOLLOWS THE SLOPE PREDICTED BY OUR THEORETICAL MODEL. THE SMALL DEVIATIONS CAN BE ATTRIBUTED TO HIGHER ORDER LIGHTING BOUNCES IN AN INDOOR SCENE WHICH IS NOT ACCOUNTED IN OUR THEORETICAL MODEL.
utt_0101 utt 572.79 583.90 -X ASIDE FROM THE SIGNAL QUALITY, THE RELATIVE MOTION OF TWO PEOPLE CAN ALSO IMPACT THE PERFORMANCE OF OUR METHOD. FOR EXAMPLE, TWO PEOPLE WALKING TOGETHER IN LOCKSTEP
utt_0103 utt 583.90 590.62 -X MIGHT BE INDISTINGUISHABLE FROM JUST ONE PERSON. TO STUDY THE IMPACT OF DIFFERENT MOTION PATTERNS,
utt_0104 utt 590.62 596.89 -X WE RENDERED A SYNTHETIC DATASET USING AN IDEALIZED twoD FLATLAND SETUP ILLUSTRATED HERE.
utt_0105 utt 597.52 602.39 -X THE TWO PERSONS MOVE IN A SINUSOIDAL PATTERN WITH CONTROLLED AMPLITUDE,
utt_0106 utt 602.39 609.08 -X PHASE, AND FREQUENCY. OUR MODEL TRAIN WITH REAL DATA WORKS WELL ON THESE SYNTHETIC SAMPLES.
utt_0107 utt 610.49 614.30 -X BASED ON THE PERFORMANCE OF OUR MODEL ON THE SYNTHETIC DATASET,
utt_0108 utt 614.33 617.85 -X WE FIND THAT LARGE RELATIVE AMPLITUDE IS PREFERRED.
utt_0109 utt 618.33 623.87 -X HAVING CONTRAST BETWEEN THE MOTIONS IS MORE VALUABLE THAN SIMPLY HAVING LARGE MOTIONS.
utt_0110 utt 624.66 634.97 -X OUT OF PHASE MOTION IS PREFERRED AS THE SIGNAL CAN BE MISTAKEN FOR A ONE PERSON SCENARIO WHEN THE TWO PEOPLE ARE ALWAYS MOVING IN THE SAME DIRECTION.
utt_0112 utt 635.54 648.70 -X IN OUR WORK, WE EXPLORED AN EXTREME SCENARIO FOR PASSIVE NON-LINE OF SIGHT IMAGING WITH MINIMAL SCENE-SPECIFIC KNOWLEDGE. IN PARTICULAR, WE DON'T MAKE ANY ASSUMPTIONS ABOUT SCENE GEOMETRY
utt_0114 utt 648.73 663.68 -X SUCH AS OCCLUDERS OR PINHOLES. YET, WE SHOW THAT IT IS POSSIBLE TO USE EVEN THIS NOISY UNSTRUCTURED SIGNAL TO PERFORM MEANINGFUL INFERENCE ABOUT THE HIDDEN SCENE. THANK YOU.
