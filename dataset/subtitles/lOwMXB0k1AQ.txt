utt_0000 utt 0.84 8.75 -X HELLO, MY NAME IS GEORG KOHL AND IN THIS VIDEO I'M GOING TO TALK TO YOU ABOUT HOW WE CAN LEARN SIMILARITY METRICS FOR NUMERICAL SIMULATION METHODS.
utt_0002 utt 9.45 16.40 -X I'VE BEEN WORKING ON THIS TOGETHER WITH KIWON UM AND NILS THUEREY HERE AT THE TECHNICAL UNIVERSITY OF MUNICH.
utt_0003 utt 16.40 27.99 -X FIRST, A QUICK OVERVIEW OVER THE MOTIVATION AND THE MAIN TASK WE'RE TRYING TO SOLVE. ESSENTIALLY, WE ARE INTERESTED IN SIMILARITY ASSESSMENT OF twoD SIMULATION DATA FROM PARTIAL DIFFERENTIAL EQUATIONS OR PDES.
utt_0006 utt 27.99 31.09 -X YOU CAN SEE A FEW EXAMPLE SEQUENCES DOWN HERE.
utt_0007 utt 32.30 44.66 -X THE MAIN GOAL IS TO BRING THESE SEQUENCES INTO A SENSIBLE ORDERING THAT YOU CAN SEE ON THE RIGHT. THE SIMPLEST IDEA OF JUST LOOKING AT THE DATA AND ARRANGING IT ACCORDINGLY DOES NOT REALLY WORK IN ALL CASES.
utt_0010 utt 44.66 54.93 -X IN THE FIRST EXAMPLE IT MIGHT WORK, BUT FOR A MORE COMPLEX CASE FOR EXAMPLE THE THIRD ONE WE HAVE HERE, THE VISUAL COMPLEXITY IS TOO HIGH AND IT'S NOT REALLY POSSIBLE ANYMORE.
utt_0013 utt 55.50 67.28 -X INSTEAD, ONE COULD USE AN Ltwo OR AN Lone DISTANCE TO COMPUTE DISTANCES BETWEEN THE SIMULATION FRAMES AND THEN ORDER THEM ACCORDINGLY. BUT THE MAIN ISSUE WITH
utt_0015 utt 67.28 75.86 -X THAT IS THAT STRUCTURES AND PATTERNS ARE ENTIRELY IGNORED BY THESE METRICS BECAUSE THEY ONLY OPERATE ON A SINGLE PIXEL-WISE BASIS.
utt_0017 utt 75.86 84.34 -X INSTEAD, WE PROPOSE TO USE CONVOLUTIONAL NEURAL NETWORKS BECAUSE THEY CAN RECOGNIZE THESE SPATIAL CONTEXT AND ARE MUCH MORE SUITABLE FOR A SIMILARITY EVALUATION.
utt_0020 utt 85.94 100.85 -X ALSO, A METRIC HAS TO FOLLOW CERTAIN MATHEMATICAL PROPERTIES WHICH WE WILL CONSIDER HERE AS WELL. DOWN HERE YOU CAN SEE ANOTHER SEQUENCE EXAMPLE, THIS TIME A VELOCITY FIELD FROM A SMOKE SIMULATION AND YOU RECOGNIZE THAT THE ORDERING ON
utt_0023 utt 100.85 105.88 -X THE RIGHT CAN ALSO BE EXPRESSED AS A SET OF DISTANCES BETWEEN THE INDIVIDUAL FRAMES.
utt_0024 utt 105.88 116.15 -X SO THIS MEANS THAT FRAMES THAT ARE REALLY SIMILAR GET A SMALL DISTANCE OF zero point one, FRAMES WHICH ARE LESS SIMILAR zero point two AND SO ON, UNTIL WE HAVE EVERY POSSIBLE PAIR LABELED.
utt_0027 utt 117.62 125.11 -X SO HOW CAN WE CREATE A MODEL THAT PREDICTS THESE DISTANCES FOR US? THE FIRST BUILDING BLOCK IS A NUMERICAL SIMULATION.
utt_0029 utt 125.17 133.97 -X SO ESSENTIALLY, A NUMERICAL SIMULATION USES A SET OF INITIAL CONDITIONS AND TRANSFORMS IT INTO AN OUTPUT VIA A PDE SOLVER.
utt_0031 utt 133.97 139.61 -X HERE, WE ARE INTERESTED IN A SEQUENCE OF DATA SO WE HAVE TO CHANGE A SINGLE INITIAL CONDITION IN THIS CASE P_I
utt_0033 utt 140.18 143.09 -X IN INCREASING STEPS DENOTED BY DELTA_I HERE,
utt_0034 utt 143.57 146.10 -X TO GET THE DATA SEQUENCE SHOWN IN THE MIDDLE.
utt_0035 utt 146.55 156.09 -X THESE INITIAL CONDITIONS ALSO DEFINE OUR GROUND TRUTH DISTANCES, WHERE A HIGHER CHANGE IN THE INITIAL CONDITION MEANS THE GROUND TRUTH DISTANCE IS GOING TO BE HIGHER AS WELL.
utt_0038 utt 157.52 160.15 -X THE NEXT BUILDING BLOCK IS LEARNING.
utt_0039 utt 160.47 171.24 -X FIRST, WE HAVE TO SPLIT UP OUR DATA SEQUENCE INTO EVERY POSSIBLE PAIR, THAT CAN BE PROCESSED BY OUR MODEL. OUR MODEL YOU IN YELLOW HERE USES SHARED
utt_0041 utt 171.24 175.94 -X WEIGHTS, SO A SIAMESE ARCHITECTURE AND CONSISTS OF TWO FEATURE EXTRACTORS
utt_0042 utt 175.96 180.34 -X DENOTED AS CNN HERE, THAT EXTRACTS FEATURES FROM OUR TWO INPUTS.
utt_0043 utt 180.47 186.33 -X THESE FEATURES ARE THEN NORMALIZED AND CAN BE COMPARED IN THE LATENT SPACE TO FORM OUR DISTANCE PREDICTION OF THE NETWORK.
utt_0045 utt 187.06 189.59 -X OF COURSE, THIS NETWORK IS NOT PERFECT RIGHT FROM THE START,
utt_0046 utt 189.62 201.72 -X SO WE HAVE TO INTRODUCE SOME OPTIMIZATION AND THIS HAPPENS VIA A LOSS BETWEEN THE GROUND TRUTH DISTANCES AND THE PREDICTED DISTANCE BY OUR NETWORK THAT IS THEN USED, FOR EXAMPLE BY AN ADAM OPTIMIZER, TO CHANGE THE WEIGHTS OF OUR NETWORK.
utt_0049 utt 202.16 209.59 -X THE FINAL BLOCK IS THE EVALUATION TO DETERMINE IF A METRIC THAT WAS LEARNED ACTUALLY PRODUCES SENSIBLE RESULTS.
utt_0051 utt 210.61 213.10 -X THIS IS DONE VIA THE SPEARMAN'S RANKING CORRELATION
utt_0052 utt 213.27 216.99 -X THAT TAKES THE GROUND TRUTH DISTANCE AND THE LEARNED DISTANCE
utt_0053 utt 217.27 221.50 -X AND COMPUTES THE LINEAR DEPENDENCY BETWEEN THOSE.
utt_0054 utt 221.50 223.48 -X SO A HIGHER VALUE MEANS
utt_0055 utt 223.57 229.31 -X THE LEARNED DISTANCES REPRESENT THE GROUND TRUTH MORE ACCURATELY.
utt_0056 utt 229.31 240.41 -X A QUICK OVERVIEW OF OUR RESULTS: ON THE LEFT HERE YOU CAN SEE A SINGLE EXAMPLE COMPARISON IN THE MIDDLE THERE'S THE REFERENCE PLUME AND TWO VARIANTS (A) AND (B) ON THE LEFT AND ON THE RIGHT, AND VISUALLY AND ALSO FROM THE GROUND TRUTH
utt_0059 utt 240.47 255.13 -X PLUME (A) LOOKS MORE SIMILAR TO THE REFERENCE. OUR METRIC RECOGNIZES THIS VERY WELL AND YOU CAN SEE IT IN THE DISTANCE PLOT, THAT THE DISTANCE MATCHES WITH THE GROUND TRUTH. FOR AN Ltwo DISTANCE THE OPPOSITE IS TRUE, SO IT EXTRACTS
utt_0062 utt 255.13 257.95 -X DISTANCES IN A WAY THAT ARE NOT REALLY SUITABLE AS YOU CAN SEE.
utt_0063 utt 258.71 272.16 -X ALSO, ON OUR COMBINED TEST DATA, A CORRELATION EVALUATION SHOWS THAT WE ARE CONSISTENTLY ACHIEVING HIGHER CORRELATION VALUES COMPARED TO SHALLOW DISTANCES LIKE Ltwo, A STRUCTURE SIMILARITY OR EVEN LIKE
utt_0066 utt 272.16 274.43 -X LEARNED IMAGE-BASED DISTANCES FOR EXAMPLE LPIPS.
utt_0067 utt 274.90 277.18 -X THIS ALSO BRINGS US TO THE RELATED WORKS.
utt_0068 utt 277.18 290.97 -X THERE ARE THREE MAIN CATEGORIES OF METRICS THAT ARE APPLICABLE FOR SIMULATION DATA: FIRST WE HAVE VECTOR SPACE METRICS WE CAN ALSO DENOTE THESE AS SHALLOW METRICS BECAUSE THEY ARE NOT CNN BASED. AND THESE INCLUDE
utt_0071 utt 290.97 305.02 -X L-P NORMS AS DISCUSSED BEFORE, A PEAK SIGNAL-TO-NOISE RATIO OR THE STRUCTURAL SIMILARITY INDEX. FURTHERMORE, WE CAN EVALUATE SIMULATION DATA VIA USER STUDIES SO ESSENTIALLY SHOWING THE DATA TO A BUNCH OF HUMANS TO DETERMINE THE SIMILARITY.
utt_0074 utt 305.02 311.58 -X THIS HAS BEEN DONE FOR EXAMPLE BY UM AND CO-WORKERS FOR LIQUID SIMULATIONS AND NON OSCILLATORY DISCRETIZATION SCHEMES.
utt_0076 utt 313.08 327.29 -X AS YOU CAN IMAGINE THIS EVALUATION IS QUITE COSTLY AND ALSO TAKES A LOT OF TIME AND IT'S NOT REALLY SUITABLE OVERALL. THE THIRD CATEGORY ARE LEARNED IMAGE BASED METRICS USING CNNS, THERE ARE QUITE A FEW OF THEM, HERE IS JUST LISTED FOR
utt_0079 utt 327.29 331.85 -X EXAMPLE LPIPS. AND THEY ARE NOT REALLY OPTIMAL EITHER BECAUSE THE DATA DISTRIBUTION
utt_0080 utt 332.22 336.48 -X OF IMAGES IS REALLY DIFFERENT FROM THE ONES THAT WE ARE INTERESTED IN.
utt_0081 utt 338.24 342.18 -X NOW, A MORE CLOSER LOOK TO THE DATA GENERATION.
utt_0082 utt 342.18 349.79 -X WE START WITH A TIME-DEPENDENT MOTION-BASED PDE THAT YOU CAN SEE HERE IN THE CENTER THAT COMPUTES DIFFERENT TIME STEPS VIA A SOLVER.
utt_0084 utt 350.11 354.66 -X THIS SOLVER IS INITIALIZED WITH CERTAIN INITIAL CONDITIONS P AND PRODUCES AN OUTPUT O.
utt_0085 utt 355.68 361.57 -X WE CAN THEN VARY A SINGLE INITIAL CONDITION P_I IN INCREMENTAL STEPS DENOTED BY DELTA_I HERE,
utt_0086 utt 362.68 367.65 -X TO GET MULTIPLE RUNS OF THE SAME SIMULATION WHERE A SINGLE THING CHANGED,
utt_0087 utt 367.65 370.34 -X SO THAT THE OUTPUTS ARE GOING TO CHANGE IN THE SAME WAY.
utt_0088 utt 370.46 378.34 -X THIS MEANS A SMALLER CHANGE IN THE SIMULATION INPUT RESULTS ALSO IN A SMALLER CHANGE IN THE OUTPUT AND ALSO THE OTHER WAY AROUND.
utt_0090 utt 379.71 394.37 -X THIS IS NOT ENOUGH YET BECAUSE WITH THIS APPROACH THE RESULTING DATA WOULD BE TOO SIMPLE. SO AN Ltwo DISTANCE WOULD ALREADY BE QUITE REASONABLE TO ASSESS THE SIMILARITY, AND AS A RESULT OUR MODEL WOULD ESSENTIALLY LEARN THIS BUT IT'S NOT REALLY OPTIMAL.
utt_0094 utt 394.91 396.32 -X SO WE ALSO INTRODUCE
utt_0095 utt 396.35 404.99 -X A NOISE THAT IS DIFFERENTLY SEEDED FOR EVERY TIME STEP OF OUR SOLVER AND THE VARIANCE OF THE NOISE CONTROLS THE DIFFICULTY OF THE RESULTING DATA.
utt_0097 utt 404.99 417.28 -X SO, HIGHER NOISE VARIANCE MEANS THE DATA IS MORE DIFFICULT AND THE NETWORK IS GOING TO LEARN BETTER BUT OF COURSE ONLY UNTIL A CERTAIN POINT BECAUSE THEN THE DATA ESSENTIALLY JUST BECOMES NOISE AND THE NETWORK IS NOT ABLE TO EXTRACT ANY USEFUL INFORMATION ANYMORE.
utt_0101 utt 418.53 421.73 -X WITH THIS APPROACH WE CREATED A VARIETY OF TRAINING DATA,
utt_0102 utt 422.24 429.99 -X FOR EXAMPLE A GRID-BASED SMOKE PLUME YOU CAN SEE ON TOP LEFT HERE WITH THE DENSITY FIELD, PRESSURE FIELD, AND A VELOCITY FIELD.
utt_0104 utt 430.11 439.65 -X IN THIS CASE, THE VARIED INITIAL CONDITIONS WERE FOR EXAMPLE THE POSITION AND ORIENTATION OF A DOWNWARDS DIRECTED FORCE FIELD, THE SIZE AND POSITION OF OUR SOURCE,
utt_0106 utt 439.68 443.11 -X OR THE DIRECTION OF THE BUOYANCY EXPERIENCED BY THE SMOKE PLUME.
utt_0107 utt 443.33 454.72 -X ON THE TOP RIGHT YOU CAN SEE OUR LIQUID DATA SET COMPUTED VIA FLUID IMPLICIT PARTICLES THAT CONSISTS OF A BRAKING DAM WHERE A LIQUID BLOB IS DROPPED INTO A POOL.
utt_0109 utt 455.33 469.99 -X YOU CAN SEE THE FLAG FIELD AT THE TOP THAT CORRESPONDS TO THE AREA WHERE LIQUID IS AND WHERE THERE ISN'T, IN THE MIDDLE YOU CAN SEE THE LEVEL SET, AND AT THE VERY BOTTOM YOU CAN SEE THE VELOCITY OF THE LIQUID SIMULATION. IN THIS CASE THE POSITION
utt_0112 utt 470.69 474.60 -X AND SIZE OF THE DROP ARE VARIED AND ALSO THE DIRECTION OF THE GRAVITY
utt_0113 utt 475.36 478.44 -X FINALLY, AT THE BOTTOM YOU CAN SEE TWO ONE-DIMENSIONAL PDES:
utt_0114 utt 478.44 486.15 -X THE ADVECTION-DIFFUSION TRANSPORT AND THE BURGER'S EQUATION THAT IN THIS CASE ARE STACKED OVER TIME TO FORM THE twoD OUTPUTS YOU CAN SEE HERE.
utt_0116 utt 486.15 493.38 -X IN THESE CASES WE USED MULTIPLE LAYERED SINE FUNCTIONS TO INITIALIZE THE FORCING TERMS AND THEY CAN BE VARIED INDIVIDUALLY.
utt_0118 utt 495.23 502.53 -X FOR OUR TEST DATA, WE USED ANOTHER LIQUID SIMULATION BUT THIS TIME WE ADDED NOISE TO THE BACKGROUND OF THE SIMULATION.
utt_0120 utt 503.11 513.57 -X SECOND, WE HAVE THE ADVECTION DIFFUSION TRANSPORT AGAIN, BUT THIS TIME WE ADDED THE NOISE TO THE DENSITY FIELD INSTEAD OF THE VELOCITY FIELD RESULTING IN A QUITE DIFFERENT DATA DISTRIBUTION.
utt_0122 utt 513.57 517.64 -X FOR THE REMAINING TEST SETS, WE USED A DIFFERENT APPROACH TO GENERATED THE DATA.
utt_0123 utt 517.64 530.38 -X ESSENTIALLY, THESE ARE JUST TEMPORAL FRAMES OF A LONGER SEQUENCE, FOR EXAMPLE THE SHAPE DATA OF MOVING SHAPES IN LINEAR LINES AND FOR THE VIDEO DATA JUST A SIMPLE VIDEO THAT CHANGES OVER TIME.
utt_0126 utt 530.38 536.68 -X THE GOAL OF THE NETWORK HERE IS TO INFER THE CORRECT ORDERING OF THE FRAMES IN TIME.
utt_0127 utt 537.76 543.24 -X FINALLY, WE HAVE THE TID two thousand and thirteen DATA SET THAT CONSISTS OF SIMPLE IMAGES
utt_0128 utt 543.36 548.04 -X THAT ARE DISTORTED WITH VARIOUS DISTORTIONS LIKE ADDED NOISE, COMPRESSION,
utt_0129 utt 548.04 550.66 -X OR A COLOR QUANTIZATION AS YOU CAN SEE AT THE BOTTOM HERE.
utt_0130 utt 552.36 557.10 -X SO HOW CAN WE LEARN A MODEL THAT ACTUALLY COMPUTES THESE DISTANCES FOR US?
utt_0131 utt 557.35 560.65 -X AS MENTIONED BEFORE, WE START WITH A SIAMESE ARCHITECTURE,
utt_0132 utt 560.65 564.65 -X SO SHARED WEIGHTS, THAT CONSISTS OF SEVERAL CONVOLUTION + RELU LAYERS.
utt_0133 utt 566.31 573.32 -X THE GOAL OF THIS BASE NETWORK IS TO EXTRACT SEVERAL FEATURES FROM THE INPUTS, FOR EXAMPLE EDGES OR CORNERS OR CERTAIN SHAPES
utt_0135 utt 574.57 584.94 -X THAT CAN THEN BE PROCESSED LATER ON. IT IS POSSIBLE TO USE A VISION BASED NETWORK HERE FOR EXAMPLE ALEXNET OR VGG BUT AS THEY ARE USING A DIFFERENT DATA DISTRIBUTION,
utt_0137 utt 584.94 588.68 -X WE FOUND THAT TRAINING A SPECIALIZED MODEL FOR THIS PURPOSE WORKS A LOT BETTER.
utt_0138 utt 589.19 594.54 -X SO, DOWN HERE YOU CAN SEE FROM THE INPUTS WE GET TWO SETS OF THIRD ORDER TENSORS AS THE FEATURE MAPS.
utt_0139 utt 594.85 597.32 -X THE NEXT STEP IS NORMALIZING THESE FEATURE MAPS,
utt_0140 utt 597.32 602.47 -X BECAUSE RIGHT NOW THEY HAVE A VERY DIFFERENT MAGNITUDE AND CANNOT BE COMPARED EQUALLY.
utt_0141 utt 602.76 614.35 -X ONE IDEA WOULD BE TO STACK THESE FEATURES INTO A LONG VECTOR AND PERFORM A UNIT LENGTH NORMALIZATION ON THIS. THIS RESULTS IN A COSINE DISTANCE SO ESSENTIALLY JUST AN ANGLE COMPARISON WHERE ANY KIND OF LENGTH IS LOST.
utt_0144 utt 614.73 618.84 -X INSTEAD, WE PROPOSE TO USE THE ENTIRE TRAINING SET AND COMPUTE THE
utt_0145 utt 619.11 628.40 -X DISTRIBUTIONS OF EVERY FEATURE MAP THAT CAN THEN BE USED VIA THE MEAN AND STANDARD DEVIATION, TO TRANSFORM EVERY FEATURE MAP TO A STANDARD NORMAL DISTRIBUTION.
utt_0147 utt 628.62 632.81 -X THIS RESULTS IN A REASONABLE LENGTH FOR EVERY FEATURE VECTOR,
utt_0148 utt 632.81 638.92 -X BUT THE ANGLE CAN BE COMPARED AS WELL. MEANING THAT WE HAVE MORE INFORMATION THAN JUST A SIMPLE UNIT LENGTH NORMALIZATION, TO COMPARE LATER ON.
utt_0150 utt 638.92 650.38 -X THE CORE OF THE METRIC IS THE LATENT SPACE DIFFERENCE WHERE WE ARE ACTUALLY COMPARING THESE SETS OF THIRD ORDER TENSORS TO FORM A SINGLE SET OF THIRD ORDER TENSORS IN THIS CASE.
utt_0152 utt 651.34 662.67 -X WE FOUND THAT THIS OPERATION HAS TO BE A METRIC WITH RESPECT TO THE LATENT SPACE, MEANING THAT WE CAN FOR EXAMPLE CHOOSE AN Lone DISTANCE OR AN Ltwo DISTANCE IN THIS CASE HERE. WE ALSO TRIED MORE
utt_0155 utt 662.67 667.76 -X INTRICATE FUNCTIONS WHERE CERTAIN OPERATIONS ARE LEARNED, BUT WE FOUND THAT THIS WORKS BEST.
utt_0156 utt 669.67 674.86 -X FINALLY, WE HAVE TO COMPRESS THESE DIFFERENCE MAPS INTO A SINGLE SCALAR RESULT.
utt_0157 utt 675.40 678.64 -X THIS IS PERFORMED BY THE FOLLOWING OPERATIONS SHOWN IN GREEN HERE.
utt_0158 utt 679.79 682.57 -X AND THE FIRST OPERATION IS A CHANNEL AGGREGATION,
utt_0159 utt 682.57 689.20 -X THEN WE HAVE A SINGLE LEARNED WEIGHT FOR EVERY FEATURE MAP AND PERFORM A WEIGHTED AVERAGE TO COMPRESS THE FEATURES ALONG THE CHANNEL DIMENSION.
utt_0161 utt 689.20 693.42 -X FOR THE SPATIAL AND THE LAYER AGGREGATION, USING SIMPLE SUMS AND AVERAGES,
utt_0162 utt 693.67 699.31 -X TO COMPRESS THE DIFFERENCES DOWN TO A SINGLE SCALAR VALUE.
utt_0163 utt 699.31 703.95 -X TO TRAIN THIS NETWORK WE ARE COMPARING THE GROUND TRUTH DISTANCES C AND THE PREDICTED DISTANCES D.
utt_0164 utt 704.33 712.94 -X OUR LOSS TERM CONSISTS OF TWO PARTS: THE MEAN SQUARED ERROR ON THE LEFT THAT JUST MINIMIZES THE DISTANCE DEVIATION OF BOTH DISTRIBUTIONS DIRECTLY.
utt_0166 utt 713.96 725.55 -X AND THIS IS VERY IMPORTANT IN THE BEGINNING OF THE TRAINING WHERE THE DISTANCES HAVE A QUITE DIFFERENT MAGNITUDE, MEANING IT HAS TO BE PULLED TOWARDS THE CORRECT VALUES FIRST.
utt_0169 utt 726.00 735.79 -X THEN WE HAVE THE SECOND TERM, THIS IS AN INVERTED CORRELATION TERM THAT MAXIMIZES THE LINEAR DISTANCE RELATIONSHIP BETWEEN BOTH DISTRIBUTIONS AND IT'S MAINLY IMPORTANT FOR THE END OF THE TRAINING,
utt_0172 utt 735.79 739.76 -X WHERE THE ORDER OF THE DIFFERENT PREDICTIONS ARE SHUFFLED AROUND.
utt_0173 utt 740.88 745.71 -X WITH OUR METRIC WE CAN ACHIEVE QUITE GOOD RESULTS AS YOU CAN SEE HERE IN THIS TABLE.
utt_0174 utt 745.71 749.39 -X THESE ARE THE SPEARMAN'S CORRELATION VALUES THAT WE MENTIONED BEFORE
utt_0175 utt 749.90 753.52 -X OF GROUND TRUTH AGAINST PREDICTED DISTANCES, WHERE A HIGHER VALUE IS BETTER.
utt_0176 utt 753.52 758.07 -X THE GREEN VALUES IN THE TABLE ARE THE BEST METRIC, AND THE RED VALUES ARE THE WORST.
utt_0177 utt 758.25 762.93 -X AS YOU CAN SEE, SHALLOW METRICS LIKE Lone, Ltwo OR THE STRUCTURAL SIMILARITY
utt_0178 utt 762.99 765.78 -X DON'T REALLY WORK WELL ON MOST OF OUR DATASETS.
utt_0179 utt 766.57 772.37 -X A LEARNED IMAGE BASED MODEL PERFORMS REALLY WELL ON THE TID DATA AND THE VIDEO DATA THAT IS FAIRLY SIMILAR TO THE
utt_0181 utt 772.49 780.82 -X TRAINING DISTRIBUTION THAT LPIPS WAS EXPERIENCING, BUT YOU CAN SEE THAT FOR THE VERY DIFFERENT DATA DISTRIBUTION OF NUMERICAL SIMULATIONS THAT WE HAVE,
utt_0183 utt 780.82 782.77 -X OUT MODEL CONSISTENTLY OUTPERFORMS THE OTHERS.
utt_0184 utt 784.49 791.27 -X TO COME BACK TO THE INITIAL DATA WE HAVE HAD A LOOK AT THREE DIFFERENT REAL-WORLD DATA REPOSITORIES
utt_0186 utt 791.41 802.64 -X CONSISTING OF TRANSPORT FLOWS THAT ARE CAPTURED VIA A MULTIPLE VIEW RECONSTRUCTION THIS IS THE SCALARFLOW DATASET ON THE TOP LEFT. THEN WE HAVE MEASURED ATMOSPHERIC
utt_0188 utt 803.41 807.70 -X QUANTITIES FOR EXAMPLE TEMPERATURE OR GEOPOTENTIAL ON THE TOP RIGTH FROM WEATHERBENCH,
utt_0189 utt 807.82 815.96 -X AND TURBULENCE VELOCITIES COMPUTED VIA DIRECT NUMERICAL SIMULATION OR DNS FROM THE JOHNS HOPKINS TURBULENCE DATABASE AT THE BOTTOM HERE.
utt_0191 utt 816.24 823.73 -X IN THIS CASE, THE GOAL OF THE MODEL ALWAYS WAS TO INFERE A SPATIAL OR TEMPORAL ORDERING IN WHICH THE FRAMES WERE CREATED.
utt_0193 utt 825.14 828.18 -X FOR THESE DATASETS WE HAD SIX DIFFERENT INTERVAL SPACINGS,
utt_0194 utt 828.24 831.28 -X FOR EVERY DATA REPOSITORY WITH ABOUT two hundred SEQUENCES EACH.
utt_0195 utt 831.31 835.57 -X IN THE DIAGRAM ON THE RIGHT YOU CAN SEE THE MEAN AND STANDARD DEVIATION OF THE
utt_0196 utt 835.70 841.01 -X AVERAGED SPEARMAN CORRELATIONS OVER THE DIFFERENT INTERVAL SPACINGS.
utt_0197 utt 841.01 849.78 -X YOU CAN SEE THAT OUR METRIC ON THE FAR RIGHT OUTPERFORMS THE THREE OTHER MODELS BY CONSISTENTLY HAVING A HIGHER MEAN AND A LOWER STANDARD DEVIATION.
utt_0199 utt 849.78 858.42 -X IN THE FUTURE, OUR LEARNED METRIC OPENS UP THE POSSIBILITY TO QUITE A FEW INTERESTING RESEARCH DIRECTIONS.
utt_0200 utt 858.90 863.46 -X FIRST, WE CAN MORE ACCURATELY ASSESS THE SIMILARITY OF NEW SIMULATION METHODS
utt_0201 utt 863.76 871.38 -X TO DETERMINE THEIR PERFORMANCE, OR ALSO PARAMETER RECONSTRUCTIONS, OR GENERATIVE MODELS OF PHYSICAL SYSTEMS CAN BENEFIT FROM AN IMPROVED COMPARISON.
utt_0203 utt 871.63 876.50 -X FURTHERMORE, WE WOULD LIKE TO EXTEND OUR DATA TO THREE DIMENSIONS AND ALSO FURTHER PDES.
utt_0204 utt 876.66 879.99 -X FINALLY, WE WOULD ALSO LIKE TO INTRODUCE A MULTI-CHANNEL VERSION,
utt_0205 utt 879.99 882.87 -X FOR EXAMPLE FOR THE VELOCITY TURBULENCE DATA THAT WE SAW IN THE END.
utt_0206 utt 883.89 887.67 -X THAT'S GOING TO BE IT FROM ME AND THANK YOU VERY MUCH FOR YOUR ATTENTION.
utt_0207 utt 887.67 894.68 -X IF YOU'RE INTERESTED IN THIS TOPIC AND WANT TO LEARN MORE, YOU CAN JOIN OUR TWO LIVE SESSIONS THAT ARE COMING UP SOON FOR MORE QUESTIONS AND A DISCUSSION.
utt_0209 utt 895.06 900.02 -X AND IF YOU WANT TO TRY OUT THE MODEL FOR YOURSELF, YOU CAN FIND OUR SOURCE CODE HERE AT THE GITHUB REPOSITORY.
utt_0210 utt 900.69 901.85 -2.0474 THANKS FOR WATCHING!
