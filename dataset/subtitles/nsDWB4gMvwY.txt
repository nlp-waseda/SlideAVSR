utt_0000 utt 1.74 2.45 -X HELLO.
utt_0001 utt 2.45 3.70 -X MY NAME IS SAMUEL CARTON.
utt_0002 utt 3.70 6.38 -X I AM A POST DOC AT THE UNIVERSITY OF COLORADO,
utt_0003 utt 6.38 6.74 -X BOULDER.
utt_0004 utt 7.34 12.18 -X THIS IS A PRESENTATION OF MY PAPER EVALUATING AND CHARACTERIZING HUMAN RATIONALES,
utt_0005 utt 12.18 14.06 -X WHICH IS JOINT WORK WITH ANIRUDH RATHORE,
utt_0006 utt 14.06 17.30 -X AND CHENHAO TAN.
utt_0007 utt 17.30 18.99 -X SO THIS IS A PAPER ABOUT RATIONALES,
utt_0008 utt 18.99 27.15 -X WHICH AS MANY OF THE PEOPLE WATCHING THIS PRESENTATION WILL KNOW ARE SUBSETS OF TOKENS TAKEN TO EXPLAIN OR JUSTIFY THE LABEL IN A TEXT CLASSIFICATION SETTING.
utt_0011 utt 27.60 29.43 -X IN THIS PARTICULAR EXAMPLE,
utt_0012 utt 29.43 31.60 -X DRAWN FROM THE E-SNLI DATASET,
utt_0013 utt 31.85 39.67 -X THE HYPOTHESIS IS A CONTRADICTION OF THE PREMISE, A FACT WHICH CAN BE EXPLAINED BY THE USE OF THE WORD SITS IN THE PREMISE VERSUS LAYING IN THE HYPOTHESIS
utt_0015 utt 42.51 44.40 -X AND THEN, OF COURSE, IN THIS CASE,
utt_0016 utt 44.40 48.08 -X A STRONG MODEL WOULD ASSIGN THE CONTRADICTION CLASS A HIGH PROBABILITY.
utt_0017 utt 50.32 53.49 -X RATIONALES ARE AN EXPLAINABLE AI TECHNIQUE FOR TEXT,
utt_0018 utt 53.49 57.94 -X AND WE'RE INTERESTED IN THEM FOR THE SAME REASONS THAT WE'RE GENERALLY INTERESTED IN EXPLAINABLE AI,
utt_0019 utt 58.86 61.72 -X WHICH INCLUDE ENABLING HUMAN-AI COLLABORATION,
utt_0020 utt 62.16 64.24 -X ENSURING MODEL ACCOUNTABILITY,
utt_0021 utt 64.24 69.33 -X MAKING DEBUGGING MODELS EASIER AND DISCOVERING NEW KNOWLEDGE.
utt_0022 utt 70.03 74.61 -X NOW, GIVEN A MODEL TRAINED TO RATIONALIZE ITS DECISIONS,
utt_0023 utt 75.38 79.86 -X A VERY IMPORTANT QUESTION IS HOW DO WE EVALUATE THE GENERATED RATIONALES?
utt_0024 utt 79.86 83.09 -X THE MOST COMMON WAYS OF DOING THIS ARE ONE,
utt_0025 utt 83.09 87.77 -X COMPARING THEM TO GOLD STANDARD HUMAN RATIONALES AND TWO, AUTOMATED METRICS,
utt_0026 utt 87.77 91.70 -X WHICH DON'T USE ANY KIND OF EXTERNAL STANDARD.
utt_0027 utt 91.70 95.22 -X AMONG THE LATTER TYPE, A PROMINENT RECENTLY PROPOSED METRIC IS FIDELITY,
utt_0028 utt 95.76 99.73 -X WHICH IS DIVIDED INTO THE SUB METRICS OF SUFFICIENCY AND COMPREHENSIVENESS,
utt_0029 utt 99.73 101.05 -X AKA NECESSITY.
utt_0030 utt 103.51 111.48 -X SUFFICIENCY MEASURES WHETHER THE RATIONAL ALONE IS SUFFICIENT TO ALLOW THE MODEL TO MAKE THE SAME PREDICTION AS IT DID WITH FULL INFORMATION.
utt_0032 utt 111.48 114.52 -X IF THIS PARTICULAR RATIONALE THAT WE'RE LOOKING AT HERE WERE HIGHLY SUFFICIENT,
utt_0033 utt 114.52 115.29 -X THEN THE MODEL WOULD,
utt_0034 utt 115.38 117.43 -X ON THE STRENGTH OF THESE TWO WORDS ALONE,
utt_0035 utt 117.68 122.58 -X ASSIGN A SIMILAR PROBABILITY TO THE CONTRADICTION CLASS AS TO WHAT IT DID WITH THE FULL INFORMATION,
utt_0036 utt 122.58 126.39 -X WHICH WAS twenty point nine six IN OUR HYPOTHETICAL EXAMPLE.
utt_0037 utt 127.57 128.70 -X BY CONTRAST,
utt_0038 utt 128.70 137.69 -X COMPREHENSIVENESS MEASURES WHETHER THE RATIONAL IT IS NECESSARY FOR MAKING THE SAME PREDICTION BY EXAMINING THE MODELS PREDICTION ON THE COMPLEMENT OF THE RATIONAL,
utt_0040 utt 137.69 138.39 -X THAT IS TO SAY,
utt_0041 utt 138.39 142.01 -X WITHOUT THE TOKENS IN THE RATIONALE.
utt_0042 utt 142.01 142.78 -X IN OUR EXAMPLE,
utt_0043 utt 142.78 145.14 -X IF OUR TWO WORD RATIONAL IS HIGHLY COMPREHENSIVE,
utt_0044 utt 145.14 150.39 -X THEN TRYING TO MAKE A PREDICTION WITHOUT THOSE TWO WORDS SHOULD LEAD TO A VERY DISSIMILAR PREDICTED CLASS PROBABILITY,
utt_0046 utt 150.52 152.63 -X POSSIBLY EVEN A DIFFERENT PREDICTED CLASS,
utt_0047 utt 152.63 159.10 -X AS THE MODEL DID WITH FULL INFORMATION.
utt_0048 utt 159.10 161.18 -X SO WE HAVE THESE TWO TYPES OF EVALUATION.
utt_0049 utt 161.18 162.30 -X BUT TO THE BEST OF OUR KNOWLEDGE,
utt_0050 utt 162.30 166.65 -X THE QUESTION HAS NOT BEEN ANSWERED OF: WHAT ABOUT THE FIDELITY OF HUMAN RATIONALES?
utt_0051 utt 167.32 173.69 -X DO HUMAN RATIONALES ACTUALLY SHOW OPTIMAL PROPERTIES WHEN THEY'RE EVALUATED BY THESE AUTOMATED METRICS?
utt_0052 utt 175.13 181.95 -X AND THIS IS AN IMPORTANT QUESTION BECAUSE IF THERE IS A SERIOUS MISALIGNMENT BETWEEN THESE TWO TYPES OF EVALUATION,
utt_0054 utt 181.95 188.99 -X THEN IT HAS TO BE RESOLVED BEFORE WE AS A COMMUNITY CAN ARRIVE AT CONSISTENT STANDARDS FOR RATIONALE QUALITY.
utt_0055 utt 190.07 193.02 -X IN ADDITION TO EVALUATING THE FIDELITY OF HUMAN RATIONALES,
utt_0056 utt 193.02 196.03 -X WE ALSO PROPOSE EXTENSIONS TO THE FIDELITY METRICS THEMSELVES.
utt_0057 utt 196.82 201.21 -X WE PROPOSE A NORMALIZATION PROCEDURE TO ACCOUNT FOR BASELINE MODEL BEHAVIOR,
utt_0058 utt 201.46 204.86 -X AND WE INVESTIGATE THE RELATIONSHIP BETWEEN FIDELITY AND MODEL ACCURACY.
utt_0059 utt 205.34 206.24 -X FINALLY,
utt_0060 utt 206.24 211.04 -X WE PROPOSE A METHOD FOR INVESTIGATING FINE-GRAINED RATIONALE PROPERTIES BY DRAWING SO-
utt_0061 utt 211.04 214.27 -X CALLED FIDELITY CURVES BASED ON RANDOM OCCLUSION OF RATIONAL TOKENS.
utt_0062 utt 216.35 220.32 -X WE WORK WITH SIX DATA SETS FOR WHICH HUMAN RATIONALES ARE AVAILABLE.
utt_0063 utt 220.32 225.95 -X THREE SINGLE TEXT CLASSIFICATIONS STYLE TASKS AND THREE DOCUMENT QUERY READING COMPREHENSION STYLE TASKS.
utt_0065 utt 226.59 229.28 -X THESE DATA SETS VARY ACROSS A NUMBER OF DIMENSIONS,
utt_0066 utt 229.28 238.72 -X FROM RATIONALE-TO-TEXT RATIO HAS SHOWN IN THE PLOT, TO VARIOUS OTHER QUALITIES THAT ARE SHOWN IN THIS TABLE THAT I'M NOT GOING TO ELABORATE ON.
utt_0068 utt 238.72 240.25 -X IN TECHNICAL TERMS,
utt_0069 utt 240.25 244.99 -X WE DEFINE SUFFICIENCY AND COMPREHENSIVENESS AS A DIFFERENCE IN PREDICTED CLASS PROBABILITY
utt_0070 utt 245.50 251.04 -X BETWEEN THE MODEL OPERATING ON FULL INFORMATION VERSUS ONLY THE RATIONALE OR ONLY THE RATIONAL COMPLIMENT.
utt_0072 utt 251.04 252.32 -X IN THE CASE OF COMPREHENSIVENESS.
utt_0073 utt 253.79 256.67 -X THERE'S A LOT OF A LOT OF CONTENT ON THIS SLIDE,
utt_0074 utt 256.67 257.89 -X BUT THE IDEA IS VERY SIMPLE.
utt_0075 utt 257.89 259.74 -X GIVEN THE RATIONALE OR ITS COMPLEMENT,
utt_0076 utt 259.74 268.13 -X WE RUN THE MODEL ON THE REDUCED TEXT AND THEN SUBTRACT THE RESULTANT CLASS PROBABILITY FROM THE ORIGINAL CLASS PROBABILITY FOR THAT EXAMPLE.
utt_0079 utt 268.13 269.15 -X IN TERMS OF NOTATION,
utt_0080 utt 269.15 274.56 -X ALPHA HERE REPRESENTS THE RATIONALE AS A BINARY MASK APPLIED TO THE TOKENS OF THE EXAMPLE X.
utt_0081 utt 276.80 279.26 -X AND THAT BRINGS US TO THE MAIN RESULTS OF THE STUDY.
utt_0082 utt 279.26 285.03 -X WE INVESTIGATE THE FIDELITY AND A HUMAN RATIONALES USING FOUR MODELS LOGISTIC REGRESSION,
utt_0084 utt 285.03 285.67 -X RANDOM FOREST,
utt_0085 utt 286.08 288.93 -X LSTM AND THE ROBERTA VARIANT OF BERT.
utt_0086 utt 290.17 291.87 -X LOOKING AT MODEL ACCURACY,
utt_0087 utt 291.87 293.63 -X WE SEE BASICALLY WHAT WE WOULD EXPECT.
utt_0088 utt 293.66 295.75 -X ROBERTA PERFORMS ALL THE OTHER MODELS,
utt_0089 utt 295.75 299.49 -X AND LSTM PERFORMS THE NON-NEURAL MODELS IN ALMOST EVERY CASE.
utt_0091 utt 301.85 303.59 -X LOOKING AT SUFFICIENCY,
utt_0092 utt 303.59 307.46 -X WE SEE THAT THE SUFFICIENCY OF HUMAN RATIONALES IS GENERALLY BETWEEN zero point eight AND
utt_0093 utt 307.71 313.95 -X zero point nine five WITH SAME RATIONALES SHOWING HIGHER SUFFICIENCY ON WEAKER MODELS GENERALLY THAN ON STRONGER ONES.
utt_0095 utt 315.36 316.39 -X AND FINALLY,
utt_0096 utt 316.39 320.16 -X COMPREHENSIVENESS IS AN INTERESTING CASE BECAUSE IT'S KIND OF DIFFICULT TO INTERPRET.
utt_0097 utt 320.61 324.45 -X WE FIND THAT HUMAN RATIONALES ARE MORE COMPREHENSIVE FOR THE STRONGER MODELS,
utt_0098 utt 324.64 327.24 -X BUT IT'S DIFFICULT TO OTHERWISE INTERPRET THESE NUMBERS,
utt_0099 utt 327.24 330.18 -X WHICH ARE ON SEEMINGLY A COMPLETELY DIFFERENT SCALE FROM SUFFICIENCY.
utt_0100 utt 331.07 333.80 -X WHAT COMPRISES GOOD COMPREHENSIVENESS, REALLY?
utt_0101 utt 333.80 335.30 -X WHAT IS THE TARGET NUMBER HERE?
utt_0102 utt 335.39 336.55 -X IN A MOMENT,
utt_0103 utt 336.55 340.87 -X I'M GONNA TALK ABOUT HOW WE CAN USE NORMALIZATION TO AT LEAST PARTIALLY ANSWER SOME OF THESE QUESTIONS.
utt_0104 utt 342.82 348.55 -X FOR MOST OF THE REST OF THIS TALK I FOCUS PRIMARILY ON ROBERTA IS IT GENERALLY REPRESENTS THE STATE OF THE ART IN NLP.
utt_0105 utt 349.15 356.61 -X BREAKING DOWN RATIONALE FINALITY SCORES BY CLASS GIVES US A LITTLE ADDITIONAL PERSPECTIVE ON WHAT'S GOING ON HERE.
utt_0107 utt 356.96 365.83 -X E-SNLI DISPLAYS A CLASS ASYMMETRY IN SUFFICIENCY WITH CONTRADICTION RATIONALES PROVING MORE SUFFICIENT THAN FOR THE OTHER TWO CLASSES.
utt_0109 utt 367.23 371.14 -X AND COMPREHENSIVENESS VARIES WILDLY BETWEEN CLASSES FOR BOTH WIKIATTACK AND,
utt_0110 utt 371.14 373.48 -X TO A LESSER EXTENT MOVIE, MULTIRC AND FEVER.
utt_0111 utt 375.59 379.53 -X IN ADDITION TO THE INTERPRETATION ISSUE I MENTIONED A MOMENT AGO,
utt_0112 utt 379.53 387.02 -X THERE'S ALSO A QUESTION HERE OF ARE THESE DISPARITIES BECAUSE RATIONALES ARE INTRINSICALLY MORE COMPREHENSIVE FOR ONE CLASS VERSUS ANOTHER,
utt_0114 utt 387.02 389.19 -X OR BECAUSE WE'RE LEARNING VERY BIASED MODELS,
utt_0115 utt 389.19 393.48 -X WHICH TEND TO LEAN STRONGLY TOWARDS ONE CLASS IN THE ABSENCE OF AVAILABLE INFORMATION.
utt_0116 utt 393.89 396.78 -X THIS IS ANOTHER QUESTION THAT WE CAN ANSWER WITH NORMALIZATION.
utt_0117 utt 398.24 401.83 -X SO TO MITIGATE THESE ISSUES OF INTERPRETABILITY AND MODEL BIAS CORRECTION,
utt_0118 utt 401.96 407.75 -X WE PROPOSED THE IDEA OF NORMALIZING FIDELITY SCORES RELATIVE TO BASELINE MODEL BEHAVIOR.
utt_0119 utt 407.75 410.02 -X WE DO THIS BY DEFINING A QUOTE-UNQUOTE NULL DIFFERENCE,
utt_0120 utt 410.12 414.79 -X WHICH IS THE DIFFERENCE BETWEEN MODEL OUTPUT BETWEEN FULL INFORMATION AND NO INFORMATION AT ALL.
utt_0121 utt 415.30 423.88 -X THIS NULL DIFFERENCE CAN BE THOUGHT OF AS THE SUFFICIENCY OF AN EMPTY RATIONALE OR THE COMPREHENSIVENESS OF AN ALL-INCLUSIVE RATIONALE.
utt_0123 utt 424.45 428.91 -X WE DEFINE THESE IDEAS AS EXTENSIONS OF THE DEFINITION OF SUFFICIENCY AND COMPREHENSIVENESS
utt_0124 utt 429.29 432.17 -X AS YOU CAN SEE FROM THE EQUATIONS AT THE BOTTOM OF THE SLIDE,
utt_0125 utt 432.17 433.83 -X THE BASIC IDEA IS VERY SIMPLE.
utt_0126 utt 433.83 435.11 -X WE CALCULATE THE NULL DIFFERENCE,
utt_0127 utt 435.11 440.14 -X AND THEN WE DIVIDE THE SUFFICIENCY AND COMPREHENSIVENESS BY IT TO GENERATE PROPERLY NORMALIZED VALUES.
utt_0128 utt 441.25 442.79 -X AND THIS IS THE RESULT.
utt_0129 utt 444.33 453.84 -X WE CAN SEE THAT THE HIGH SUFFICIENCY OF THE WEAKER MODELS WAS AN ARTIFACT OF MODEL UNCERTAINTY AND THAT REALLY THE HUMAN RATIONALES ARE NOT MUCH MORE SUFFICIENT THAN EMPTY RATIONALES FOR THESE MODELS.
utt_0131 utt 454.89 459.44 -X WE CAN ALSO SEE THAT COMPREHENSIVENESS HAS BEEN PROJECTED CLOSER TO THE SAME SCALE AS SUFFICIENCY,
utt_0132 utt 459.53 465.16 -X ALTHOUGH RATIONALES STILL FALL SHORT IN COMPREHENSIVENESS COMPARED THIS EFFICIENCY EVEN UNDER THIS NORMALIZATION REGIME.
utt_0134 utt 468.01 473.32 -X PERFORMING THE SAME TRANSFORMATION ON THE CLASS-WISE RESULTS FOR ROBERTA,
utt_0135 utt 473.58 478.60 -X WE SEE THAT THE SKEWED RESULTS FOR FEVER DO INDEED SEEM TO HAVE BEEN THE RESULT OF MODEL BIAS.
utt_0136 utt 479.53 481.52 -X BUT THERE ARE GENUINE DISCREPANCIES.
utt_0137 utt 481.52 483.53 -X PRESIDENT FOR WIKIATTACK, MOVIE AND MULTIRC.
utt_0138 utt 483.53 490.67 -X WE ALSO FIND THAT THERE ARE DISCREPANCIES IN SUFFICIENCY IN WIKIATTACK THAT WERE ACTUALLY MASKED BY THE LACK OF NORMALIZATION.
utt_0140 utt 493.48 500.21 -X A MAJOR STICKING POINT IN INTERPRETING FIDELITY SCORES IS THE QUESTION OF THE PRACTICAL IMPLICATION.
utt_0142 utt 500.49 503.12 -X DOES A LOW SUFFICIENCY SCORE REALLY MATTER?
utt_0143 utt 503.12 507.76 -X OR DOES IT JUST MEAN THAT THE CLASSIFIER IS LESS CONFIDENT ABOUT THE CORRECT CLASS?
utt_0144 utt 508.14 512.59 -X AND HOW DOES IT AFFECT MATTERS WHEN THE MODEL IS ALLOWED TO ADAPT TO THE PRESENCE OF RATIONALES,
utt_0145 utt 512.59 514.48 -X AS IN THE CASE FOR RATIONALE ARCHITECTURES?
utt_0146 utt 516.04 517.26 -X IN THIS PLOT,
utt_0147 utt 517.29 522.29 -X WE INVESTIGATE THE ACCURACY OF THE ROBERTA MODEL WHEN TRAINED AND EVALUATED ON FULL INFORMATION,
utt_0148 utt 522.54 530.00 -X VERSUS TRAINED ON FULL AND EVALUATED ONLY ON RATIONALES, AS WELL WHEN IT IS BOTH TRAINED AND EVALUATED ON RATIONALES.
utt_0150 utt 530.73 533.20 -X THIS IS A VISUAL ILLUSTRATION OF WHAT I MEAN.
utt_0151 utt 533.20 535.86 -X YOU CAN SEE IN THE THREE DIFFERENT CONDITIONS,
utt_0152 utt 536.08 539.18 -X THE FULL INFORMATION IS EITHER USED OR NOT USED DURING TRAINING,
utt_0153 utt 539.18 541.39 -X AND EITHER USED OR NOT USED DURING EVALUATION.
utt_0154 utt 542.44 545.81 -X WHAT WE SEE IS KIND OF INTERESTING.
utt_0155 utt 545.81 548.59 -X EVALUATING ON REDUCED DATA HURTS IN THREE OUT OF SIX CASES,
utt_0156 utt 548.59 553.71 -X BUT IT ACTUALLY HELPS IN THE OTHER THREE. MOREOVER, IN THREE CASES,
utt_0157 utt 554.13 559.67 -X ALLOWING THE MODEL TO ADAPT TO THE REDUCED DATA ACTUALLY IMPROVES THE PERFORMANCE OVER THE FULL INFORMATION CASE.
utt_0159 utt 560.65 568.11 -X SO WHAT THIS TELLS US IS THAT THE SUB-OPTIMAL SUFFICIENCY CAN BE ASSOCIATED WITH EITHER HIGHER OR LOWER PREDICTION ACCURACY,
utt_0161 utt 568.40 573.49 -X GIVING US ANOTHER REASON TO BE CAREFUL ABOUT OUR INTERPRETATION OF THESE FIDELITY METRICS.
utt_0162 utt 576.27 577.11 -X FINALLY,
utt_0163 utt 577.11 579.79 -X THERE'S A WHOLE SET OF QUALITIES THAT RATIONALES CAN HOLD,
utt_0164 utt 579.79 582.68 -X WHICH ARE NOT REALLY CAPTURED BY EXISTING FIDELITY METRICS.
utt_0165 utt 583.70 585.81 -X ONE SUCH QUALITY IS TOKEN REDUNDANCY,
utt_0166 utt 585.81 590.29 -X WHERE THE RATIONALE CONTAINS MORE TOKENS THAT ARE NECESSARY TO PREDICT THE CORRECT CLASS.
utt_0167 utt 591.22 593.33 -X ANOTHER SUCH QUALITY IS TOKEN IRRELEVANCY,
utt_0168 utt 593.33 597.01 -X WHERE THE RATIONALE CONTAINS TOKENS THAT ARE IRRELEVANT TO THE TASK IN HAND.
utt_0169 utt 598.86 601.14 -X TOKENS CAN BE DEPENDENT ON ONE ANOTHER,
utt_0170 utt 601.14 608.50 -X ALLOWING FOR CORRECT PREDICTION IF AND ONLY IF THEY'RE BOTH PRESENT, OR THEY CAN BE INDEPENDENT AND CONTAINED PREDICTIVE SIGNAL ALL BY THEMSELVES.
utt_0172 utt 609.87 611.99 -X IN ORDER TO EVALUATE THESE QUALITIES,
utt_0173 utt 611.99 618.13 -X WE PROPOSE TO EXAMINE HOW SUFFICIENCY AND COMPREHENSIVENESS DEGRADE AS TOKENS ARE RANDOMLY REMOVED FROM THE HUMAN RATIONALES.
utt_0175 utt 618.32 621.40 -X DEPENDING ON THE VARIOUS LEVELS OF REDUNDANCY,
utt_0176 utt 621.40 622.01 -X RELEVANCE,
utt_0177 utt 622.01 623.54 -X DEPENDENCY AND INDEPENDENCY,
utt_0178 utt 623.54 629.11 -X WE EXPECT TO SEE DIFFERENT RATES OF DEGRADATION IN SUFFICIENCY AND COMPREHENSIVENESS. BRIEFLY,
utt_0180 utt 629.11 631.64 -X AN EXAMPLE HERE IS THE MOVIES DATASET IN ORANGE,
utt_0181 utt 631.64 633.17 -X WHICH HAS A VERY LOW,
utt_0182 utt 633.20 637.24 -X VERY SLOW DROP IN SUFFICIENCY AND A RELATIVELY FAST DROP IN COMPREHENSIVENESS
utt_0183 utt 637.39 639.77 -X INDICATING THAT HAS MANY REDUNDANT TOKENS.
utt_0184 utt 639.77 645.05 -X SO THAT WAS A LOT OF INFORMATION IN A RELATIVELY SHORT TALK.
utt_0186 utt 645.49 648.44 -X WE ANALYZED THE FIDELITY OF HUMAN RATIONALES,
utt_0187 utt 648.44 650.94 -X AND WE PROPOSED EXTENSIONS TO THE BASIC FIDELITY METRICS,
utt_0188 utt 650.94 655.45 -X INCLUDING NORMALIZATION, ACCURACY ANALYSIS AND RANDOM OCCLUSION OF TOKENS.
utt_0189 utt 655.67 669.02 -X THE MAIN TAKEAWAYS FROM OUR STUDY ARE THAT HUMAN RATIONALES ARE NOT NECESSARILY OPTIMAL AND THAT MODEL PROPERTIES HAVE A BIG IMPACT ON RATIONALE FIDELITY ASSESSMENTS, AND THAT FIDELITY ITSELF IS NOT NECESSARILY CORRELATED WITH ACCURACY.
utt_0192 utt 670.32 677.75 -X WHAT THIS ALL POINTS TO IS THAT THE INTERPRETABILITY COMMUNITY REALLY NEEDS TO BE CAREFUL IN SETTING BENCHMARKS FOR RATIONAL QUALITY.
utt_0194 utt 677.75 678.39 -X FOR EXAMPLE,
utt_0195 utt 678.39 681.85 -X WHILE THE NORMALIZATION SCHEME WE PROPOSE MAY NOT BE THE ONE THAT COMMUNITY SETTLES ON,
utt_0196 utt 681.85 689.72 -X WE SUSPECT THAT SOME KIND OF NORMALIZATION IS NECESSARY MOVING FORWARD TO EVALUATE THE FINALITY OF EXPLANATIONS ACROSS DIFFERENT MODELS AND DATA SETS.
utt_0198 utt 692.79 694.49 -X AND THAT CONCLUDES MY TALK.
utt_0199 utt 694.49 697.15 -X I REALLY APPRECIATE ANYONE WHO STUCK AROUND THIS LONG,
utt_0200 utt 697.15 698.91 -X AND I WELCOME QUESTIONS OR FURTHER DISCUSSION.
utt_0201 utt 698.91 699.71 -1.5929 THANK YOU.
