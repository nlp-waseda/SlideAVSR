utt_0000 utt 0.65 12.88 -X HI, MY NAME IS HARINI AND I'M PRESENTING OUR WORK ON SEMANTICALLY-GROUNDED CONTEXT-SPECIFIC MODEL EVALUATION. SO EVALUATION IS REALLY IMPORTANT BECAUSE IT DETERMINES WHAT SYSTEMS ARE CONSIDERED STATE OF THE ART HOW WE
utt_0003 utt 12.88 27.68 -X UNDERSTAND SYSTEM STRENGTHS AND LIMITATIONS AND THE AREAS WE TARGET FOR IMPROVEMENT AS A RESULT EVALUATION HAS A BROAD IMPACT ON RESEARCH AGENDAS AND VALUES IN MACHINE LEARNING BECAUSE OF THIS WE REALLY NEED EVALUATION PARADIGMS THAT SURFACE HARM AND REFLECT ACTUAL USER NEEDS
utt_0007 utt 28.43 38.63 -X AS A SPECIFIC EXAMPLE OF WHERE CURRENT EVALUATIONS FALL SHORT CONSIDER CONTENT MODERATION LOTS OF RESEARCH HAS SHOWN THAT DIFFERENT ONLINE COMMUNITIES DEAL WITH VERY DIFFERENT TYPES OF HARASSMENT AND
utt_0010 utt 38.63 52.98 -X ENFORCE WIDELY DIFFERENT RULES AND NORMS FOR EXAMPLE THIS PAPER GROUP SUBREDDITS INTO CLUSTERS BASED ON THE TYPES OF RULES THEY ENFORCED AS SHOWN IN THE TABLE THEY FOUND THAT SOME SUBREDDITS MODERATE THINGS LIKE COMMENTS MOCKING THE CONCEPT OF A SAFE SPACE WHILE OTHERS DO NOT
utt_0014 utt 53.20 67.70 -X SOME MODERATE ATTEMPTS TO BE FUNNY OR SARCASTIC WHILE OTHERS DON'T AND THERE ARE HUNDREDS OF NORMS LIKE THIS THAT DIFFER WIDELY ACROSS COMMUNITIES AT THE SAME TIME MODERATION IS PRETTY TAXING AND THERE ARE INCREASINGLY MORE MACHINE LEARNING BASED TOOLS OUT THERE THAT CLAIM TO BE ABLE TO HELP PARTIALLY
utt_0018 utt 67.70 71.03 -X AUTOMATE THE PROCESS OF MODERATION LIKE THIS ONE CALLED PERSPECTIVE
utt_0019 utt 71.63 86.13 -X BUT HOW WOULD SOMEONE IN A PARTICULAR ONLINE COMMUNITY FIGURE OUT IF ONE OF THESE TOOLS WOULD MAKE SENSE TO USE GIVEN THE RULES AND NORMS OF THEIR SPECIFIC CONTEXT TYPICAL EVALUATIONS MIGHT BE ABLE TO TELL US THINGS LIKE THE MODEL'S ACCURACY OR GENERAL ROBUSTNESS WHICH ARE
utt_0023 utt 86.13 100.92 -X CERTAINLY USEFUL THINGS TO KNOW BUT THEY'RE NOT ENOUGH ON THEIR OWN BECAUSE THEY DON'T CAPTURE MANY OF THE OTHER THINGS THAT MATTER TO PEOPLE IN A PARTICULAR CONTEXT FOR EXAMPLE IT'D BE MUCH HARDER FOR A MODERATOR TO ASK THE QUESTION IS THIS MODERATION MODEL ABLE TO FLAG COMMENTS MOCKING SAFE SPACES
utt_0027 utt 101.01 113.86 -X WITH EXISTING EVALUATION METHODS THAT'S BECAUSE THIS REQUIRES UNDERSTANDING A SEMANTICALLY MEANINGFUL CONCEPT WHICH CAN'T BE EASILY FORMALIZED OR DESCRIBED WITH LOW-LEVEL FEATURES AND IT STEMS FROM USERS PERSONAL KNOWLEDGE
utt_0030 utt 113.86 116.91 -X ABOUT THE TYPES OF THINGS THAT ARE IMPORTANT IN THEIR CONTEXT
utt_0031 utt 118.23 132.60 -X SO WE DESIGNED THE SYSTEM KALEIDOSCOPE TO FILL THE SCAP AND FACILITATE MODEL EVALUATION THAT ACHIEVES THESE GOALS OF BEING CONTEXT-SPECIFIC SEMANTICALLY MEANINGFUL AND USER-DRIVEN IT'S MADE UP OF AN UNDERLYING WORKFLOW AND METHODOLOGY AS WELL AS AN INTERACTIVE UI THAT IMPLEMENTS IT
utt_0035 utt 132.89 144.14 -X KALEIDOSCOPE'S WORKFLOW HAS THREE PARTS STARTING WITH IDENTIFICATION WHERE USERS IDENTIFY A FEW EXEMPLARS OF A SEMANTICALLY MEANINGFUL CONCEPT SO TAKING A CONTENT MODERATION EXAMPLE THEY MIGHT IDENTIFY THE SINGLE COMMENT
utt_0038 utt 144.14 148.03 -X IMMIGRANTS DON'T BELONG HERE AS AN EXEMPLAR OF A XENOPHOBIC ATTACK
utt_0039 utt 148.57 155.32 -X THEN THEY WOULD GENERALIZE THESE EXEMPLARS INTO A LARGER DIVERSE SET OF EXAMPLES REPRESENTING THE BROADER CONCEPT OF XENOPHOBIC ATTACKS
utt_0041 utt 155.90 167.13 -X FINALLY THEY CAN SPECIFY THEIR EXPECTATIONS OF GOOD MODEL BEHAVIOR WITH THESE CONCEPTS AND TEST WHETHER THEY HOLD SO HERE THE USER COULD SPECIFY THAT THEY EXPECT XENOPHOBIC COMMENTS TO BE MODERATED AND TEST HOW WELL THE MODEL
utt_0044 utt 167.13 174.16 -X MEETS THE SPECIFICATION AND WHEN I REFER TO EXAMPLES AND DATA HERE IT'S UNLABELED DATA INTENDED TO COME FROM THE USER'S CONTEXT
utt_0046 utt 174.87 189.15 -X WE BUILT AN INTERACTIVE SYSTEM TO FACILITATE THIS WORKFLOW WHERE THE OVERALL LAYOUT LOOKS LIKE THIS ON THE LEFT USERS CAN CONSTRUCT EXAMPLE SETS THAT REPRESENT MEANINGFUL CONCEPTS THE MIDDLE IS A PROJECTION OF ALL OF THE EXAMPLES IN THE DATA THAT'S UTILIZED THROUGHOUT THE WORKFLOW AND ON THE RIGHT
utt_0050 utt 189.15 204.06 -X THEY CAN SPECIFY AND RUN TESTS ABOUT MODEL BEHAVIOR USING THE DEFINED EXAMPLE SETS SO LET'S SAY I'M A MODERATOR OF THE NEWS SUBREDDIT AND IN THE SUBREDDIT COMMON CONSULTING MODERATORS ARE NOT ALLOWED SO I WANT TO ASK THE QUESTION HOW WELL DOES THIS MODERATION MODEL DEAL WITH THOSE
utt_0054 utt 204.06 215.04 -X KINDS OF COMMENTS FOR THIS EXAMPLE THE SYSTEM WILL BE SEATED WITH DATA FROM MY CONTEXT OF R NEWS AS A HEADS UP IN A FEW SLIDES I'LL BE SHOWING SCREENSHOTS WITH REAL DATA AND MANY OF THE COMMENTS CAN BE QUITE OFFENSIVE
utt_0058 utt 217.12 231.30 -X SO WE START WITH THE IDENTIFICATION STAGE I MIGHT ALREADY HAVE A PARTICULAR EXAMPLE IN MIND BASED ON SOMETHING THAT I'VE SEEN WHICH I CAN INPUT DIRECTLY TO SEE THE EXAMPLE SET IF I DIDN'T HAVE A SPECIFIC EXAMPLE THOUGH I CAN STILL FIND ONE BY EXPLORING EXAMPLES USING A KEYWORD HERE I'M USING
utt_0062 utt 231.30 242.95 -X THE KEYWORD MODS JUST AIMING TO FIND A FEW RELEVANT EXEMPLARS OF THE CONCEPT AND USE THOSE TO SEED THE EXAMPLE SET ONCE I DO THAT THEY'RE NOW PART OF THE INSULTING MODERATORS EXAMPLE SET THAT'S BEEN DEFINED ABOVE
utt_0066 utt 244.86 259.65 -X IN THE GENERALIZATION STAGE A USER CAN EXPAND THOSE FEW EXAMPLES INTO A LARGER DIVERSE SET OF EXAMPLES REPRESENTING THE HIGHER LEVEL CONCEPT THEY HAVE IN MIND THE WAY THIS WORKS IS THROUGH ITERATIVELY RETRIEVING SEMANTICALLY SIMILAR EXAMPLES FROM THE DATA BASED ON A DISTANCE METRIC IN A LEARNED EMBEDDING
utt_0070 utt 259.65 271.08 -X SPACE SO HOW THIS WOULD WORK IN THE TOOL IS WE FIRST SELECT THE EXEMPLARS WE ADDED WHAT APPEARS DOWN BELOW THEN ARE OTHER EXAMPLES FROM THE DATA THAT ARE MOST SEMANTICALLY SIMILAR TO THOSE THAT I'VE
utt_0073 utt 271.08 285.67 -X SELECTED ABOVE THE RESULTS ARE GROUPED INTO THREE CLUSTERS AND THE PROJECTION PLOT SHOWS US WHERE THESE CLUSTERS APPEAR RELATIVE TO OTHER EXAMPLES IN THE TOP WORDS IN EACH CLUSTER BY SKIMMING THE EXAMPLES AND THIS INFORMATION WE CAN QUICKLY TRY TO GET A SENSE OF THE TYPES OF EXAMPLES IN EACH CLUSTER DEPENDING ON
utt_0077 utt 285.67 300.39 -X OUR MENTAL MODEL OF THESE TYPES OF EXAMPLES WE MIGHT DECIDE TO ONLY ADD CERTAIN EXAMPLES OR ONLY CERTAIN CLUSTERS BUT IN THIS CASE LET'S SAY WE THINK THESE ARE ALL RELEVANT TO THE CONCEPT WE CAN SELECT ALL AND ADD THEM TO THE INSULTING MODS EXAMPLE SET AT THIS POINT THIS PROCESS KEEPS
utt_0081 utt 300.39 312.74 -X ITERATING RELEVANT EXAMPLES GET ADDED TO THE EXAMPLE SET THAT UPDATES THE SIMILAR EXAMPLES BASED ON THE NEW SELECTION AND THEN WE ADD RELEVANT EXAMPLES OR CLUSTERS AGAIN AND SO ON AND WE CAN REPEAT THIS JUST A FEW TIMES TO BUILD UP
utt_0084 utt 312.74 322.09 -X A PRETTY LARGE EXAMPLE SET HERE AFTER JUST A FEW ITERATIONS OF THIS PROCESS I ENDED UP WITH one hundred and sixteen EXAMPLES THAT I FEEL REPRESENTED THE CONCEPT OF INSULTING MODERATORS
utt_0087 utt 324.20 339.18 -X IN THE SPECIFICATION AND TESTING STAGE USERS CAN USE THE DEFINED CONCEPTS TO MAKE THEIR EXPECTATIONS OF GOOD MODEL BEHAVIOR EXPLICIT AND TEST HOW WELL THE MODEL MEETS THE SPECIFICATIONS WE DEFINE A BUNCH OF DIFFERENT BEHAVIORS USERS CAN SPECIFY INCLUDING DESIRED MODEL OUTPUTS OR DESIRED OUTPUT SHIFTS BETWEEN TWO
utt_0091 utt 339.18 354.09 -X DISTRIBUTIONS AND OUR PAPER HAS MORE DETAILS ON HOW WE ORGANIZE AND FORMALIZE THESE DIFFERENT BEHAVIORS IN THE INTERFACE THIS IS AN EXAMPLE OF CREATING A TEST TO SPECIFY THAT COMMENTS INSULTING MODERATORS SHOULD BE FLAGGED BY THE MODEL THAT'S WHAT I'M SPECIFYING HERE WITH DESIRED MODEL BEHAVIOR
utt_0095 utt 354.86 358.94 -X AFTER I RUN THIS I CAN SEE THAT THE MODEL ONLY GAVE thirty-two point eight PERCENT OF THAT
utt_0096 utt 359.08 371.53 -X EXAMPLE SET A MODERATION PROBABILITY ABOVE zero point five THE OUTPUT ALSO SHOWS THE PROBABILITY DISTRIBUTION AND SPECIFIC EXAMPLES THAT THE MODEL RECOMMENDED SHOULD OR SHOULD NOT BE MODERATED WHICH I CAN FILTER TO SEE FOR EXAMPLE IF THE
utt_0099 utt 371.72 382.77 -X EXAMPLES WITH A LOWER PROBABILITY ARE ACTUALLY LESS SEVERE THAN THE EXAMPLES WITH A HIGHER PROBABILITY OR IF THE MODEL IS PAYING ATTENTION TO UNWANTED CORRELATIONS OR ORDERING THESE EXAMPLES IN A WAY THAT SEEMS ARBITRARY
utt_0102 utt 383.50 395.98 -X WE CAN ALSO TEST OTHER TYPES OF BEHAVIOR SO FOR EXAMPLE WE CAN CREATE A TEST SAYING THAT XENOPHOBIC COMMENTS SHOULD BE MODERATED EVEN IF THEY HAVE THE PHRASE LOL JK AT THE END OF THEM THIS WOULD BE WHAT WE CALL AN INSTANCE
utt_0105 utt 395.98 410.90 -X LEVEL INVARIANCE TEST SINCE WE WANT TO TRACK THAT MODEL BEHAVIOR DOESN'T CHANGE AFTER APPLYING A TRANSFORMATION TO EACH INSTANCE WE CAN CHOOSE FROM A RANGE OF TRANSFORMATIONS BUT HERE I'M JUST DEFINING ONE THAT ADDS THE PHRASE LOL JK TO THE END OF EACH EXAMPLE AFTER RUNNING IT THIS PLOT SHOWS US HOW
utt_0109 utt 410.90 425.52 -X MUCH MODEL PREDICTIONS CHANGED AFTER APPLYING THE TRANSFORMATION SO ON AVERAGE PREDICTIONS DON'T CHANGE BUT THERE ARE SEVERAL EXAMPLES FOR WHICH PREDICTIONS EITHER BECOME SIGNIFICANTLY MORE LIKELY OR LESS LIKELY TO BE MODERATED AFTER ADDING LOL JK TO THE END OF THE EXAMPLE AND HERE I'M FILTERING TO
utt_0113 utt 425.52 437.52 -X SHOW EXAMPLES THAT USED TO HAVE A VERY HIGH PROBABILITY OF MODERATION BUT POST-TRANSFORMATION HAVE A VERY LOW PROBABILITY WHICH IN MANY CONTEXTS YOU CAN IMAGINE WOULD BE QUITE PROBLEMATIC I'LL END BY TALKING ABOUT SOME INSIGHTS
utt_0116 utt 437.52 447.76 -X FROM A STUDY WE DID WITH REDDIT USERS AND MODERATORS WHO USED KALEIDOSCOPE TO EVALUATE PUBLICLY AVAILABLE MODERATION MODELS FOR THEIR CONTEXT I'LL HIGHLIGHT JUST TWO INSIGHTS HERE BUT PLEASE SEE OUR PAPER FOR THE COMPLETE ANALYSIS
utt_0119 utt 448.40 451.22 -X SO FIRST WE FOUND THAT THE GENERALIZATION PROCESS DREW OUT
utt_0127 utt 468.60 471.51 -6.5750 REPRESENTING THESE TWO SUBSETS THIS WAS THE DISTINCTION THAT SHE PROBABLY
