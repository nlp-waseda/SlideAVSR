utt_0000 utt 0.40 7.47 -X HI! IN THIS TALK, I PRESENT OUR WORK SIGN LANGUAGE SEGMENTATION WITH TEMPORAL CONVOLUTIONAL NETWORKS.
utt_0001 utt 7.47 15.31 -X MY NAME IS KATRIN AND THIS WORK WAS DONE IN COLLABORATION WITH NICOLAJ STACHE, SAMUEL ALBANIE AND GÃœL VAROL.
utt_0003 utt 16.56 20.53 -X THE TASK OF THIS WORK IS AUTOMATICALLY SEGMENT SIGN LANGUAGE VIDEOS.
utt_0004 utt 20.94 24.85 -X FOR THIS, WE USE VIDEOS OF CONTINUOUS SIGN LANGUAGE AS INPUT.
utt_0005 utt 26.70 34.16 -X IN THESE VIDEOS, WE WANT TO DETECT BOUNDARY AND SIGN SEGMENTS, WHERE A BOUNDARY REPRESENTS THE START AND END TIME OF EACH SIGN.
utt_0006 utt 35.44 42.68 -X WHY DO WE NEED SIGN SEGMENTATION? ONE MOTIVATION IS TO SPEED AND SCALE UP SIGN LANGUAGE DATA COLLECTION.
utt_0007 utt 42.68 45.46 -X TO GET AN IDEA OF THIS: FOR A ONE-HOUR VIDEO,
utt_0008 utt 45.46 48.85 -X A PROFESSIONAL BSL ANNOTATOR NEEDS ABOUT one hundredH TO ANNOTATE THIS.
utt_0009 utt 51.18 56.50 -X FROM THIS one hundredH APPROXIMATELY twenty-five TO fifty HOURS ARE SPENT FOR THE SEGMENTATION PART.
utt_0010 utt 56.95 62.26 -X SO IF WE COULD AUTOMATICALLY SEGMENT THE SIGNS WE COULD IMPROVE THE DATA COLLECTION PROCESS.
utt_0011 utt 64.02 67.96 -X A SECOND MOTIVATION ARE AUTOMATIC TOOLS FOR LINGUISTIC ANALYSIS.
utt_0012 utt 68.37 75.80 -X HERE YOU CAN SEE AN EXAMPLE TOOL WITH A CONTINUOUS SIGN LANGUAGE VIDEO WHERE WE CAN IMPORT THE AUTOMATIC GENERATED SEGMENTS.
utt_0013 utt 89.20 93.02 -X THIS CAN BE USED TO OBTAIN STATISTICS ABOUT THE SIGN DURATIONS
utt_0014 utt 93.08 97.46 -X AND WITH THIS THE SIGNING SPEED OR THE NUMBER OF SIGNS IN A GIVEN INTERVAL.
utt_0015 utt 99.70 106.78 -X THE CHALLENGES WHICH OCCUR IN THIS TASK ARE FIRST THE FACT THAT SIGN LANGUAGES CONVEY MEANING THROUGH MULTIPLE CHANNELS.
utt_0016 utt 107.16 110.36 -X THIS INCLUDES THE HAND POSE, LOCATION IN SPACE
utt_0017 utt 110.55 122.17 -X AND THE MOVEMENTS AS WELLS AS FACIAL EXPRESSIONS OR HEAD OR BODY MOVEMENTS AS YOU CAN SEE HERE IN THE VIDEO.
utt_0018 utt 124.18 127.84 -X THE SECOND CHALLENGE ARE CO-ARTICULATION EFFECTS.
utt_0019 utt 127.84 133.53 -X SINCE WE WORK WITH CONTINUOUS SIGNING THE APPEARANCE OF A SIGN IS INFLUENCED BY THE PREVIOUS AND NEXT SIGN.
utt_0020 utt 133.78 136.32 -X THIS IS IN CONTRAST TO ISOLATED SIGNING.
utt_0021 utt 143.80 147.20 -X THE LAST POINT IS ABOUT THE VISUAL APPEARANCE IN OUR DATASETS.
utt_0022 utt 147.51 151.58 -X HERE YOU CAN SEE THE DIFFERENCES IN THE BACKGROUND AND SIGNER POSE.
utt_0023 utt 152.99 157.57 -X FOR FAST MOVEMENTS, WE CAN SEE HERE THAT MOTION BLUR OCCURS AROUND THE HANDS.
utt_0024 utt 158.97 162.40 -X AN ADDITIONAL POINT ARE THE OCCLUSION OF PARTS OF THE BODY.
utt_0025 utt 162.75 168.35 -X ON THE LEFT IMAGE PARTS OF THE FACE AND ON THE RIGHT A PART OF THE RIGHT HAND ARE OCCLUDED.
utt_0026 utt 171.32 174.72 -X IN THIS WORK, WE USE THREE DIFFERENT SIGN LANGUAGE DATASETS.
utt_0027 utt 175.61 184.16 -X BSLCORPUS IS OUR MAIN DATASET. IN THIS CORPUS, GLOSS ANNOTATIONS ARE ONLY AVAILABLE FOR A SUBSET OF THE VIDEOS.
utt_0028 utt 184.16 186.66 -X WE MAINLY USE THIS DATA TO TRAIN OUR MODELS.
utt_0029 utt 187.93 192.67 -X THE SECOND DATASET BSLminus oneK IS ALSO A BRITISH SIGN LANGUAGE DATASET.
utt_0030 utt 192.99 200.51 -X WE MANUALLY ANNOTATED A SMALL PORTION OF THIS TO TEST THE GENERALIZATION ABILITY OF OUR MODEL.
utt_0031 utt 200.51 209.54 -X THE PHOENIX-WEATHERminus two thousand and fourteen DATASET IS OUR LAST ONE, WHICH IS A GERMAN SIGN LANGUAGE DATASET FOR WHICH AUTOMATIC GENERATED LABELS ARE AVAILABLE.
utt_0033 utt 209.63 214.40 -X THIS DATASET IS MAINLY USED TO TEST THE CROSS-LINGUAL GENERALISATION PERFORMANCE.
utt_0034 utt 216.83 223.46 -X TO GET THE TIMES OF THE SIGN BOUNDARIES WE PROPOSE THE USAGE OF AN IthreeD MODEL TO GET SPATIOTEMPORAL FEATURES.
utt_0035 utt 224.54 229.32 -X THESE FEATURES ARE PROCESSED WITH A MULTI-STAGE TEMPORAL CONVOLUTIONAL NETWORK.
utt_0036 utt 230.75 235.97 -X IN ORDER TO TRAIN THE IthreeD MODEL WE USE A RANDOMLY CHOSEN sixteen FRAME INPUT.
utt_0037 utt 236.42 241.54 -X THESE FRAMES ARE FED INTO THE IthreeD BACKBONE WHICH GENERATES SPATIOTEMPORAL FEATURES.
utt_0038 utt 242.37 247.88 -X A CLASSIFICATION LAYER ON TOP OF THIS FEATURE VECTOR GENERATES THE SIGN CLASS PROBABILITIES.
utt_0039 utt 249.38 254.22 -X DURING TRAINING, WE ALWAYS USE THE LABEL OF THE MIDDLE FRAME TO CALCULATE THE LOSS.
utt_0040 utt 254.88 261.26 -X AFTER THIS TRAINING, WE ONLY USE THE BACKBONE TO GENERATE FEATURE VECTORS OF THE WHOLE VIDEO WITH A SLIDING WINDOW.
utt_0041 utt 263.65 269.10 -X THESE FEATURE VECTORS ARE THEN USED TO TRAIN THE MULTI-STAGE TEMPORAL CONVOLUTIONAL NETWORK OR MS-TCN.
utt_0042 utt 270.18 277.16 -X THIS IS TRAINED AS A FRAME-LEVEL BINARY CLASSIFICATION. WE FOLLOWED THE WORK OF FARHA ET AL. FOR THE TRAINING PROCESS.
utt_0043 utt 278.66 281.48 -X WE NOW WANT TO GIVE SOME QUANTITATIVE RESULTS.
utt_0044 utt 281.70 285.19 -X WE FIRST SHOW THE IMPACT OF PRETRAINING THE IthreeD NETWORK.
utt_0045 utt 285.48 293.58 -X WE CAN SEE HERE THAT FINETUNING THE IthreeD BACKBONE WITH BSLCORPUS SIGNIFICANTLY IMPROVES PERFORMANCE.
utt_0046 utt 293.58 298.28 -X FURTHER, WE CAN SEE THAT PRETRAINING WITH BSLminus oneK IS NOT NECESSARY.
utt_0047 utt 300.46 308.81 -X WE NOW COMPARE THE RESULTS WITH OUR REIMPLEMENTATION OF THE PREVIOUS STATE OF THE ART WHICH USES GEOMETRIC FEATURES AND A RANDOM FOREST CLASSIFIER.
utt_0049 utt 309.61 315.44 -X HERE YOU CAN SEE THE RESULTS ON BSLCORPUS. THIS WAS THE DATASET WE USED FOR THE TRAINING.
utt_0050 utt 315.44 320.72 -X A FIRST IMPROVEMENT CAN BE OBTAINED BY USING THE MS-TCN INSTEAD OF THE RANDOM FOREST CLASSIFIER.
utt_0051 utt 321.51 329.65 -X CHANGING THE FEATURES FROM GEOMETRIC FEATURES TO SPATIOTEMPORAL FEATURES OBTAINED BY IthreeD WE GET A FURTHER SIGNIFICANT IMPROVEMENT.
utt_0053 utt 332.87 337.71 -X TO TEST THE GENERALIZATION ABILITY WE USED THE SAME MODEL ON THE TWO OTHER DATASETS.
utt_0054 utt 338.06 345.65 -X FIRST ON BSLminus oneK WHERE WE CAN SEE THAT WE ARE ALSO ABLE TO OUTPERFORM THE STATE OF THE ART.
utt_0055 utt 345.65 352.37 -X AND SECOND ON THE GERMAN SIGN LANGUAGE DATASET PHOENIXfourteen WHERE WE CAN SEE A LIMITED BUT REASONABLE PERFORMANCE.
utt_0056 utt 352.81 357.81 -X THIS RESULT INDICATES THAT THE MODEL HAS LEARNED SOME COMMON VISUAL CUES BETWEEN THE LANGUAGES.
utt_0057 utt 357.81 365.07 -X HERE YOU CAN SEE SOME QUALITATIVE RESULTS. THE VIDEO IS SLOWED DOWN BY A FACTOR OF SIX.
utt_0058 utt 365.36 394.23 -X ON THE BOTTOM, WE SHOW THE GROUND-TRUTH AND THE PREDICTION OF OUR MODEL.
utt_0059 utt 394.23 397.81 -X HERE ON THE TOP, YOU CAN SEE SOME OTHER SUCCESS CASES FOR BSLCORPUS.
utt_0060 utt 398.77 402.10 -X BELOW THIS YOU CAN SEE SOME OF THE LIMITATIONS OF THE MODEL.
utt_0061 utt 402.58 410.45 -X THIS INCLUDES OVER-SEGMENTING FINGERSPELLING OR ABRUPT CHANGES DURING A SIGN AND UNDER-SEGMENTING VERY SHORT SIGNS.
utt_0062 utt 411.60 416.60 -X ON THE BOTTOM, WE SHOW TWO RANDOMLY CHOSEN EXAMPLES OF BSLminus oneK AND PHOENIXfourteen.
utt_0063 utt 416.60 421.01 -X YOU CAN FIND CORRESPONDING VIDEOS ON OUR PROJECT PAGE.
utt_0064 utt 422.64 424.66 -2.2816 THANK YOU FOR YOUR ATTENTION!
