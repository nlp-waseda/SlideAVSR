utt_0000 utt 0.42 7.41 -X HELLO EVERYONE, IN THIS VIDEO WE INTRODUCE OUR CVPR HIGHLIGHT PAPER AUTOAD: MOVIE DESCRIPTION IN CONTEXT.
utt_0002 utt 8.20 13.36 -X AD STANDS FOR AUDIO DESCRIPTION, WHICH IS A NARRATION DESCRIBING VISUAL ELEMENTS IN MOVIES.
utt_0004 utt 13.55 17.71 -X WE AIM TO GENERATE AD WITH COMPUTER VISION MODELS AUTOMATICALLY.
utt_0005 utt 17.71 22.77 -X OUR MODEL USES PROMPT TUNING METHOD ON GPTtwo FOR VIDEO DESCRIPTION.
utt_0006 utt 22.77 28.72 -X WE FEED IN VISUAL, CONTEXTUAL AD, AND MOVIE SUBTITLES TO THE MODEL.
utt_0007 utt 30.00 34.74 -X TRAINING SUCH A MODEL IS CHALLENGING DUE TO VERY LIMITED AMOUNT OF COMPLETE MOVIE DATA,
utt_0008 utt 34.86 39.79 -X THAT IS, HAVING THE CORRESPONDING VISUAL, AD, AND SUBTITLES TOGETHER.
utt_0009 utt 40.14 47.28 -X WE PROPOSE TO PRE-TRAIN ON PARTIAL DATA LIKE VIDEO-TEXT PAIRS OR TEXT-ONLY AUDIO DESCRIPTIONS.
utt_0010 utt 48.78 51.47 -X OUR MODEL PRODUCES RESULTS LIKE THIS.
utt_0011 utt 51.53 58.83 -X IT HAS ACCESS TO THE CONTEXT AD, SUBTITLES, AND THE MOVIE CLIP, AND IT GENERATES AD FOR THIS MOVIE CLIP.
utt_0013 utt 65.45 69.33 -X NEXT, WE WILL INTRODUCE MORE DETAILS OF THE PAPER.
utt_0014 utt 69.65 76.18 -X WE WILL COVER THESE FOUR PARTS: THE AUDIO DESCRIPTION, OUR METHOD, DATA PROCESSING,
utt_0015 utt 76.18 77.33 -X AND THE RESULTS.
utt_0016 utt 78.99 82.07 -X FIRST, LET ME SHOW YOU A SHORT MOVIE CLIP.
utt_0017 utt 82.07 84.98 -X THIS CLIP IS TAKEN FROM THE MOVIE OUT OF SIGHT.
utt_0018 utt 84.98 95.76 -X CAN I BUY YOU A DRINK?
utt_0019 utt 97.65 115.25 -X YEAH I'D LOVE ONE.
utt_0020 utt 115.25 119.38 -X NEXT, THIS IS THE SAME MOVIE CLIP BUT WITH AUDIO DESCRIPTIONS.
utt_0021 utt 120.02 122.42 -X [AD] A MAN APPROACHES TOYING WITH A LIGHTER.
utt_0022 utt 122.42 128.15 -X [AD] SHE TURNS HER HEAD AND FINDS JACK STANDING BESIDE HER.
utt_0023 utt 128.15 134.68 -X [SUBTITLE] CAN I BUY YOU A DRINK?
utt_0025 utt 136.66 137.88 -X [SUBTITLE] SIT DOWN.
utt_0026 utt 137.88 143.57 -X [AD] HE TAKES THE SEAT OPPOSITE AND THEN PLACES HIS LIGHTER ON THE TABLE.
utt_0027 utt 143.57 146.85 -X [AD] SHE OPENS HER MOUTH AS IF TO SPEAK BUT NO WORDS COME
utt_0034 utt 179.44 194.42 -X WE ARE INTERESTED IN THIS CHALLENGING AD GENERATION TASK BECAUSE IT REQUIRES A LONG-TERM VISUAL UNDERSTANDING, MULTIMODAL UNDERSTANDING LIKE VISUAL, SPEECH, AUDIO, AND SO ON, AND FINE-GRAINED VISUAL RECOGNITION.
utt_0037 utt 194.42 199.03 -X ALSO BECAUSE OF THE GREAT SOCIAL IMPACT FOR THE VISUALLY IMPAIRED.
utt_0038 utt 200.47 213.94 -X OUR MODEL USES A PRE-TRAINED GPTtwo FOR TEXT GENERATION ALL THE CONDITIONAL INFORMATION ARE ADDED AS PROMPTING VECTORS TO THE MODEL LIKE THE VISUAL FEATURES, THE CONTEXTUAL AD,
utt_0040 utt 213.94 215.51 -X AND THE MOVIE SUBTITLES.
utt_0041 utt 216.44 222.81 -X HOWEVER SUCH A MODEL IS REALLY HARD TO BE TRAINED OR FINE-TUNED DUE TO THE LACK OF TRAINING DATA.
utt_0043 utt 223.51 231.19 -X THERE ARE A MASSIVE AMOUNT OF WEB VIDEOS BUT THE MOVIE DATA IS A VERY VERY SMALL PORTION OF THEM.
utt_0045 utt 231.19 240.47 -X FURTHERMORE, AD GENERATION REQUIRES CORRESPONDING VISUAL, SUBTITLES, AND AD DATA FOR THE SAME MOVIE WHICH IS EVEN MORE LIMITED.
utt_0047 utt 242.68 248.51 -X TO OVERCOME THIS CHALLENGE, WE PROPOSE TO PRE-TRAIN OUR MODEL WITH PARTIAL DATA.
utt_0048 utt 248.85 255.26 -X FOR INSTANCE WE CAN USE A VISUAL-TEXTUAL PAIRED DATA LIKE CONCEPTUAL CAPTIONS OR WEBVID
utt_0049 utt 255.41 257.34 -X TO TRAIN THE VISUAL MODULE.
utt_0050 utt 259.51 264.86 -X AND WE CAN USE THE TEXT-ONLY AD DATA TO TRAIN THE CONTEXT AD MODULE.
utt_0051 utt 267.16 279.61 -X IN OUR EXPERIMENTS, WE FIND THE EXISTING MOVIE AUDIO DESCRIPTION DATASET MAD HAS A SUBSTANTIAL AMOUNT OF NOISE, LIKE THE INCORRECT WORDS OR DIALOGUE LEAKAGES.
utt_0053 utt 280.15 286.95 -X THIS IS BECAUSE MAD SOURCES THE TEXT DATA FROM AUDIOVAULT WEBSITE WHICH ONLY PROVIDES
utt_0054 utt 287.22 293.56 -X MPthree AUDIO FILES WITH FUSED MOVIE AUDIO TRACK AND AUDIO DESCRIPTIONS.
utt_0055 utt 293.56 298.65 -X EXTRACTING AD IN THE TEXT FORM REQUIRES NON-TRIVIAL PRE-PROCESSING.
utt_0056 utt 299.38 312.19 -X TO SOLVE THIS PROBLEM, WE PROPOSE TO USE THE TIME-ACCURATE ASR MODEL WHISPERX, TOGETHER WITH THE SPEAKER DIARIZATION MODEL TO OBTAIN BOTH THE AD AND SUBTITLES FROM THE MIXED AUDIO FILE.
utt_0059 utt 312.57 321.76 -X WE USE THE SAME PIPELINE TO DENOISE MAD DATASET AND ALSO COLLECT AND DENOISE MORE MOVIE ADS FROM THE AUDIOVAULT WEBSITE
utt_0061 utt 323.64 329.61 -X USING OUR IMPROVED PIPELINE THE DATA SET QUALITY IS MUCH BETTER THAN THE ORIGINAL VERSION
utt_0062 utt 332.92 341.79 -X NEXT FEW SLIDES ARE EXPERIMENTAL RESULTS FIRST WE SHOW THAT CLEANING THE MAD DATASET IMPROVED THE AD GENERATION QUALITY.
utt_0064 utt 342.04 353.12 -X FOLLOWING PREVIOUS WORKS, THE TEXT-ONLY AD DATA HAS TWO FORMS: NAMED AND UNNAMED, WHERE THE UNNAMED VERSION REPLACES THE CHARACTER NAMES WITH SOMEONE.
utt_0066 utt 354.55 361.95 -X SECOND, THIS PLOT SHOWS THE BENEFITS OF CONTEXT AND PARTIAL DATA PRE-TRAINING.
utt_0067 utt 361.95 366.01 -X BUT THE SUBTITLE INPUT DOES NOT HELP MUCH IN OUR EXPERIMENT
utt_0068 utt 368.44 379.17 -X WE ALSO SHOW THAT A LONGER AD CONTEXT IS HELPFUL FOR AD GENERATION FOR THE MODELS WITH OR WITHOUT PARTIAL DATA PRE-TRAINING.
utt_0070 utt 379.17 381.37 -X MORE QUALITATIVE RESULTS ARE SHOWN HERE.
utt_0071 utt 381.56 390.88 -X NOTE THAT OUR MODEL CANNOT DESCRIBE CHARACTER NAMES YET, AND THERE ARE SOME ERRORS IN THE ACTION DESCRIPTION, COUNTING, OR FINE-GRAIN RECOGNITION
utt_0073 utt 395.42 400.16 -X TO SUMMARIZE, IN THIS PAPER WE DEFINE THE AD GENERATION TASK.
utt_0074 utt 400.41 405.50 -X WE PROVIDE DATA SET FOR IT WE PROPOSE MODELS AND EFFECTIVE TRAINING METHOD.
utt_0075 utt 406.20 410.43 -X HOWEVER, THE CURRENT AUTOAD SYSTEM HAS ITS LIMITATIONS.
utt_0076 utt 410.75 417.09 -X FOR EXAMPLE, IT CANNOT REFERENCE CHARACTER NAMES OR CANNOT PROPOSE WHEN TO GENERATE AD.
utt_0077 utt 417.50 421.28 -X THE FINE GRAIN UNDERSTANDING NEEDS IMPROVEMENTS AS WELL.
utt_0078 utt 423.90 425.89 -X THANK YOU FOR WATCHING.
utt_0079 utt 425.89 428.75 -2.0139 PLEASE VISIT OUR PROJECT PAGE FOR MORE DETAILS
