utt_0000 utt 0.30 9.55 -X HI, I’M LIOR, AND I WILL PRESENT TO YOU OUR RECENT WORK ON -“MULTIVIEW NEURAL SURFACE RECONSTRUCTION WITH IMPLICIT LIGHTING AND MATERIAL”.
utt_0002 utt 9.55 14.06 -X IN THIS WORK WE ADDRESS THE CHALLENGING PROBLEM OF MULTIVIEW threeD SURFACE RECONSTRUCTION
utt_0003 utt 14.35 25.65 -X GIVEN twoD IMAGES CAPTURING A REAL OBJECT FROM MULTIPLE VIEWS, OUR GOAL IS TO INFER THE threeD GEOMETRY OF THE OBJECT, ITS APPEARANCE, AND THE CAMERAS WHICH CAPTURED THOSE IMAGES.
utt_0005 utt 26.22 33.49 -X WE PRESENT IMPLICIT DIFFERENTIABLE RENDERER: A NEURAL NETWORK ARCHITECTURE THAT SIMULTANEOUSLY LEARNS THOSE three UNKNOWNS.
utt_0007 utt 34.00 44.43 -X IDR ABLE TO PRODUCE HIGH FIDELITY threeD SURFACE RECONSTRUCTION, BY DISENTANGLING GEOMETRY AND APPEARANCE, LEARNED SOLELY FROM MASKED twoD IMAGES AND ROUGH CAMERA ESTIMATES.
utt_0009 utt 45.74 53.81 -X A RECENT SUCCESSFUL NEURAL NETWORK APPROACH TO SOLVING THIS PROBLEM IS BY FEEDING THOSE three UNKNOWNS INTO A DIFFERENTIABLE RENDERING SYSTEM.
utt_0011 utt 53.97 61.20 -X THAT IS, SIMULATE THE RENDERING OF THE SCENE FROM A GIVEN VIEW, AND COMPARING THE RENDERED IMAGE TO THE ORIGINAL IMAGE.
utt_0013 utt 61.46 69.36 -X THE KEY CHALLENGE IS HOW TO MAKE THE RENDERER A FUNCTION OF THE GEOMETRY, THAT IS INDEPENDENT OF THE OBJECT MATERIAL OR THE SCENE LIGHTING.
utt_0015 utt 70.80 82.96 -X A RECENT WORK BY NIEMEYER ET AL., INTRODUCED SUCH DIFFERENTIAL RENDERER MODEL THAT CAN REPRESENT ARBITRARY TEXTURE, BUT CANNOT HANDLE REFLECTANCE AND LIGHTING EFFECTS, NOR CAN IT HANDLE NOISY CAMERAS.
utt_0018 utt 84.14 95.13 -X CONCURRENTLY TO OUR WORK, NERF USED NEURAL RENDERING FOR NOVEL VIEWS SYNTHESIS FROM A SET OF IMAGES WITH KNOWN CAMERAS, WHERE DIFFERENTLY FROM IDR THEIR METHOD DOESN’T PRODUCE A
utt_0020 utt 95.13 100.02 -X SURFACE RECONSTRUCTION OF THE SCENE’S GEOMETRY, RATHER THAN A three-DIMENSIONAL DENSITY FIELD.
utt_0021 utt 100.85 113.30 -X IN OUR WORK, WE RECONSTRUCT AN IMPLICIT SURFACE TOGETHER WITH A SURFACE LIGHT FIELD THAT IS SEPARATED FROM THE GEOMETRY, AND WE CAN HANDLE BOTH EXACT AND NOISY CAMERA INFORMATION.
utt_0023 utt 113.30 121.27 -X OUR GEOMETRY IS REPRESENTED AS THE ZERO LEVEL SET OF A NEURAL NETWORK F, WHICH MODEL FOR EACH threeD POINT ITS SIGN DISTANCE FUNCTION TO THE SHAPE.
utt_0025 utt 121.49 129.21 -X GIVEN A LEARNABLE CAMERA POSITION AND SOME FIXED IMAGE PIXEL, WE WOULD LIKE TO PRODUCE DIFFERENTIABLE RGB VALUES.
utt_0027 utt 129.49 138.42 -X THE CAMERA ORIENTATION AND PIXEL DEFINE A VIEWING DIRECTION, AND WE CAN TRACE FOR THE FIRST INTERSECTION OF THE VIEWING RAY WITH THE IMPLICIT SURFACE.
utt_0029 utt 139.92 148.25 -X THE FIRST STEP IS TO REPRESENT THE INTERSECTION POINT AND ITS NORMAL AS A DIFFERENTIAL FUNCTIONS OF THE IMPLICIT GEOMETRY AND THE CAMERA PARAMETERS.
utt_0031 utt 148.28 156.31 -X WE IMPLEMENT IT BY SIMPLY COMPOSING THE NEURAL NETWORK WITH A FIXED LINEAR COMPUTATION AT ITS ENTRANCE AND ANOTHER AT ITS OUTPUT.
utt_0033 utt 158.10 165.08 -X SECONDLY, WE WANT TO APPROXIMATE THE COLOR OF THE PIXEL, DETERMINED BY THE RADIANCE REFLECTED FROM THE SURFACE TO THE CAMERA.
utt_0035 utt 165.21 170.84 -X OUR INTEREST IS THAT THE RENDERER WILL NOT MEMORIZE ANY PART OF THE GEOMETRY OR THE VIEWING CAMERAS.
utt_0037 utt 171.09 175.93 -X THEREFORE, WE SUGGEST REPRESENTING THE LIGHT FIELD AS A FUNCTION OF THE SURFACE POSITION,
utt_0038 utt 175.93 178.49 -X SURFACE NORMAL, AND VIEWING DIRECTION.
utt_0039 utt 178.58 183.07 -X THIS IS IMPLEMENTED USING A SECOND NEURAL NETWORK TO OUTPUT RGB VALUES.
utt_0040 utt 183.64 191.45 -X INCORPORATING THE NORMAL AND THE VIEWING DIRECTION IS NECESSARY FOR threeD RECONSTRUCTION THAT IS DECOUPLED FROM THE APPEARANCE AND THE CAMERAS.
utt_0042 utt 191.77 200.51 -X THIS CLAIM CAN BE EXPLAINED USING THIS SIMPLE EXAMPLE A RENDERER WITHOUT NORMAL WILL PRODUCE THE SAME LIGHT ESTIMATION IN THOSE TWO CASES,
utt_0044 utt 200.66 205.28 -X THEREFORE CAN RESULT IN A RENDERER THAT COMPENSATES OVER GEOMETRY PROPERTIES.
utt_0045 utt 205.98 215.39 -X A RENDERER WITHOUT VIEWING DIRECTION WILL PRODUCE THE SAME LIGHT ESTIMATION IN THOSE TWO CASES, WHEREIN REAL-LIFE THE SCENE APPEARANCE IS LIKELY TO BE VIEW-DEPENDENT.
utt_0047 utt 216.63 224.22 -X TO COMPLETE THE IDR MODEL, WE INTRODUCE A GLOBAL FEATURE VECTOR OF THE GEOMETRY, TO GET OUR FINAL RADIANCE APPROXIMATION.
utt_0049 utt 224.22 229.92 -X WHICH THEN COMPARED TO THE GROUND TRUTH PIXEL COLOR, TO SIMULTANEOUSLY TRAIN THE MODEL’S PARAMETERS.
utt_0051 utt 231.83 237.73 -X WE APPLY OUR MULTIVIEW SURFACE RECONSTRUCTION MODEL TO REAL twoD IMAGES FROM THE DTU DATASET.
utt_0052 utt 238.07 249.82 -X HERE WE SHOW THE RECONSTRUCTED GEOMETRY, I.E THE ZERO LEVEL SET OF THE IMPLICIT FUNCTION F, AND RENDERING OF NOVEL VIEWS GAINED FROM THE NEURAL RENDERER M, WHEN USING FIXED GROUND TRUTH CAMERAS.
utt_0055 utt 250.71 261.79 -X TOWARDS THE GOAL OF DISENTANGLING GEOMETRY AND APPEARANCE, WE SHOW THAT WE ABLE TO TRANSFER THE APPEARANCE LEARNED FROM ONE SCENE TO DIFFERENT GEOMETRY, BY SIMPLY SWITCH BETWEEN THE RENDERING NETWORKS.
utt_0058 utt 262.33 272.10 -X NOTE THAT WITHOUT USING THE NORMAL IN THE RENDERER, THE GEOMETRY IS NOT WELL APPROXIMATED AND THE RENDERER FAILS TO PRODUCE A PLAUSIBLE RENDERING OF DIFFERENT GEOMETRIES,
utt_0060 utt 272.10 277.44 -X ALTHOUGH THE LIGHT FIELD APPROXIMATION LOOKS REASONABLE.
utt_0061 utt 278.43 282.62 -X HERE ARE RESULTS IN THE SETUP OF TRAINABLE CAMERAS WITH NOISY INITIALIZATIONS.
utt_0062 utt 282.84 288.03 -X WE SHOW OUR SURFACE RECONSTRUCTION COMPARED TO THE POPULAR NON-DEEP LEARNING APPROACH COLMAP.
utt_0064 utt 288.22 294.85 -X WE FURTHER SHOW RESULT OF IDR TRAINING WITH FIXED CAMERAS SET TO THE INACCURATE CAMERA INITIALIZATIONS.
utt_0066 utt 294.88 301.86 -X THIS INDICATES THAT THE OPTIMIZATION OF CAMERA PARAMETERS TOGETHER WITH THE threeD RECONSTRUCTION IS INDEED SIGNIFICANT.
utt_0068 utt 302.78 304.96 -X HERE ARE SOME MORE RESULTS OF OUR METHOD.
utt_0069 utt 305.15 311.71 -X FOR MORE DETAILS YOU ARE WELCOME TO TAKE A LOOK AT OUR PAPER, AND STAY TUNED BECAUSE OUR CODE AND DATA WILL BE AVAILABLE SOON.
utt_0071 utt 311.71 313.54 -1.9670 THANK YOU FOR LISTENING.
