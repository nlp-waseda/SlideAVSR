utt_0000 utt 0.19 4.37 -X HELLO AND WELCOME TO THIS UNUSUAL AI COFFEE BREAK!
utt_0001 utt 4.37 9.94 -X TODAY WE’LL SHARE WITH YOU SOME OF OUR OWN WORK, WHICH WAS ACCEPTED AT ACL two thousand and twenty-two.
utt_0002 utt 11.50 24.50 -X I KNOW WHAT YOU COULD THINK: IT MIGHT NOT SEEM LIKE MUCH, ESPECIALLY WHEN WE COMPARE OUR WORK WITH PAPERS THAT WE HAVE PREVIOUSLY COVERED ON THE CHANNEL, COMING FROM BIG COMPANIES
utt_0004 utt 24.50 30.29 -X AND MANY AUTHORS, BUT YOU KNOW, WE ARE PROUD OF OUR PAPER, IT IS HONEST WORK!
utt_0005 utt 30.29 41.07 -X WE’LL BE PRESENTING THIS AT ACL two thousand and twenty-two IN THE LAST WEEK OF MAY, SO IN CASE YOU WILL BE ATTENDING THE ACL CONFERENCE TOO, I GUESS WE’LL SEE YOU IN DUBLIN!
utt_0007 utt 41.36 44.15 -X DON’T HESITATE TO SAY HI IF YOU’RE AROUND!
utt_0008 utt 44.27 49.49 -X OTHERWISE, YOU CAN HAVE A LOOK AT WHAT WE HAVE BEEN WORKING ON RECENTLY, IN THIS VIDEO.
utt_0009 utt 49.65 50.39 -X ENJOY!
utt_0010 utt 51.60 52.56 -X HELLO!
utt_0011 utt 52.56 65.17 -X WE ARE HAPPY TO PRESENT OUR WORK ON „VALSE”, A TASK-INDEPENDENT BENCHMARK MEANT FOR TESTING VISION AND LANGUAGE MODELS WITH SPECIFIC LINGUISTIC PHENOMENA.
utt_0013 utt 65.87 69.62 -X WHY DID WE DO THE TROUBLE IN SETTING UP THIS BENCHMARK?
utt_0014 utt 69.94 81.59 -X WELL, DURING THE LAST YEARS, WE HAVE SEEN AN EXPLOSION OF TRANSFORMER-BASED VISION AND LANGUAGE MODELS PRETRAINED ON LARGE AMOUNTS OF IMAGE-TEXT PAIRS.
utt_0016 utt 81.78 94.58 -X EACH ONE OF THESE MODELS PUSHES STATE-OF-THE ART ON VISION AND LANGUAGE TASKS, SUCH AS VISUAL QUESTION ANSWERING, VISUAL COMMONSENSE REASONING, IMAGE RETRIEVAL, PHRASE GROUNDING.
utt_0018 utt 94.58 100.68 -X SO, WE GOT THE MESSAGE, THE ACCURACIES ON THESE TASK-SPECIFIC BENCHMARKS ARE INCREASING
utt_0019 utt 100.69 107.35 -X STEADILY, BUT DO WE KNOW WHAT THE MODELS HAVE ACTUALLY LEARNED?
utt_0020 utt 107.35 117.02 -X WHAT IS IT THAT A VISION AND LANGUAGE TRANSFORMER “UNDERSTOOD” WHEN ASSIGNING A HIGH SCORE FOR THIS IMAGE AND THIS SENTENCE TO MATCH?
utt_0022 utt 117.84 119.93 -X AND A LOW SCORE FOR THIS ONE?
utt_0023 utt 122.55 125.18 -X DO VL MODELS FOCUS ON THE RIGHT THING?
utt_0024 utt 125.20 129.56 -X OR DO THEY FOCUS ON BIASES AS SHOWN BY PREVIOUS WORK?
utt_0025 utt 130.39 138.55 -X TO SHED MORE LIGHT ON THIS ASPECT, WE PROPOSE A MORE TASK-AGNOSTIC DIRECTION AND INTRODUCE
utt_0026 utt 138.55 150.43 -X VALSE THAT TESTS THE SENSITIVITY OF VL MODELS TO SPECIFIC LINGUISTIC PHENOMENA THAT AFFECT BOTH THE LINGUISTIC AND THE VISUAL MODALITIES.
utt_0028 utt 150.77 157.76 -X WE TARGET EXISTENCE, PLURALITY, COUNTING, SPATIAL RELATIONS, ACTIONS, AND ENTITY COREFERENCE.
utt_0029 utt 158.04 164.06 -X BUT HOW DO WE TEST WHETHER THE VL MODELS HAVE CAPTURED THESE PHENOMENA?
utt_0030 utt 164.57 176.89 -X BY FOILING, A METHOD PREVIOUSLY APPLIED FOR VL MODELS ONLY FOR NOUN PHRASES BY RAVI SHEKHAR AND COLLABORATORS, AND ON COUNTING, BY US IN PREVIOUS WORK.
utt_0032 utt 177.30 189.95 -X FOILING BASICALLY MEANS THAT WE TAKE THE CAPTION OF AN IMAGE AND PRODUCE A FOIL BY ALTERING THE CAPTION SUCH THAT IT DOES NOT DESCRIBE THE IMAGE ANYMORE.
utt_0034 utt 190.20 198.21 -X AND WE DO THESE PHRASE ALTERATIONS BY FOCUSING ON six SPECIFIC PIECES, SUCH AS EXISTENCE, PLURALITY,
utt_0035 utt 198.21 212.93 -X COUNTING, SPATIAL RELATIONS, ACTIONS, AND ENTITY COREFERENCE, WHERE EACH PIECE CAN CONSIST OF ONE OR MORE INSTRUMENTS, IN CASE WE FOUND MORE THAN ONE WAY TO CREATE FOIL INSTANCES.
utt_0037 utt 213.28 225.89 -X FOR EXAMPLE, IN THE CASE OF THE ACTIONS PIECE, WE HAVE TWO INSTRUMENTS: ONE IN WHICH THE ACTION VERB IS CHANGED WITH A DIFFERENT ACTION AND ONE IN WHICH ACTANTS ARE SWAPPED.
utt_0039 utt 226.11 231.23 -X COUNTING AND COREFERENCE ARE ALSO PIECES THAT HAVE MORE THAN ONE INSTRUMENT.
utt_0040 utt 231.36 240.35 -X WE CREATE THESE FOILS BY MAKING SURE THAT THEY FAIL TO DESCRIBE THE IMAGE, THAT THEY ARE GRAMMATICAL AND OTHERWISE VALID SENTENCES.
utt_0042 utt 240.67 248.23 -X THIS IS NOT EASY TO DO BECAUSE A FOILED CAPTION MAY BE LESS LIKELY THAN THE ORIGINAL CAPTION:
utt_0043 utt 248.29 261.41 -X FOR EXAMPLE, THOUGH NOT IMPOSSIBLE, IT IS STATISTICALLY LESS LIKELY FOR PLANTS TO CUT A MAN THAN A MAN TO CUT PLANTS AND LARGE VL MODELS COULD PICK UP ON THIS.
utt_0045 utt 261.60 271.40 -X THEREFORE, TO OBTAIN VALID FOILS, WE MUST TAKE ACTION: FIRST, WE MAKE USE OF STRONG LANGUAGE MODELS TO PROPOSE FOILS.
utt_0047 utt 271.65 285.99 -X SECOND, WE USE NATURAL LANGUAGE INFERENCE TO FILTER OUT FOILS THAT COULD BE STILL DESCRIBING THE IMAGE, SINCE WHEN CONSTRUCTING FOILS, WE NEED TO ENSURE THAT THEY FAIL TO DESCRIBE THE IMAGE.
utt_0050 utt 286.24 298.44 -X TO TEST THIS AUTOMATICALLY, WE APPLY NATURAL LANGUAGE INFERENCE (NLI) WITH THE FOLLOWING RATIONALE: WE CONSIDER AN IMAGE TO BE THE PREMISE AND ITS CAPTION ITS ENTAILED HYPOTHESIS.
utt_0052 utt 298.79 303.97 -X IN ADDITION, WE CONSIDER THE CAPTION TO BE THE PREMISE AND THE FOIL IS ITS HYPOTHESIS.
utt_0053 utt 305.19 311.49 -X IF AN NLI MODEL PREDICTS THE FOIL TO CONTRADICT OR TO BE NEUTRAL WITH RESPECT TO THE CAPTION,
utt_0054 utt 311.55 315.49 -X WE TAKE THIS AS AN INDICATOR OF A VALID FOIL.
utt_0055 utt 315.75 329.35 -X IF AN NLI MODEL PREDICTS THE FOIL TO BE ENTAILED BY THE CAPTION, IT CANNOT BE A GOOD FOIL SINCE BY TRANSITIVITY IT WILL GIVE A TRUTHFUL DESCRIPTION OF THE IMAGE AND WE FILTER THESE FOILS OUT.
utt_0057 utt 329.48 343.21 -X BUT THIS PROCEDURE IS NOT PERFECT, IT IS JUST AN INDICATOR FOR VALID FOILS, THEREFORE AS A THIRD MEASURE FOR GENERATING VALID FOILS, WE EMPLOY HUMAN ANNOTATORS TO VALIDATE THE DATA USED IN VALSE.
utt_0060 utt 343.91 352.68 -X SO, AFTER FILTERING AND HUMAN EVALUATION, WE HAVE AS MANY TEST INSTANCES AS DESCRIBED IN THIS TABLE.
utt_0062 utt 352.68 361.51 -X NOTE THAT VALSE DOES NOT DELIVER ANY TRAINING DATA, BUT ONLY TEST DATA SINCE IT IS A ZERO-SHOT TESTING BENCHMARK ONLY.
utt_0064 utt 361.57 368.75 -X IT IS DESIGNED TO LEVERAGE THE EXISTING CAPABILITIES OF VL MODELS AFTER PRE-TRAINING.
utt_0065 utt 368.93 375.08 -X FINE-TUNING WOULD ONLY ENABLE MODELS TO EXPLOIT ARTEFACTS OR STATISTICAL BIASES IN THE DATA.
utt_0066 utt 375.46 388.01 -X WE ALL KNOW THAT THESE MODELS LIKE TO CHEAT AND TAKE SHORTCUTS AND AS WE SAID, WE ARE INTERESTED IN ASSESSING WHAT CAPABILITIES THE VL MODELS HAVE AFTER PRE-TRAINING.
utt_0068 utt 388.01 397.90 -X WE EXPERIMENT WITH FIVE VL MODELS ON VALSE, NAMELY WITH CLIP, LXMERT, VILBERT, VILBERT twelve-INminus one AND VISUALBERT.
utt_0070 utt 398.12 407.79 -X TWO OF OUR MOST IMPORTANT EVALUATION METRICS ARE: THE ACCURACY OF THE MODELS IN CLASSIFYING IMAGE-SENTENCE PAIRS INTO CAPTIONS AND FOILS.
utt_0072 utt 408.10 421.61 -X PERHAPS MORE RELEVANT FOR THIS VIDEO, WE WILL SHOWCASE OUR MORE PERMISSIVE METRIC, THE PAIRWISE ACCURACY WHICH MEASURES WHETHER THE IMAGE-SENTENCE ALIGNMENT SCORE IS GREATER FOR A CORRECT IMAGE-TEXT
utt_0074 utt 421.61 424.43 -X PAIR THAN FOR ITS FOILED PAIR.
utt_0076 utt 428.24 435.05 -X THE RESULTS WITH PAIRWISE ACCURACY ARE SHOWN HERE AND THEY ARE CONSISTENT WITH THE RESULTS WE GOT WITH THE OTHER METRICS.
utt_0078 utt 435.63 442.06 -X THE BEST ZERO-SHOT PERFORMANCE IS ACHIEVED BY VILBERT twelve-INminus one, FOLLOWED BY VILBERT, LXMERT,
utt_0079 utt 442.06 444.08 -X CLIP AND FINALLY VISUALBERT.
utt_0080 utt 444.40 458.13 -X IT'S NOTABLE HOW INSTRUMENTS CENTERED ON INDIVIDUAL OBJECTS LIKE EXISTENCE AND NOUN PHRASES ARE ALMOST SOLVED BY VILBERT twelve-INminus one, HIGHLIGHTING THAT MODELS ARE CAPABLE OF IDENTIFYING NAMED
utt_0082 utt 458.13 460.21 -X OBJECTS AND THEIR PRESENCE IN IMAGES.
utt_0083 utt 460.33 466.74 -X HOWEVER, NONE OF THE REMAINING PIECES CAN BE RELIABLY SOLVED IN OUR ADVERSARIAL FOILING SETTINGS.
utt_0085 utt 466.86 478.80 -X WE SEE FROM THE PLURALITY AND COUNTING INSTRUMENTS THAT VL MODELS HAVE TROUBLE DISTINGUISHING REFERENCES TO SINGLE VS. MULTIPLE OBJECTS OR COUNTING THEM IN AN IMAGE.
utt_0087 utt 478.80 486.93 -X THE RELATION PIECE SHOWS THAT THEY HAVE DIFFICULTIES IN CORRECTLY CLASSIFYING A NAMED SPATIAL RELATION BETWEEN OBJECTS IN AN IMAGE.
utt_0089 utt 486.93 497.24 -X THEY ALSO HAVE TROUBLE DISTINGUISHING ACTIONS AND IDENTIFYING THEIR PARTICIPANTS, EVEN IF SUPPORTED BY PLAUSIBILITY BIASES, AS WE SEE IN THE ACTIONS PIECE.
utt_0091 utt 497.36 507.44 -X FROM THE COREFERENCE PIECE WE FIND OUT THAT TRACING MULTIPLE REFERENCES TO THE SAME OBJECT IN AN IMAGE BY USING PRONOUNS IS ALSO DIFFICULT FOR VL MODELS.
utt_0093 utt 508.37 520.79 -X AS A SANITY CHECK AND ALSO BECAUSE IT IS AN INTERESTING EXPERIMENT, WE ALSO BENCHMARK TWO TEXT-ONLY MODELS: GPTone AND GPTtwo TO ASSESS WHETHER VALSE IS SOLVABLE BY THESE UNIMODAL
utt_0095 utt 520.79 530.42 -X MODELS BY COMPUTING THE PERPLEXITY OF THE CORRECT AND FOILED CAPTION AND PREDICTING THE ENTRY WITH THE LOWEST PERPLEXITY.
utt_0097 utt 530.64 541.08 -X IF THE PERPLEXITY IS HIGHER FOR THE FOIL, WE TAKE THIS AS AN INDICATION THAT THE FOILED CAPTION MAY SUFFER FROM PLAUSIBILITY BIAS OR OTHER LINGUISTIC BIASES.
utt_0099 utt 541.71 551.73 -X IT IS INTERESTING TO SEE, THAT IN SOME CASES, THE TEXT-ONLY GPT MODELS HAVE CAPTURED THE PLAUSIBILITY OF THE WORLD BETTER THAN THE VISION AND LANGUAGE MODELS.
utt_0101 utt 552.66 565.78 -X TO SUM UP, VALSE IS A BENCHMARK THAT USES THE LENS OF LINGUISTIC CONSTRUCTS TO HELP THE COMMUNITY IMPROVE V&AMPL MODELS BY HARD TESTING THEIR VISUAL GROUNDING CAPABILITIES.
utt_0103 utt 566.10 578.30 -X OUR EXPERIMENTS SHOW THAT V&AMPL MODELS IDENTIFY NAMED OBJECTS AND THEIR PRESENCE IN IMAGES WELL (AS SHOWN BY THE EXISTENCE PIECE), BUT STRUGGLE TO GROUND THEIR INTERDEPENDENCE AND
utt_0105 utt 578.30 582.75 -X RELATIONSHIPS IN VISUAL SCENES WHEN FORCED TO RESPECT LINGUISTIC INDICATORS.
utt_0106 utt 583.13 591.16 -X WE WOULD REALLY LIKE TO ENCOURAGE THE COMMUNITY TO USE VALSE FOR MEASURING PROGRESS TOWARDS LANGUAGE GROUNDING WITH V&AMPL MODELS.
utt_0108 utt 592.05 605.05 -X EVEN MORE, VALSE COULD BE USED AS AN INDIRECT ASSESSMENT OF DATASETS, AS MODELS COULD BE EVALUATED BEFORE AND AFTER TRAINING OR FINE-TUNING TO SEE IF A DATASET HELPS MODELS IMPROVE ON
utt_0110 utt 605.05 608.12 -X ANY OF THE ASPECTS TESTED BY VALSE.
utt_0111 utt 608.12 613.34 -X IF YOU’RE INTERESTED, DO CHECK OUT THE VALSE DATA ON GITHUB AND IF YOU HAVE ANY QUESTIONS,
utt_0112 utt 613.34 616.41 -2.7992 DO NOT HESITATE TO CONTACT US!
