utt_0000 utt 0.03 5.78 -X HELLO EVERYONE, MY NAME IS DA YAN AND I AM AN ASSISTANT PROFESSOR FROM THE COMPUTER SCIENCE DEPARTMENT OF THE UNIVERSITY OF ALABAMA AT BIRMINGHAM.
utt_0002 utt 5.78 15.41 -X I AM HERE TO PRESENT OUR ICDE two thousand and twenty PAPER TITLED G-THINKER: A DISTRIBUTED FRAMEWORK FOR MINING SUBGRAPHS IN A BIG GRAPH FIRST, LET ME INTRODUCE OUR TARGET PROBLEM,
utt_0004 utt 15.41 18.54 -X THAT IS, TO FIND QUALIFIED SUBGRAPH INSTANCES FROM A BIG GRAPH.
utt_0005 utt 18.83 28.11 -X ONE EXAMPLE IS TO MINE DENSE SUBGRAPH STRUCTURES SUCH AS CLIQUES, QUASI-CLIQUES THAT REQUIRES EACH NODE TO BE CONNECTED TO THE MAJORITY OF OTHER NODES, AND MANY OTHER DENSE SUBGRAPH DEFINITIONS.
utt_0008 utt 28.11 34.06 -X ANOTHER EXAMPLE IS SUBGRAPH MATCHING, WHERE GIVEN A QUERY GRAPH, WE WANT TO FIND SUBGRAPH INSTANCES THAT MATCH IT IN A BIG DATA GRAPH.
utt_0010 utt 34.22 37.90 -X THIS QUERY IS USEFUL IN SEARCHING KNOWLEDGE GRAPHS AND BIOLOGICAL NETWORKS.
utt_0011 utt 38.38 49.27 -X A KEY FEATURE OF THOSE PROBLEMS THAT WE TARGET IS THAT THEIR TIME COMPLEXITY IS HIGH, OFTEN BECAUSE OF THE GIANT SEARCH SPACE RATHER THAN THE DATA VOLUME ITSELF AS IN CONVENTIONAL DATA-INTENSIVE ANALYTICS.
utt_0014 utt 49.27 58.74 -X IN THIS SLIDE, WE SHOW HOW WE CAN EXPLORE THE VERTEX SET OF A RESULT SUBGRAPH BY DEPTH-FIRST BACKTRACKING IN A SET-ENUMERATION TREE OVER ALL POSSIBLE VERTICES.
utt_0016 utt 58.74 62.16 -X THIS, FOR EXAMPLE, APPLIES TO OUR CLIQUE FINDING PROBLEM.
utt_0017 utt 62.16 69.30 -X TO AVOID REDUNDANCY, WE ONLY ADD NEW VERTICES INTO THE SET IF THEIR IDS ARE LARGER THAN THOSE VERTICES THAT ARE ALREADY IN THE SET.
utt_0019 utt 69.30 75.25 -X FOR EXAMPLE, TO GET {A,B,D}, WE DO NOT GROW {B,D} BY A, BUT RATHER GROW {A,B} BY D.
utt_0020 utt 75.95 84.21 -X IN TRADITIONAL SINGLE-THREADED ALGORITHMS, WE USUALLY SOLVE THESE PROBLEMS BY DIVIDE AND CONQUER, THAT BACKTRACKS ON THE NODES IN OUR PREVIOUS SET-ENUMERATION SEARCH TREE.
utt_0022 utt 84.56 87.89 -X LET US ILLUSTRATE BY CONSIDERING THE PROBLEM OF FINDING MAXIMAL CLIQUES.
utt_0023 utt 88.33 98.80 -X SPECIFICALLY, SINCE EACH CLIQUE IS A COMPLETE GRAPH WHERE EACH PAIR OF NODES ARE ONE HOP AWAY, WE CAN CONSTRUCT one-HOP EGO-NETWORK AROUND EACH VERTEX, AND FIND CLIQUES FROM THOSE SUBGRAPHS.
utt_0025 utt 98.80 103.83 -X IF A VERTEX, SAY Vone, HAS A HIGH DEGREE AND SO THE SUBGRAPH AROUND IT IS STILL VERY BIG,
utt_0026 utt 104.08 109.75 -X WE CAN RECURSIVELY DIVIDE IT INTO SMALL OVERLAPPING SUBGRAPHS FOR FURTHER MINING.
utt_0027 utt 109.75 115.22 -X NOW LET US ZOOM IN THAT SUBGRAPH, AND ASSUME THAT Vone IS ALREADY IN OUR RESULT CLIQUE.
utt_0028 utt 115.22 119.60 -X WE CAN THEN CONSIDER two CASES, THOSE CLIQUES CONTAINING Vthree, AND THOSE WITHOUT Vthree.
utt_0029 utt 120.21 128.82 -X THE PINK SUBGRAPH ASSUMES Vone AND Vthree ARE IN OUR CLIQUE ALREADY, AND WE CAN CONTINUE MINING CLIQUES IN THIS SUBGRAPH BY KICKING OUT THOSE VERTICES MORE THAN ONE HOP AWAY FROM Vthree
utt_0031 utt 130.03 134.48 -X FOR THOSE WITHOUT Vthree, WE CAN FURTHER DIVIDE THEM INTO THOSE WITH Vfour AND THOSE WITHOUT.
utt_0032 utt 135.31 145.78 -X THE PINK SUBGRAPH ASSUMES Vone AND Vfour ARE ALREADY IN OUR CLIQUE, AND WE KICK OUT THOSE VERTICES MORE THAN ONE HOP AWAY FROM Vfour FROM THE SUBGRAPH AND THEN CONTINUE THE MINING.
utt_0034 utt 145.78 149.33 -X WE CAN THEN CONTINUE ON THE REMAINING SUBGRAPH AND DIVIDE IT IF NECESSARY.
utt_0035 utt 149.33 155.54 -X IN FACT, THE MINING ITSELF FOLLOWS THIS RECURSIVE PROCEDURE AND EXPLORES OUR SET-ENUMERATION TREE IN DEPTH-FIRST ORDER.
utt_0037 utt 155.54 158.07 -X WE NEXT REVIEW THE RELATED WORKS THAT TACKLE THIS PROBLEM.
utt_0038 utt 159.09 172.44 -X EARLIER WORKS USE MAPREDUCE FOR DENSE SUBGRAPH MINING PROBLEMS LIKE TRIANGLE COUNTING, BUT AS THE TKDD PAPER IN THIS SLIDE SHOWS, THE AUTHORS FOUND THAT MAPREDUCE IS NOT SUITABLE FOR TRIANGLE COUNTING, AS THE FASTEST MAPREDUCE ALGORITHM AT THAT TIME TAKES OVER sixteen HUNDRED
utt_0041 utt 172.44 176.40 -X MACHINES FOR MORE THAN five MINUTES TO FIND THE TRIANGLES OF A GRAPH, ON WHICH THE AUTHORS'
utt_0042 utt 176.40 178.64 -X SINGLE-THREADED ALGORITHM ONLY NEEDS HALF A MINUTE.
utt_0043 utt 178.64 181.30 -X THIS IS A HUGE WASTE OF COMPUTING RESOURCES AND ENERGY.
utt_0044 utt 181.94 189.62 -X DUE TO THE POPULARITY OF THINK-LIKE-A-VERTEX PROGRAMMING MODEL, THERE ARE SOME WORKS SOLVING DENSE SUBGRAPH MINING AND GRAPH MATCHING USING VERTEX-CENTRIC PROGRAMS.
utt_0046 utt 189.97 198.29 -X HOWEVER, IN THE VERTEX-CENTRIC PARADIGM, VERTICES NOTIFY OTHER VERTICES ABOUT THEIR VALUE UPDATES BY SENDING MESSAGES ALONG EDGES, MAKING THE EXECUTION NETWORK IO-BOUND.
utt_0048 utt 199.34 209.08 -X ALSO, THE PROGRAMMING IS NOT INTUITIVE FOR SUBGRAPH MINING, SINCE VERTEX-CENTRIC PROGRAMS OPERATE IN THE UNIT OF VERTEX AND ARE USUALLY FOR COMPUTING VALUES FOR VERTICES, NOT FOR FINDING SUBGRAPHS.
utt_0051 utt 209.94 216.69 -X RECENTLY, A NUMBER OF SYSTEMS WERE PROPOSED FOR GRAPH MINING BASED ON THE IDEA OF SUBGRAPH-CENTRIC PROGRAMMING WHICH IS MORE INTUITIVE.
utt_0053 utt 217.59 224.37 -X HOWEVER, THEY ONLY ADDRESS THE PROGRAMMING FRIENDLINESS ISSUE BUT NOT THE LOW-EFFICIENCY ISSUE, AS THEIR EXECUTION ENGINES ARE STILL IO-BOUND.
utt_0055 utt 224.79 232.85 -X NSCALE IS THE FIRST WORK IN THIS DIRECTION, WHICH CONSTRUCTS CANDIDATE SUBGRAPHS TO MINE UPON AROUND EACH VERTEX USING K ITERATIONS OF BREADTH-FIRST SEARCH.
utt_0057 utt 233.14 237.85 -X HOWEVER, THIS IS CONDUCTED BY K MAPREDUCE JOBS, WHICH MAKES THE PROCESS NETWORK IO-BOUND.
utt_0058 utt 238.00 243.00 -X EACH MAPREDUCE JOB ALSO NEEDS TO LOAD AND DUMP A HUGE AMOUNT OF INTERMEDIATE SUBGRAPHS VIA HADOOP DISTRIBUTED FILE SYSTEM.
utt_0060 utt 243.63 250.26 -X THE SUBGRAPHS ARE THEN FINALLY DISTRIBUTED FOR CONCURRENT MINING WITH ANOTHER MAPREDUCE JOB, WHICH SUFFERS FROM THE CURSE OF THE LAST REDUCER.
utt_0062 utt 251.12 256.92 -X ARABESQUE PROPOSES A USER-FRIENDLY PROGRAMMING INTERFACE FOR GRAPH MINING, CALLED EMBEDDING-CENTRIC PROGRAMMING.
utt_0064 utt 256.92 262.93 -X HERE, AN EMBEDDING IS A MATERIALIZED SUBGRAPH, AND THESE SUBGRAPHS ARE GROWN IN INCREASING SIZE FOR CHECKING.
utt_0066 utt 262.93 267.70 -X ARABESQUE IS A DISTRIBUTED SYSTEM WHERE EVERY MACHINE NEEDS TO KEEP AN ENTIRE DATA GRAPH IN MEMORY,
utt_0067 utt 267.70 272.18 -X AND SUBGRAPH MATERIALIZATION MAKES IT NETWORK IO-BOUND.
utt_0068 utt 272.18 279.00 -X IN CONTRAST, OUR G-THINKER USES NODE BACKTRACKING IN SERIAL MINING ALGORITHMS AS MUCH AS POSSIBLE TO AVOID THE COST OF MATERIALIZING SUBGRAPHS.
utt_0070 utt 279.63 289.53 -X ARABESQUE'S API ALSO COVERS THE PROBLEM OF FREQUENT SUBGRAPH PATTERN MINING, WHICH REQUIRES ARABESQUE TO CONDUCT SUBGRAPH ISOMORPHISM CHECK ON EVERY NEWLY MATERIALIZED SUBGRAPH.
utt_0072 utt 289.62 293.33 -X BUT SUCH CHECK IS NOT NEEDED IN OTHER SUBGRAPH MINING PROBLEMS THAT WE CONSIDER.
utt_0073 utt 294.07 301.59 -X RECALL THAT OUR SET-ENUMERATION TREE PERFECTLY DIVIDES THE SEARCH SPACE, AND AVOIDS REDUNDANCY BY COMPARING VERTEX IDS.
utt_0075 utt 301.59 305.78 -X IN SUMMARY, ARABESQUE'S API IS SIMPLE BUT NOT AMENABLE TO EFFICIENT EXECUTION.
utt_0076 utt 306.48 311.90 -X CHECK OUT OUR PREFIXFPM SYSTEM FOR A MORE EFFICIENT SOLUTION FOR FREQUENT PATTERN MINING!
utt_0077 utt 311.90 317.34 -X IN FACT, REMOVING THE SLOW NETWORK COMMUNICATION CAN SPEED UP THE COMPUTING, AS IS DONE BY THE RSTREAM SYSTEM.
utt_0079 utt 317.62 321.98 -X BUT AS A SINGLE-MACHINE SYSTEM RUNNING OUT-OF-CORE, RSTREAM IS STILL DISK IO-BOUND.
utt_0080 utt 322.36 328.41 -X ANOTHER SYSTEM, NURI, PROPOSES TO FIND THE TOP-K RESULT SUBGRAPHS RATHER THAN ALL OF THEM.
utt_0081 utt 328.41 330.36 -X BUT NURI IS A SINGLE-THREADED JAVA PROGRAM.
utt_0082 utt 331.28 335.90 -X ALL THE SYSTEMS WE REVIEWED SO FAR DO NOT SCALE THEIR PERFORMANCE WITH THE NUMBER OF CPU CORES THEY USE.
utt_0084 utt 336.18 341.18 -X FOR EXAMPLE, ON A DATASET CALLED YOUTUBE, NURI TAKES OVER A THOUSAND SECONDS TO FIND CLIQUES.
utt_0085 utt 341.30 346.04 -X IF YOU USE OUR G-THINKER SYSTEM ON THE SAME GRAPH WITH one MILLION VERTICES, IT TAKES ONLY
utt_0086 utt 346.13 349.59 -X nine point four SECONDS ON ONE MULTI-CORE MACHINE.
utt_0087 utt 349.59 354.36 -X YOU ARE WELCOMED TO CHECK OUT OUR DEMO ON THE G-THINKER WEBSITE!
utt_0088 utt 354.36 366.20 -X AS A SIDE NOTE, FRANK MCSHERRY HAS CRITICIZED THE IO-BOUND BOTTLENECK OF EXISTING BIG DATA SYSTEMS WHOSE PERFORMANCE IS OFTEN ONLY COMPARABLE TO A SINGLE CPU CORE'S THROUGHPUT.
utt_0090 utt 366.20 373.56 -X I STARTED A NEW PARADIGM CALLED T-THINKER, OR, THINK-LIKE-A-TASK, WHICH TARGETS HIGH-COMPLEXITY DIVIDE-AND-CONQUER ALGORITHMS OVER BIG DATA.
utt_0092 utt 374.42 384.83 -X THE IDEA IS THAT IF YOUR COMPUTING COST IS SUPERLINEAR TO DATA SIZE, THE COST OF COMPUTING A TASK ON A SUBSET OF YOUR DATA IS EXPENSIVE ENOUGH TO JUSTIFY THE IO COST OF COLLECTING THE DATA SUBSET.
utt_0095 utt 386.01 392.31 -X OF COURSE WE SHOULD STILL KEEP THE PROGRAMMING MODEL MORE GENERAL AND FRIENDLY THAN USING CONVENTIONAL HPC LIBRARIES.
utt_0097 utt 392.31 402.20 -X THERE ARE MANY PROBLEMS AMENABLE TO DIVIDE AND CONQUER! AND HERE, THERE ARE A GREAT AMOUNT OF NEW RESEARCH OPPORTUNITIES FOR SYSTEMS RESEARCHERS!
utt_0099 utt 402.20 409.66 -X I WAS A VETERAN OF SYSTEMS IN THE VERTEX-CENTRIC PARADIGM, AND MY EXPERIENCE TELLS ME THAT THE T-THINKER PARADIGM IS THE NEXT GOLD MINE!
utt_0101 utt 409.66 414.97 -X WE WILL ALSO HAVE A NEW BOOK CHAPTER COMING, SHARING OUR EXPERIENCE DEVELOPING SUCH SYSTEMS,
utt_0102 utt 415.16 417.56 -X AND YOU ARE WELCOMED TO CHECK IT OUT!
utt_0103 utt 417.56 419.64 -X HERE IS A BRIEF HISTORY OF OUR G-THINKER SYSTEM.
utt_0104 utt 419.64 424.12 -X G-THINKER WAS ORIGINALLY A PROTOTYPE WHERE I PROPOSE A VERTEX-PULLING BASED SUBGRAPH API,
utt_0105 utt 424.15 438.47 -X BUT AS A PROTOTYPE, THE EXECUTION ENGINE IS JUST TO MAKE THINGS WORK, AND IT DOES NOT EVEN HAVE MULTITHREADING SUPPORT, IT ALSO HAS FLAWED DESIGNS, SAY, TASKS ACCESS VERTICES IN A BULK-SYNCHRONOUS MANNER, AND TO REDUCE MEMORY OVERHEAD, SUBGRAPHS ARE SAVED TO DISKS
utt_0108 utt 438.47 444.09 -X BUT A BAD TASK SCHEDULING STRATEGY LEAVES MANY SUBGRAPHS ON DISK, LEADING TO EXPENSIVE IO COST.
utt_0110 utt 444.66 454.59 -X SINCE A FULL-FLEDGED G-THINKER SYSTEM WILL TAKE TIME TO DEVELOP, THE STUDENT WHO HELPED IMPLEMENTED THE OLD G-THINKER ADDED MULTITHREADING SUPPORT AND TERMED THE RESULTING SYSTEM G-MINER,
utt_0112 utt 454.68 460.41 -X BUT IT INHERITS ALL THE FLAWED DESIGNS, AND LEADS TO POOR PERFORMANCE WHEN AN INPUT GRAPH GETS BIG.
utt_0114 utt 461.11 463.64 -X G-MINER FOLLOWS THE SAME API AS G-THINKER.
utt_0115 utt 464.09 468.51 -X PLEASE CHECK OUT OUR NEW G-THINKER WEBSITE WHERE YOU CAN FIND GREAT DOCUMENTATION!
utt_0116 utt 468.51 471.93 -X AND MY GROUP WILL PROVIDE FULL TECHNICAL SUPPORT!
utt_0117 utt 471.93 475.39 -X HERE'S AN OVERVIEW OF G-THINKER IN A CLUSTER OF three MACHINES.
utt_0118 utt 475.39 482.81 -X G-THINKER LOADS THE INPUT GRAPH FROM HDFS, WHERE EACH MACHINE LOADS A FRACTION OF VERTICES ALONG WITH THEIR ADJACENCY LISTS INTO A LOCAL TABLE.
utt_0120 utt 482.81 490.14 -X TASKS ARE INITIALIZED FROM EACH VERTEX IN THE LOCAL TABLE, AND A TASK CAN GROW ITS SUBGRAPH BY REQUESTING NEIGHBORING VERTICES, OR ACTUALLY, THEIR ADJACENCY LISTS.
utt_0122 utt 490.36 498.78 -X TO ALLOW MULTIPLE TASKS IN A MACHINE TO SHARE REMOTE VERTICES, A REMOTE VERTEX CACHE IS MAINTAINED BUT IT HAS A CAPACITY LIMIT TO KEEP MEMORY BOUNDED.
utt_0124 utt 499.06 502.56 -X EACH COMPUTING THREAD MAINTAINS A LOCAL TASK QUEUE TO KEEP IT BUSY.
utt_0125 utt 502.62 505.40 -X THIS IS THE KEY TO OUR SCALABILITY TO CPU CORES.
utt_0126 utt 505.56 518.33 -X WHEN THE TASK QUEUE IS ABOUT TO BE EMPTY, NEW TASKS WILL BE REFILLED TO THE QUEUE, WHILE IF MORE TASKS NEED TO BE ADDED TO A FULL TASK QUEUE, THE LAST BATCH OF TASKS IN THE QUEUE WILL BE SPILLED TO DISK TO BE REFILLED BY OTHER COMPUTING THREAD LATER.
utt_0129 utt 518.58 521.85 -X THIS ALLOWS THE MEMORY CONSUMED BY TASKS TO BE BOUNDED.
utt_0130 utt 522.14 532.86 -X HERE IS AN ILLUSTRATION OF HOW VERTICES ARE PARTITIONED BY THE LOCAL VERTEX TABLES OF ALL MACHINES, WHICH FORM A DISTRIBUTED KEY-VALUE STORE WHERE A TASK CAN PULL THE ADJACENCY LIST OF A VERTEX USING ITS ID.
utt_0133 utt 533.66 536.38 -X HERE IS AN ILLUSTRATION OF THE REMOTE VERTEX CACHE.
utt_0134 utt 536.38 544.06 -X FOR EXAMPLE, WHILE VERTEX eight IS NOT IN MACHINE Mzero, IF A TASK ON Mzero REQUESTS VERTEX eight, IT WILL BE PULLED TO THE CACHE.
utt_0136 utt 544.06 550.36 -X NOTE THAT IF ANOTHER TASK ON Mzero ALSO NEEDS eight, IT CAN THEN DIRECTLY ACCESS IT IN THE CACHE WITHOUT SENDING A DUPLICATE REQUEST.
utt_0138 utt 550.78 553.47 -X HERE IS THE TASK-CENTRIC PROGRAMMING MODEL OF G-THINKER.
utt_0139 utt 553.47 557.34 -X THE FIRST USER-DEFINED FUNCTION SPECIFICS HOW A TASK IS SPAWNED FROM AN INDIVIDUAL VERTEX.
utt_0140 utt 557.34 566.46 -X THE SECOND USER-DEFINED FUNCTION SPECIFICS HOW A TASK GROWS ITS SUBGRAPH FROM THOSE SURROUNDING VERTICES' ADJACENCY LISTS WHICH ARE PULLED INTO THE FRONTIER ARRAY THE LAST TIME THE
utt_0143 utt 567.45 572.67 -X A TASK CALLS COMPUTE(.) IN ITERATIONS TO EXPAND ITS SUBGRAPH UNTIL ALL NEEDED DATA ARE READY,
utt_0144 utt 572.67 576.29 -X AFTER WHICH THE TASK THEN MINES THE CONSTRUCTED SUBGRAPH.
utt_0145 utt 576.29 582.05 -X WHEN VERTICES ARE BEING PULLED, THE TASK IS SUSPENDED SO THAT CPU CORES CAN BE RELEASED TO PROCESS OTHER TASKS.
utt_0147 utt 582.36 591.26 -X A TASK CAN PULL A VERTEX THAT IS ON ITS SUBGRAPH BOUNDARY, IT CAN ALSO SPLIT THE SUBGRAPH INTO MULTIPLE NEW TASKS FOR CONCURRENT PROCESSING IF THE SUBGRAPH IS BIG.
utt_0149 utt 591.29 605.41 -X THE NEXT QUESTION IS HOW TO DESIGN OUR REMOTE VERTEX CACHE SO THAT TASKS CAN ACCESS VERTICES CONCURRENTLY, WHILE REQUESTED VERTICES CAN BE CONTINUOUSLY ADDED FROM REMOTE, AND VERTICES NO LONGER NEEDED BY TASKS CAN BE EVICTED TO MAKE ROOM FOR NEW REQUESTS?
utt_0152 utt 605.88 614.05 -X ONE SOLUTION IS TO HASH VERTICES INTO DIFFERENT BUCKETS USING THEIR IDS, SO THAT IF TWO VERTICES ARE IN DIFFERENT BUCKETS, THEIR PROCESSING CAN HAPPEN TOGETHER.
utt_0154 utt 614.43 619.23 -X IN THIS SLIDE, WE ASSUME VERTICES ARE HASHED TO ten BUCKETS BY HASHING THEIR IDS MODULO ten.
utt_0155 utt 619.80 625.41 -X EACH BUCKET IS PROTECTED BY A LOCK SO THAT ONLY ONE OPERATION CAN BE CARRIED OUT EACH TIME.
utt_0156 utt 625.41 629.31 -X A BUCKET HAS three CONTAINERS: GAMMA-TABLE KEEPS THE ADJACENCY LISTS
utt_0157 utt 629.82 633.77 -X Z-TABLE OR ZERO-TABLE TRACKS WHICH VERTICES ARE NO LONGER NEEDED BY TASKS
utt_0158 utt 633.85 641.89 -X AND R-TABLE OR REQUEST-TABLE KEEPS THOSE VERTICES THAT ARE REQUESTED BY TASKS, BUT WHOSE ADJACENCY LISTS ARE STILL ON THEIR WAY.
utt_0160 utt 641.89 644.13 -X WE NEXT ILLUSTRATE HOW THESE CONTAINERS ARE USED.
utt_0161 utt 644.48 656.77 -X FOR EXAMPLE, IF SOME TASK REQUESTS REMOTE VERTICES ten AND eleven, AND THEIR ADJACENCY LISTS HAPPEN TO BE IN GAMMA-TABLES, THEN WE SIMPLY ADD THEIR COUNTERS BY one TO INDICATE THAT ONE MORE TASK IS HOLDING THEM.
utt_0164 utt 657.18 665.09 -X HERE, VERTEX ten IS ALSO REMOVED FROM Z-TABLE AS ITS COUNTER IS NO LONGER zero AND IT CANNOT BE EVICTED ANY MORE.
utt_0166 utt 665.53 670.78 -X NEXT, ASSUME A TASK FINISHES A ROUND OF COMPUTE FUNCTION, AND RELEASES ITS HOLD OF REQUESTED VERTICES,
utt_0167 utt 671.20 675.74 -X SUCH AS twelve AND thirteen HERE, THEN WE NEED TO DECREMENT THEIR COUNTERS IN THE GAMMA-TABLE,
utt_0168 utt 675.74 682.46 -X AND SINCE VERTEX twelve'S COUNTER BECOMES zero, IT IS ADDED TO Z-TABLE TO ALLOW EVICTION.
utt_0169 utt 682.46 697.25 -X NOW ASSUME A TASK REQUESTS VERTICES twenty AND twenty-one FROM OUR CACHE, AND THEIR ADJACENCY LISTS ARE NOT ALREADY IN GAMMA-TABLES, THEN WE NEED TO ADD THEM TO R-TABLE, HERE, twenty IS ALREADY IN R-TABLE AND SO WE SIMPLY INCREMENT ITS COUNTER TO AVOID SENDING ANOTHER REDUNDANT
utt_0172 utt 697.25 702.59 -X REQUEST, WHILE twenty-one IS A NEWCOMER AND THUS, THE REQUEST IS ADDED TO THE SENDING QUEUE.
utt_0173 utt 702.59 706.94 -X NOTE THAT R-TABLE AVOIDS SENDING REDUNDANT VERTEX REQUESTS !!!
utt_0174 utt 706.94 712.03 -X NOW ASSUME THAT VERTEX twenty-two'S ADJACENCY LIST ARRIVED, AND IN R-TABLE, twenty-two ALREADY HAS three
utt_0175 utt 712.06 719.58 -X TASK REQUESTS, WE THEN MOVE THIS ENTRY ALONG WITH ITS COUNTER three TO GAMMA-TABLE, INDICATING THAT three TASKS ARE HOLDING VERTEX twenty-two.
utt_0177 utt 720.44 732.77 -X WE ALSO HAVE A GARBAGE COLLECTOR THAT PERIODICALLY SCANS Z-TABLES TO EVICT VERTICES, THAT'S WHY WE NEED THE SMALL-SIZED Z-TABLES: IF WE LET GC SCAN THE LARGER GAMMA-TABLES, IT WILL TAKE
utt_0179 utt 732.77 737.06 -X A LONGER TIME TO CHECK EACH BUCKET AND HENCE REDUCING CONCURRENCY.
utt_0180 utt 737.06 742.11 -X AN EVICTED VERTEX IS REMOVED FROM BOTH Z-TABLE AND GAMMA-TABLE.
utt_0181 utt 742.11 745.03 -X NEXT WE LOOK AT G-THINKER'S TASK MANAGEMENT.
utt_0182 utt 745.03 749.47 -X IN THIS SLIDE, THE COMPONENTS IN THE RED BOX ARE SHARED BY ALL COMPUTING THREADS IN A MACHINE
utt_0183 utt 749.53 759.17 -X INCLUDING THE LOCAL VERTEX TABLE, AND A LIST OF TASK FILES SPILLED FROM THE TASK QUEUES OF COMPUTING THREADS, BOTH OF WHICH ARE SOURCES OF TASKS TO BE REFILLED INTO TASK QUEUES.
utt_0185 utt 759.17 767.43 -X THE BLACK BOX ON THE RIGHT SHOWS THE COMPONENTS FOR EACH COMPUTING THREAD, WHERE THE threeRD TASK SOURCE IS A SET OF TASKS THAT ARE WAITING FOR THE REQUESTED DATA TO ARRIVE.
utt_0187 utt 767.65 780.23 -X WE WILL PRIORITIZE OUR REFILL BY CONSIDERING THE TASK FILES FIRST AS THESE TASKS HAVE BEEN PARTIALLY PROCESSED, AND WE WANT TO FINISH PENDING TASKS EARLIER THAN SPAWNING NEW TASKS TO PROCESS IN ORDER TO MINIMIZE THE NUMBER OF DISK-BUFFERED TASKS.
utt_0190 utt 780.86 784.26 -X NOW LET'S LOOK AT THOSE COMPONENTS INSIDE EACH COMPUTING THREAD.
utt_0191 utt 784.77 791.49 -X THE TASK QUEUE KEEPS A LIST OF TASKS TO BE COMPUTED BY THE CURRENT THREAD, ALONG WITH THEIR VERTICES TO REQUEST FOR.
utt_0193 utt 791.49 796.58 -X IF THE QUEUE HAS TOO FEW TASKS, WE WILL REFILL TASKS FROM ONE OF THE PREVIOUS three TASK SOURCES.
utt_0194 utt 796.73 803.46 -X IF THE QUEUE IS FULL BUT A NEW TASK NEEDS TO BE ADDED, WE WILL SPILL THE LAST BATCH OF TASKS AS A FILE TO DISK.
utt_0196 utt 803.81 815.20 -X EACH COMPUTING THREAD POPS A TASK FROM THE HEAD OF THE QUEUE EACH TIME, REQUESTS THE VERTICES, AND IF ANY OF THEM IS NOT IN THE CACHE, IT WILL PUT THE TASK INTO THE TASK TABLE SHOWN HERE TO WAIT FOR DATA.
utt_0199 utt 815.39 819.24 -X WE ALSO KEEP TRACK OF HOW MANY REQUESTED VERTICES ARE MET.
utt_0200 utt 819.36 823.84 -X IF A VERTEX RESPONSE IS RECEIVED, WE GET THE TASK LIST OF THAT VERTEX FROM THE R-TABLE.
utt_0201 utt 823.84 832.71 -X WE MENTIONED WE MAINTAIN A COUNTER FOR EACH R-TABLE VERTEX ENTRY, BUT WE ACTUALLY MAINTAIN THE LIST OF TASK IDS INSTEAD, TO TRACK THOSE TASKS THAT REQUEST THAT VERTEX.
utt_0203 utt 832.96 842.44 -X FOR EACH TASK IN THE TASK TABLE, WE ADD THE MET-COUNTER, AND IF THE COUNTER REACHES THE TOTAL REQUESTED VERTEX COUNT, WE MOVE THE TASK TO THE TASK BUFFER HERE.
utt_0205 utt 842.59 852.80 -X EACH COMPUTING THREAD KEEPS CALLING POP TO TAKE TASKS FOR PROCESSING, AND CALLING PUSH TO COMPUTE THE READY TASKS AND ADD THEM TO THE TASK QUEUE IF MORE PROCESSING IS NEEDED.
utt_0207 utt 852.80 857.44 -X NEWLY CREATED TASKS ARE ALSO APPENDED TO THE TASK QUEUE, AND TASKS MAY BE SPILLED TO THE DISK.
utt_0208 utt 857.76 872.74 -X WE REMARK THAT IF VERTEX CACHE OR TASK CONTAINERS REACH THEIR CAPACITY LIMIT, WE ONLY REPEAT THE PUSH FUNCTION TO PROCESS READY TASKS SO THAT VERTICES CAN BE RELEASED FROM THE CACHE TO MAKE ROOM, AND POP CAN THEN BE RESTORED TO REQUEST MORE VERTICES FOR NEW TASKS.
utt_0211 utt 872.90 885.00 -X FOR TASK STEALING BETWEEN MACHINES, WE WILL ESTIMATE THE PENDING TASKS IN EACH MACHINE FROM THE CAPACITY OF THE LOCAL VERTEX TABLE AND TASK FILES BUFFERED ON THE DISK, FOR DECIDING EFFECTIVE TASK STEALING PLANS.
utt_0214 utt 885.00 891.78 -X TASKS STOLEN FROM OTHER MACHINES ARE APPENDED TO OUR FILE LIST ON DISK, TO BE REFILLED INTO THE TASK QUEUES OF THE COMPUTING THREADS.
utt_0216 utt 892.45 898.57 -X AS YOU CAN SEE HERE, G-THINKER IS ORDERS OF MAGNITUDE FASTER THAN OTHER SYSTEMS, ESPECIALLY FOR BIG GRAPHS.
utt_0218 utt 898.88 913.00 -X THE ONLY COMPETITOR IS G-MINER WHICH CAN SCALE WITH THE NUMBER OF CPU CORES USED, BUT IT DOES NOT SCALE WELL WHEN THE GRAPH GETS BIG, DUE TO ITS BAD TASK SCHEDULING SCHEME THAT KEEPS A LOT OF PARTIALLY COMPUTED TASKS ON DISKS.
utt_0221 utt 913.00 915.85 -4.1877 THANKS FOR YOUR ATTENTION AND PLEASE CHECK OUT OUR SYSTEMS ONLINE!
