utt_0000 utt 0.22 3.28 -X A VERY GOOD MORNING, AFTERNOON, OR EVENING TO EVERYONE.
utt_0001 utt 3.44 10.70 -X I AM KENNETH, AND ON BEHALF OF MY CO-AUTHORS, IT IS MY PLEASURE TO PRESENT OUR WORK IN THE two thousand and twenty-three INTERNATIONAL CONFERENCE ON ACOUSTICS,
utt_0003 utt 10.70 12.43 -X SPEECH AND SIGNAL PROCESSING.
utt_0004 utt 12.78 18.42 -X OUR WORK CONCERNS A MULTIMODAL METHOD FOR THE PREDICTION OF AFFECTIVE RESPONSES TO AUGMENTED URBAN SOUNDSCAPES.
utt_0006 utt 18.51 24.11 -X THE MAIN APPLICATION OF OUR WORK IS TO ALLOW AN AUTOMATIC SELECTION OF SOUNDS, ALSO KNOWN AS MASKERS,
utt_0008 utt 24.21 31.31 -X TO ADD OR OTHERWISE AUGMENT TO REAL-LIFE URBAN SOUNDSCAPES TO IMPROVE ATTRIBUTES SUCH AS THEIR PERCEIVED PLEASANTNESS OR ACOUSTIC COMFORT.
utt_0011 utt 31.66 38.87 -X THE MAIN NOVELTY OF OUR WORK LIES IN THE EXTENSIBLE MULTIMODAL FUSION METHODS TO INCLUDE ADDITIONAL INFORMATION PERTINENT TO PERCEPTION,
utt_0014 utt 38.87 42.29 -X SUCH AS VISUAL INFORMATION OR INFORMATION RELATED TO THE LISTENER
utt_0015 utt 42.73 51.73 -X USING PARTICIPANT-LINKED INFORMATION IN THIS WAY SIGNIFICANTLY IMPROVES MODEL PERFORMANCE IN TERMS OF MEAN SQUARED ERROR IN THE PREDICTION OF ISO PLEASANTNESS.
utt_0018 utt 52.46 55.28 -X IN SHORT, AS THE TITLE OF THE PRESENTATION SUGGESTS,
utt_0019 utt 55.31 63.00 -X WE HAVE DEVELOPED A MODEL TO PERFORM AUTONOMOUS SOUNDSCAPE AUGMENTATION WITH MULTIMODAL FUSION OF VISUAL AND PARTICIPANT-LINKED INPUTS.
utt_0021 utt 63.92 67.99 -X WITH THAT, ALLOW ME TO ELABORATE ON THE BACKGROUND AND MOTIVATION BEHIND OUR PROJECT.
utt_0023 utt 68.43 74.90 -X WE ARE WORKING UNDER THE PARADIGM OF A SOUNDSCAPE BEING AN ACOUSTIC ENVIRONMENT, AS PERCEIVED BY A PERSON OR PEOPLE, IN CONTEXT.
utt_0025 utt 74.90 80.05 -X THIS FOLLOWS THE DEFINITION PROVIDED BY THE INTERNATIONAL STANDARD FOR SOUNDSCAPES, ISO twelve thousand, nine hundred and thirteen.
utt_0027 utt 81.39 86.77 -X CONSEQUENTLY, AUGMENTATION INVOLVES ADDING MASKERS TO EXISTING SOUNDSCAPES TO ALTER THEIR PERCEPTION.
utt_0029 utt 86.99 93.20 -X FOR EXAMPLE, WE COULD ADD THE SOUND OF A BIRD TO AN EXISTING SOUNDSCAPE BESIDE A NOISY ROAD TO IMPROVE ITS OVERALL PERCEIVED PLEASANTNESS.
utt_0031 utt 93.58 96.98 -X IN PRACTICE, THIS ADDITION CAN BE DONE VIA HEADPHONES OR SPEAKERS.
utt_0032 utt 97.90 104.25 -X FOR THIS PROJECT, WE RETURN TO THE DEFINITION OF A SOUNDSCAPE AND FOCUS ON THE TWO WORDS PERSON AND CONTEXT.
utt_0034 utt 104.75 111.03 -X THIS IMPLIES THE IMPORTANCE OF CONSIDERING NON-ACOUSTIC FACTORS WHEN ANALYZING OR PREDICTING PERCEPTUAL QUANTITIES RELATED TO SOUNDSCAPES.
utt_0036 utt 111.25 115.22 -X THE FIRST POSSIBLE FACTOR IS THE VISUAL ENVIRONMENT. FOR INSTANCE,
utt_0037 utt 115.22 117.97 -X IN A STUDY ILLUSTRATED BY THE FIGURES ON THE RIGHT SIDE OF THE SLIDE,
utt_0038 utt 118.10 127.32 -X THE VISUAL ENVIRONMENT WITH AN ADDED GREEN HEDGE BLOCKING THE VIEW OF THE ROAD HAD A HIGHER RELATIVE PREFERENCE SCORE WHEN BOTH WERE COMBINED WITH THE EXACT SAME AUDIO CLIP.
utt_0041 utt 128.15 132.25 -X OTHER IMPORTANT FACTORS TO CONSIDER ARE DEMOGRAPHIC FACTORS SUCH AS THE PARTICIPANT'S AGE,
utt_0043 utt 132.34 135.35 -X AS WELL AS ENVIRONMENTAL FACTORS SUCH AS THE AMBIENT TEMPERATURE.
utt_0044 utt 135.67 146.55 -X IN LIGHT OF THIS, WE WOULD EXPECT THAT FOR MODELS RELYING PURELY ON ACOUSTIC INFORMATION, INCORPORATING ADDITIONAL INFORMATION FROM RELEVANT NON-ACOUSTIC MODALITIES WOULD IMPROVE THEIR PERFORMANCE.
utt_0047 utt 146.55 155.58 -X HENCE, FOR THIS PROJECT, WE INVESTIGATE THE MULTIMODAL IDEA ON AN ATTENTION-BASED MODEL WHICH WE CALL A PROBABILISTIC PERCEPTUAL ATTRIBUTE PREDICTOR, OR PPAP FOR SHORT.
utt_0050 utt 156.18 158.55 -X I WILL FIRST DESCRIBE THE ACOUSTIC-ONLY VERSION,
utt_0051 utt 158.55 162.14 -X AND THEN ELABORATE ON HOW WE EXTENDED IT TO BE COMPATIBLE WITH MULTIPLE MODALITIES.
utt_0053 utt 163.12 165.72 -X AS I EXPLAINED EARLIER, IN SOUNDSCAPE AUGMENTATION,
utt_0054 utt 165.72 168.34 -X WE ADD MASKERS TO EXISTING SOUNDSCAPES,
utt_0055 utt 168.34 171.00 -X SO WE BEGIN BY CONSIDERING THEIR SPECTROGRAMS SEPARATELY.
utt_0056 utt 171.32 175.22 -X IN PRACTICE, THE BASE SOUNDSCAPE <I>IS</I> THE AMBIENT ACOUSTIC ENVIRONMENT,
utt_0057 utt 175.22 176.89 -X SO WE ASSUME NO GAIN CONTROL OVER IT.
utt_0058 utt 177.17 180.38 -X HOWEVER, WE CAN CONTROL THE GAIN OF THE ADDED MASKER, FOR EXAMPLE,
utt_0059 utt 180.38 182.59 -X BY ADJUSTING THE VOLUME OF A PLAYBACK SYSTEM,
utt_0060 utt 182.61 185.88 -X SO WE INCLUDE THE LOG-GAIN AS AN AUXILIARY INPUT TO THE PPAP.
utt_0061 utt 187.45 192.12 -X THE ACOUSTIC-ONLY PPAP THEN EXTRACTS FEATURES FROM THE BASE SOUNDSCAPE AND MASKER SEPARATELY,
utt_0063 utt 192.12 198.30 -X AND THEN PERFORMS AUGMENTATION IN THE FEATURE SPACE TO OUTPUT AUGMENTED SOUNDSCAPE FEATURES WITH THE LOG-GAIN AS A CALIBRATION FACTOR.
utt_0065 utt 198.93 208.67 -X CONSIDERING THE BASE SOUNDSCAPE, MASKER, AND AUGMENTED SOUNDSCAPE FEATURES AS KEYS, QUERIES, AND VALUES TO ANY COMPATIBLE QKV ATTENTION BLOCK,
utt_0067 utt 208.69 215.51 -X THE PPAP FINALLY PREDICTS PARAMETERS OF A RANDOM DISTRIBUTION MODELLING A GIVEN PERCEPTUAL ATTRIBUTE FOR THAT AUGMENTED SOUNDSCAPE,
utt_0069 utt 215.51 217.31 -X SUCH AS ITS PERCEIVED PLEASANTNESS.
utt_0070 utt 217.31 220.99 -X THIS GIVES THE PPAP A PROBABILISTIC NATURE,
utt_0071 utt 221.02 224.09 -X AND WE TRAIN IT WITH A CORRESPONDING LOSS FUNCTION,
utt_0072 utt 224.25 229.66 -X WHICH IS THE LOG-PROBABILITY OF THE OBSERVED GROUND TRUTH GIVEN THE PREDICTED DISTRIBUTION PARAMETERS.
utt_0074 utt 230.84 234.68 -X NOW, WE MODIFY THIS ARCHITECTURE INTO WHAT WE CALL A CONTEXTUAL PPAP
utt_0075 utt 235.19 238.14 -X THAT ENCOMPASSES MULTIMODAL INPUTS.
utt_0076 utt 238.46 243.90 -X AS AN EXAMPLE FOR THIS STUDY, WE CONSIDER CONTEXTUAL INFORMATION FROM THE LISTENER, SUCH AS THEIR DEMOGRAPHIC,
utt_0078 utt 243.90 248.86 -X AS WELL AS IMAGES FROM THE VISUAL ENVIRONMENT MATCHING THE ACOUSTIC ENVIRONMENT OF THE BASE SOUNDSCAPE.
utt_0080 utt 249.27 254.24 -X THIS IS INSPIRED FROM THE DEFINITION OF SOUNDSCAPE AS ...PERCEIVED BY A PERSON OR PEOPLE, IN CONTEXT.
utt_0082 utt 255.00 256.86 -X AS WITH THE ACOUSTIC-ONLY PPAP,
utt_0083 utt 257.02 259.77 -X WE FIRST EXTRACT FEATURES FROM THE NEW MODALITIES,
utt_0084 utt 259.77 266.17 -X AND ADD IN VIRTUAL SWITCHES THAT ALLOW US TO CHOOSE INDEPENDENTLY WHETHER TO INCLUDE THEM AS ADDITIONAL INPUTS.
utt_0086 utt 267.32 273.92 -X WE THEN NEED TO ADDRESS HOW TO FUSE THESE MULTIMODAL FEATURES WITH THE ACOUSTIC-ONLY PPAP IN A SENSIBLE MANNER.
utt_0088 utt 274.14 276.99 -X FOR THIS STUDY, WE PROPOSE THREE MODES OF FUSION,
utt_0089 utt 276.99 280.67 -X WHICH WE REFER TO AS EARLY, MID-LEVEL, AND LATE FUSION.
utt_0090 utt 281.66 287.77 -X IN EARLY FUSION, WE TREAT EACH MODE AS INDEPENDENT CHANNELS OF INFORMATION IN THE FEATURE AUGMENTATION BLOCK F_G,
utt_0092 utt 287.99 291.04 -X AND STACK THEM TOGETHER AS INPUT INTO A CONVOLUTIONAL BLOCK.
utt_0093 utt 291.61 294.65 -X IN MID-LEVEL FUSION, WE ONLY USE THE LOG-GAIN,
utt_0094 utt 294.65 296.54 -X CORRESPONDING TO THE ACOUSTIC MODALITY,
utt_0095 utt 296.54 298.43 -X IN THE FEATURE AUGMENTATION BLOCK F_G,
utt_0096 utt 298.84 302.27 -X AND CONCATENATE THE INFORMATION FROM ALL MODES AT THE OUTPUT LEVEL.
utt_0097 utt 302.75 306.69 -X AND LASTLY, IN LATE FUSION, WE USE THE SAME IDEA AS MID-LEVEL FUSION,
utt_0098 utt 306.69 312.37 -X BUT WE CONCATENATE THE INFORMATION FROM ALL MODES <I>AFTER</I> THE OUTPUT LEVEL OF THE ACOUSTIC-ONLY PPAP.
utt_0100 utt 313.28 319.74 -X TO VALIDATE OUR PROPOSED METHOD, WE RAN EXPERIMENTS ON THE DIFFERENT MODALITIES AND FUSION MODES ON A COMMON DATASET THAT WE PREVIOUSLY COLLECTED.
utt_0103 utt 319.87 326.14 -X THIS IS THE ARAUS DATASET, CONSISTING OF AUDIO-VISUAL STIMULI CONFIGURED IN A MANNER THAT ALLOWS FOR five-FOLD CROSS-VALIDATION.
utt_0105 utt 326.81 329.86 -X EACH STIMULUS IN THE DATASET IS AN AUGMENTED SOUNDSCAPE,
utt_0106 utt 329.86 335.84 -X PAIRED WITH A GROUND-TRUTH SET OF RESPONSES TO A SELECTION OF PERCEPTUAL ATTRIBUTE SCALES PROVIDED BY STUDY PARTICIPANTS.
utt_0108 utt 336.57 340.51 -X FOR OUR VALIDATION EXPERIMENTS, WE USE THE ATTRIBUTE ISO PLEASANTNESS,
utt_0109 utt 340.51 342.11 -X WHICH TAKES VALUES FROM minus one TO one.
utt_0110 utt 344.00 348.80 -X THE SET OF RESPONSES IS ALSO PUBLICLY ACCESSIBLE AT THE URL SHOWN ON THE SLIDE.
utt_0112 utt 350.46 357.19 -X FOR THE EXPERIMENTAL SETUP, WE VARIED ALL COMBINATIONS OF MODALITIES AND FUSION METHODS THAT WE DESCRIBED EARLIER IN THE PRESENTATION,
utt_0114 utt 357.19 361.57 -X AND A VISUAL SUMMARY IS SHOWN IN THE TABLE ON THE RIGHT OF THE SLIDE.
utt_0115 utt 361.57 367.84 -X AS A BASELINE REFERENCE, WE ALSO RUN THE EXPERIMENTS ON THE ACOUSTIC-ONLY PPAP, WHICH IS NOT MULTIMODAL IN NATURE.
utt_0117 utt 368.54 382.69 -X WE USE A COMMON DOT-PRODUCT ATTENTION BLOCK FOR ALL VARIANTS OF THE CONTEXTUAL PPAP, AS WELL AS THE SAME LOSS FUNCTION CORRESPONDING TO THE LOG-PROBABILITY OF A NORMAL DISTRIBUTION FOR TRAINING, IN ORDER TO ALLOW FOR A CONSISTENT EXPERIMENTAL SETUP.
utt_0121 utt 382.69 387.84 -X WE RAN ten RUNS FOR EACH INVESTIGATED VARIANT AND AGGREGATED THE RESULTS IN TERMS OF THE MEAN SQUARED ERROR IN PREDICTION.
utt_0123 utt 388.13 391.59 -X THE TABLE ON THE RIGHT OF THIS SLIDE SHOWS A SUMMARY OF THE RESULTS.
utt_0124 utt 391.65 399.43 -X WE DID A KRUSKAL-WALLIS TEST WITH BONFERRONI CORRECTION TO VERIFY IF ANY CHANGES IN PERFORMANCE WITH RESPECT TO THE BASELINE WERE INDEED STATISTICALLY SIGNIFICANT.
utt_0127 utt 400.10 406.95 -X WE CAN OBSERVE THAT THERE WERE SIGNIFICANT IMPROVEMENTS IN PERFORMANCE WHEN PARTICIPANT-LINKED INFORMATION WAS USED AS ADDITIONAL MULTIMODAL INPUT,
utt_0129 utt 407.04 410.08 -X WITH THE GREATEST IMPROVEMENT IN THE LATE FUSION METHOD.
utt_0130 utt 410.56 414.34 -X ADDING THE VISUAL MODALITY ALSO GAVE IMPROVEMENTS IN THE PERFORMANCE,
utt_0131 utt 414.34 417.29 -X BUT THE IMPROVEMENTS WERE NOT STATISTICALLY SIGNIFICANT.
utt_0132 utt 418.31 425.00 -X HOWEVER, USING <I>BOTH</I> THE VISUAL AND PARTICIPANT-LINKED MODALITIES TOGETHER POTENTIALLY LEADS TO SIGNIFICANT WORSENING OF PERFORMANCE.
utt_0134 utt 425.12 430.98 -X THIS COULD BE A CONFLICT IN THE VISUAL MODALITY AS AN <I>OBJECTIVE</I> CHARACTERISTIC OF THE ENVIRONMENT,
