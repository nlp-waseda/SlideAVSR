utt_0000 utt 0.81 6.26 -X HELLO! I'M YAO XIAO FROM SUN YAT-SEN UNIVERSITY, AND I'M GLAD TO PRESENT OUR PAPER:
utt_0001 utt 6.26 10.70 -X “MASKED IMAGES ARE COUNTERFACTUAL SAMPLES FOR ROBUST FINE-TUNING”.
utt_0002 utt 10.70 15.92 -X RECENTLY, LARGE PRE-TRAINED MODELS LIKE CLIP EXHIBIT STRONG ROBUSTNESS TO DISTRIBUTION SHIFT,
utt_0003 utt 15.92 18.99 -X SHOWING SIGNIFICANTLY BETTER PERFORMANCE ON OOD DATA.
utt_0004 utt 19.76 24.69 -X HOWEVER, IT IS FOUND THAT FINE-TUNING THESE PRE-TRAINED MODELS CAN REDUCE THE ROBUSTNESS,
utt_0005 utt 24.69 28.08 -X LEADING TO A TRADE-OFF BETWEEN ID AND OOD PERFORMANCE.
utt_0006 utt 28.69 32.56 -X IN THIS PAPER, WE STUDY THIS ISSUE FROM A CAUSAL PERSPECTIVE,
utt_0007 utt 32.56 35.47 -X AND HERE IS OUR STRUCTURAL CAUSAL MODEL.
utt_0008 utt 35.47 44.85 -X WE ARGUE THAT FINE-TUNED MODELS TEND TO LEARN THE SPURIOUS CORRELATION BETWEEN SEMANTIC AND NON-SEMANTIC FACTORS, WHICH CAN BE UNSTABLE UNDER DISTRIBUTION SHIFTS.
utt_0010 utt 45.26 54.55 -X THEREFORE, WE PROPOSE TO USE MASKED IMAGES AS COUNTERFACTUAL TRAINING SAMPLES THAT BREAK THE SPURIOUS CORRELATIONS. BY APPLYING DISTILLATION BASED ON
utt_0012 utt 54.55 61.75 -X MASKED IMAGES, WE CAN EFFECTIVELY IMPROVE THE ROBUSTNESS OF THE FINE-TUNED MODELS. |oneMIN|
utt_0013 utt 61.75 63.48 -X NOW, LET'S DRILL DOWN TO THE DETAILS.
utt_0014 utt 64.24 68.05 -X THANKS TO THE PRE-TRAINING ON MASSIVE DATA OF VARIOUS DOMAINS,
utt_0015 utt 68.05 80.95 -X THE LARGE PRE-TRAINED MODELS ARE EXPECTED TO LEARN THE CORRECT ATTRIBUTION OF IMAGE SEMANTICS $S$ TO THE SEMANTIC REPRESENTATIONS $H_S$. HOWEVER, DUE TO THE SPURIOUS CORRELATION IN
utt_0017 utt 80.95 87.57 -X DOWNSTREAM DATA, FINE-TUNED MODELS TEND TO RELY ON BOTH $H_S$ AND $H_D$ FOR THE PREDICTION OF $S$.
utt_0018 utt 89.33 95.57 -X UNFORTUNATELY, THE CORRELATION BETWEEN H_D AND S IS UNSTABLE UNDER DISTRIBUTION SHIFT.
utt_0019 utt 95.57 108.28 -X FOR EXAMPLE, WHILE THE RED ADMIRAL BUTTERFLIES MAY ALL BE CAPTURED SITTING ON FLOWERS IN TRAINING DATA, THEY CAN APPEAR ANYWHERE IN TEST IMAGES. HENCE, WE WOULD LIKE TO BREAK THE LEARNING OF
utt_0021 utt 108.28 114.01 -X SUCH SPURIOUS CORRELATIONS BY USING COUNTERFACTUAL SAMPLES.
utt_0022 utt 114.55 119.67 -X TO THIS END, WE PROPOSE AN INTUITIVE METHOD FOR CONSTRUCTING COUNTERFACTUAL SAMPLES.
utt_0023 utt 119.83 127.03 -X WE USE CLASS ACTIVATION MAP TO DIVIDE THE PATCHES OF AN IMAGE INTO CONTEXT AND OBJECT.
utt_0024 utt 127.48 134.33 -X THEN, EITHER THE CONTEXT OR THE OBJECT IS MASKED, RESULTING IN THE MODIFICATION OF H_D OR H_S.
utt_0025 utt 134.33 146.11 -X IT SHOULD BE NOTED THAT THIS MASKING-BASED METHOD IS NOT THE ONLY WAY TO BUILD THE COUNTERFACTUAL SAMPLES, AND WE DO NOT EXPECT IT TO COVER ALL THE SPURIOUS CORRELATIONS.
utt_0027 utt 148.09 159.26 -X BASED ON THE COUNTERFACTUAL SAMPLES, WE APPLY A SIMPLE FEATURE-BASED DISTILLATION METHOD TO CONSTRAIN THE FINE-TUNING, TAKING THE PRE-TRAINED MODEL AS A TEACHER MODEL.
utt_0029 utt 159.26 164.54 -X HERE, THE PRE-TRAINED AND FINE-TUNING MODEL ARE FED WITH THE SAME COUNTERFACTUAL IMAGES,
utt_0030 utt 164.54 168.96 -X AND THE LABEL $Y$ IS ONLY USED FOR THE LEARNING OF FACTUAL SAMPLE $X$.
utt_0031 utt 170.36 176.76 -X BY REQUESTING CONSISTENT PREDICTION WITH THE PRE-TRAINED MODEL ON THE SEMANTICS OF COUNTERFACTUAL SAMPLES,
utt_0033 utt 176.76 182.33 -X WE HINDER THE FINE-TUNING MODEL FROM ATTRIBUTING THE SEMANTICS $S$ TO $H_D$.
utt_0034 utt 185.02 189.82 -X MOREOVER, SINCE THE COUNTERFACTUAL SAMPLES ARE USED FOR THE DISTILLATION,
utt_0035 utt 189.88 195.04 -X WE NEED TO ENLARGE THE DISAGREEMENT BETWEEN THE FINE-TUNING AND PRE-TRAINED MODEL,
utt_0036 utt 195.04 199.26 -X SO THAT THE DISTILLATION LOSS CAN MORE EFFECTIVELY CONSTRAIN THE FINE-TUNING.
utt_0037 utt 199.64 206.46 -X HENCE, WE PROPOSE TO FURTHER REFILL THE MASKED REGIONS WITH PATCHES TAKEN FROM OTHER IMAGES.
utt_0038 utt 208.86 214.08 -X SPECIFICALLY, CONTEXT-MASK MAY NOT PRODUCE CONTRADICTIONS IN PREDICTIONS,
utt_0039 utt 214.08 219.23 -X SINCE BOTH MODELS CAN PREDICT THE SEMANTIC LABEL “CAT” FROM THE OBJECT PATCHES,
utt_0040 utt 219.39 225.66 -X SO WE NEED REFILLING TO BRING SOME CONFLICTING CONTEXT THAT DISTURBS THE PREDICTION OF THE FINE-TUNING MODEL.
utt_0042 utt 227.74 233.06 -X IN THE OTHER CASE, OBJECT-MASK ALONE CAN PRODUCE CONTRADICTIONS IN THEORY,
utt_0043 utt 233.06 236.77 -X AS THE FINE-TUNING MODEL COULD STILL PREDICT THE “CAT” FROM THE CONTEXT,
utt_0044 utt 236.93 248.42 -X WHILE THE PRE-TRAINED MODEL COULD NOT. IN PRACTICE, HOWEVER, DUE TO THE IMPERFECT MASKING, THE PRE-TRAINED MODEL MAY STILL RECOGNIZE THE OBJECT FROM ITS UNMASKED PARTS.
utt_0046 utt 249.41 259.39 -X SO IN THIS CASE, WE NEED REFILLING TO FURTHER DISTORT THE ORIGINAL SEMANTICS TO ENLARGE THE DISAGREEMENT.
utt_0048 utt 259.39 263.78 -X TO VALIDATE THE EFFECTIVENESS OF THE PROPOSED MASKING AND REFILLING,
utt_0049 utt 263.78 270.08 -X WE CONDUCT EXPERIMENTS ON FINE-TUNING CLIP TO THE IMAGENET CLASSIFICATION TASK.
utt_0050 utt 270.08 275.94 -X HERE IS THE COMPARISON OF DIFFERENT COMBINATIONS OF STRATEGIES WITH DIFFERENT HYPER-PARAMETERS.
utt_0051 utt 277.63 285.19 -X THE MAJOR CONCLUSION IS THAT BOTH MASKING AND REFILLING ARE IMPORTANT FOR OUR METHOD.
utt_0052 utt 285.19 288.68 -X BESIDES, OBJECT-MASK IS MORE EFFECTIVE THAN CONTEXT-MASK,
utt_0053 utt 288.68 295.37 -X WHICH MAY BE EXPLAINED BY THE LESS DEPENDENCY ON REFILLING.
utt_0054 utt 295.43 300.65 -X WE ALSO COMPARE OUR METHOD WITH EXISTING METHODS FOR ROBUST FINE-TUNING.
utt_0055 utt 300.83 306.66 -X THESE RESULTS SUGGEST THAT OUR METHOD CAN ACHIEVE SUPERIOR OOD PERFORMANCE ON AVERAGE,
utt_0056 utt 306.75 311.37 -X WITHOUT USING MODEL ENSEMBLE AS IN WISE-FT OR UNIFORM SOUP.
utt_0057 utt 312.51 319.11 -X AS EXPECTED, OUR METHOD IS PARTICULARLY EFFECTIVE ON OBJECTNET AND IMAGENET-A,
utt_0058 utt 319.33 326.82 -X WHERE MANY OBJECTS ARE SHOWN IN UNUSUAL CONTEXTS.
utt_0059 utt 326.82 332.26 -X WE FURTHER DISCUSS THE INTEGRATION WITH WISE-FT, A WEIGHT-SPACE ENSEMBLE METHOD.
utt_0060 utt 332.26 341.38 -X IT WAS FOUND THAT THE WEIGHT-SPACE LINEAR INTERPOLATION BETWEEN THE ZERO-SHOT AND VANILLA FINE-TUNED MODEL CAN PRODUCE SUCH A CURVE THAT,
