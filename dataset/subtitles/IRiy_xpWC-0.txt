utt_0000 utt 1.71 12.82 -X HELLO, I'M KAYO, AND TODAY I WILL PRESENT OUR WORK THAT TRIES TO ANSWER THE QUESTION DO CONTEXT-AWARE TRANSLATION MODELS PAY THE RIGHT ATTENTION?
utt_0002 utt 12.82 16.14 -X SO TO BEGIN, WHY DO WE NEED CONTEXT DURING TRANSLATION?
utt_0003 utt 16.14 21.52 -X WELL, LET'S TAKE A LOOK AT THIS EXAMPLE. HERE, WHAT DOES THE WORD MOLE IN THIS SENTENCE REFER TO?
utt_0004 utt 22.54 28.31 -X WELL, IF THE PREVIOUS SENTENCE WAS THINGS COULD START TO GET DANGEROUS IF THE MINISTERS FIND OUT,
utt_0005 utt 28.49 42.10 -X THEN THE MOLE PROBABLY REFERS TO A SPY. BUT IF THE PREVIOUS SENTENCE WAS COULD IT BE ANYTHING SERIOUS, DOCTOR? THE MOLE REFERS TO A BIRTHMARK INSTEAD. SO DEPENDING ON CONTEXT,
utt_0007 utt 42.10 48.85 -X THE MEANING OF THE WORD CHANGES, AND THEREFORE ITS TRANSLATION DEPENDS ON THE CONTEXT AS WELL.
utt_0008 utt 49.20 59.76 -X CURRENT NEURAL MACHINE TRANSLATION MODELS ARE REASONABLY GOOD AT SENTENCE-LEVEL TRANSLATION FOR HIGH RESOURCE LANGUAGE PAIRS, SUCH AS ENGLISH AND FRENCH. SO FOR EXAMPLE,
utt_0010 utt 59.76 64.79 -X A POPULAR PROVIDER CAN CORRECTLY TRANSLATE THE SENTENCE HERE.
utt_0011 utt 64.79 76.74 -X HOWEVER, WHEN THE CONTEXT CHANGES, THE CORRECT TRANSLATION SHOULD NOW BE CET GRAIN DE BEAUTÃ‰ FOR THE MOLE, BUT THE MODEL DOES NOT PICK UP ON THE CHANGE IN MEANING. SO CURRENT MODELS
utt_0013 utt 76.74 89.94 -X OFTEN FAIL TO PRODUCE ADEQUATE TRANSLATIONS ON A DOCUMENT LEVEL WHEN THERE ARE AMBIGUOUS WORDS THAT REQUIRE CONTEXT TO RESOLVE. ANOTHER EXAMPLE IS FOR THE TRANSLATION OF THE NEUTRAL ENGLISH
utt_0015 utt 89.94 103.29 -X PRONOUN THEY, WHERE DEPENDING ON THE CONTEXT, HERE THEY REFERS TO IMPLICATIONS WHICH IS A FEMININE NOUN IN FRENCH, SO THE PRONOUN SHOULD BE THE FEMININE ELLE INSTEAD OF THE MASCULINE IL.
utt_0017 utt 105.43 116.92 -X TO ADDRESS THE DIFFICULTIES IN DOCUMENT LEVEL TRANSLATION AND THE IMPORTANCE OF CONTEXT, SEVERAL METHODS OVER THE LAST FOUR OR FIVE YEARS HAVE BEEN PROPOSED TO INCORPORATE CONTEXT IN NEURAL MACHINE
utt_0019 utt 116.92 130.36 -X TRANSLATION. BUT EVEN WITH THE NECESSARY CONTEXT, THESE MODELS PERFORM POORLY ON TRANSLATING RELATIVELY SIMPLE DISCOURSE PHENOMENA, SUCH AS ANAPHORIC PRONOUNS. IN THIS EXAMPLE, IT REFERS
utt_0021 utt 130.36 135.58 -X TO REPORT, WHICH IS A MASCULINE NOUN IN FRENCH, SO THE PRONOUN SHOULD BE THE MASCULINE IL.
utt_0022 utt 137.46 148.71 -X TO TRY TO FIND OUT WHY THE MODEL MADE THIS ERROR, LET'S TAKE A LOOK AT WHICH TOKENS THE MODEL PAID THE MOST ATTENTION TO, WHICH WE HIGHLIGHT IN YELLOW HERE. WE CAN SEE THAT THE MODEL PAYS
utt_0024 utt 148.71 154.20 -X HIGH ATTENTION TO THE WORD INFIRMARY, WHICH IS A FEMININE NOUN WHEN TRANSLATED INTO FRENCH,
utt_0025 utt 154.20 164.22 -X BUT THE MODEL DOES NOT PAY ATTENTION TO REPORT OR RAPPORT, WHICH WOULD HAVE HELPED IT TRANSLATE THE WORD ACCURATELY. THIS MAY EXPLAIN WHY THE MODEL MADE THIS ERROR.
utt_0027 utt 166.74 178.20 -X IN GENERAL, CONTEXT-AWARE MACHINE TRANSLATION MODELS HAVE BEEN FOUND TO OFTEN ATTEND TO UNINFORMATIVE TOKENS IN CONTEXT, OR DO NOT USE THE INFORMATION CONTAINED IN THE CONTEXT AT ALL.
utt_0029 utt 179.70 183.03 -X WE, THEREFORE, ASK OURSELVES THE FOLLOWING RESEARCH QUESTIONS:
utt_0030 utt 183.22 197.02 -X FIRST, IN CONTEXT-AWARE TRANSLATION, WHAT CONTEXT IS USEFUL TO DISAMBIGUATE HARD TRANSLATIONS SUCH AS AMBIGUOUS PRONOUNS OR WORD SENSES? TWO, ARE CONTEXT-AWARE MACHINE TRANSLATION MODELS PAYING
utt_0032 utt 197.02 203.00 -X ATTENTION TO THE RELEVANT CONTEXT OR NOT? THREE, IF NOT, CAN WE ENCOURAGE THEM TO DO
utt_0033 utt 204.66 217.63 -X SO? FIRST, WE CONDUCTED A USER STUDY TO COLLECT THE SUPPORTING CONTEXT WORDS THAT HUMAN TRANSLATORS USE FOR DISAMBIGUATION. WE ASKED twenty PROFESSIONAL ENGLISH-FRENCH TRANSLATORS TO SELECT
utt_0035 utt 217.63 223.36 -X THE CORRECT TRANSLATION AND THEN HIGHLIGHT ALL THE SUPPORTING CONTEXT WORDS THAT THEY USED TO ANSWER.
utt_0036 utt 224.06 236.19 -X WE PERFORMED THIS STUDY FOR TWO TASKS: FIRST, PRONOUN ANAPHORA RESOLUTION, WHERE THEY CHOOSE THE CORRECT GENDERED FRENCH PRONOUN THAT IS ASSOCIATED WITH A NEUTRAL ENGLISH PRONOUN, THEN WORD-SENSE
utt_0038 utt 236.28 243.42 -X DISAMBIGUATION, WHERE THE TRANSLATOR CHOOSES THE FRENCH TRANSLATION FOR A POLYSEMOUS ENGLISH WORD.
utt_0039 utt 245.91 257.42 -X WE GAVE TRANSLATORS VARYING AMOUNTS OF THE PREVIOUS SENTENCES IN THE ENGLISH SOURCE SIDE AND/OR THE FRENCH TARGET SIDE AS CONTEXT, AND WE ANALYZED WHEN TRANSLATORS ARE ABLE
utt_0041 utt 257.42 264.51 -X TO ANSWER ACCURATELY AND WITH HIGH CONFIDENCE DEPENDING ON HOW MUCH AND WHAT CONTEXT WAS GIVEN.
utt_0042 utt 264.57 269.38 -X WE ALSO ANALYZED THE SUPPORTING CONTEXT WORDS THAT HAVE BEEN SELECTED BY TRANSLATORS,
utt_0043 utt 269.38 275.30 -X BY LOOKING AT WHERE THESE WORDS ARE: IS IT IN THE CURRENT SENTENCE OR THREE SENTENCES BEFORE?
utt_0044 utt 275.30 286.85 -X WHETHER IT IS AN ENGLISH SOURCE OR A FRENCH TARGET WORD, AND THEN ITS FEATURES SUCH AS THE PART OF SPEECH AND SYNTACTIC DEPENDENCIES. YOU CAN LOOK AT OUR PAPER FOR THE FULL ANALYSIS AND THE RESULTS.
utt_0046 utt 288.99 296.23 -X OUR MAIN FINDINGS ARE THAT FOR PRONOUNS, THE PREVIOUS CONTEXT SENTENCES ARE THE MOST USEFUL,
utt_0047 utt 296.23 302.91 -X ESPECIALLY ON THE TARGET SIDE, AND WE FIND THAT HUMANS ESPECIALLY RELY ON THE PRONOUN ANTECEDENT,
utt_0048 utt 303.20 308.67 -X OR IN OTHER CASES THE OTHER REFERENCE OF THE PRONOUN IN THE TARGET SIDE.
utt_0049 utt 309.09 322.15 -X THE SAME COREFERENCE CHAIN IN THE ENGLISH SIDE IS NOT AS USEFUL, BECAUSE THE CHAIN IN FRENCH CAN CARRY INFORMATION ABOUT GENDER WHEREAS IN ENGLISH IT DOES NOT CARRY ANY INFORMATION ABOUT GENDER.
utt_0051 utt 324.13 329.92 -X NOW, DURING WORD-SENSE DISAMBIGUATION, THE CURRENT SENTENCE IN EITHER LANGUAGE IS OFTEN SUFFICIENT.
utt_0052 utt 330.94 344.34 -X FOR EXAMPLE, CHARME IN FRENCH MEANS THE QUALITY OF BEING CHARMING, WHILE PORTE-BONHEUR IS A GOOD LUCK CHARM. WE FIND THAT HUMANS OFTEN USE WORDS THAT CAN INDICATE THE ROLE OR MEANING OF THE
utt_0054 utt 344.34 352.23 -X POLYSEMOUS WORD. MOREOVER, THE SOURCE AND TARGET SIDE OFTEN CONTAIN AN EQUAL AMOUNT OF SEMANTIC
utt_0055 utt 352.23 360.42 -X LOAD WHICH IS USED FOR WORD-SENSE DISAMBIGUATION, WHICH IS WHY EITHER SIDE SEEMS TO BE AS USEFUL.
utt_0056 utt 360.42 365.29 -X AFTER OUR USER STUDY, WE ALSO ANNOTATED THE SUPPORTING CONTEXT FOR fourteen THOUSAND
utt_0057 utt 365.35 371.88 -X EXAMPLES OF PRONOUN ANAPHORA RESOLUTION IN ENGLISH-FRENCH, AND WE RELEASE THE SCAT DATASET.
utt_0058 utt 374.79 379.69 -X NEXT, TO EVALUATE WHETHER MODELS PAY ATTENTION TO THE RELEVANT CONTEXT,
utt_0059 utt 379.69 383.33 -X WE QUANTIFY HOW MUCH MODEL ATTENTION IS ALIGNED WITH SCAT.
utt_0060 utt 385.03 389.77 -X FOR OUR EXPERIMENTS, WE USE THE STANDARD TRANSFORMER TRANSLATION MODEL,
utt_0061 utt 390.02 395.82 -X BUT INSTEAD OF ONLY TAKING THE DATA SENTENCE BY SENTENCE AS WE DO FOR SENTENCE-LEVEL TRANSLATION,
utt_0062 utt 396.07 407.99 -X WE INCORPORATE THE FIVE PREVIOUS SOURCE AND TARGET SENTENCES AS THE CONTEXT BY CONCATENATING THEM TO THE CURRENT SENTENCE, THAT IS THEN FED INTO THE MODEL. WE USE fourteen
utt_0064 utt 408.00 412.94 -X MILLION PARALLEL ENGLISH-FRENCH SENTENCES FROM THE OPENSUBTITLES DATASET FOR TRAINING.
utt_0065 utt 413.99 425.19 -X TO QUANTIFY THE ALIGNMENT BETWEEN THE HUMANS AND THE MODEL'S ATTENTIONS, WE CONSTRUCT VECTORS THAT REPRESENT THE SCAT ANNOTATIONS AND THE MODEL ATTENTIONS WHILE TRANSLATING THE AMBIGUOUS
utt_0067 utt 425.19 438.60 -X PRONOUN. THEN, TAKING THIS SCAT VECTOR AND THE MODEL ATTENTION VECTOR, WE FIRST SORT THE TOKENS BY DECREASING MODEL ATTENTION WEIGHTS. THEN, WE LOOK FOR THE RANK OF THE FIRST SUPPORTING
utt_0069 utt 438.60 445.03 -X CONTEXT TOKEN FROM SCAT IN THE SORTED VECTOR. IN THIS EXAMPLE, THE ALIGNMENT SCORE BECOMES two,
utt_0070 utt 445.38 451.98 -X AND THE MORE ATTENTION THE MODEL ASSIGNS TO THE SUPPORTING CONTEXT, THE LOWER THE ALIGNMENT SCORE.
utt_0071 utt 451.98 459.18 -X WE ALSO USED TWO OTHER ADDITIONAL ALIGNMENT METRICS THAT YOU CAN FIND IN OUR PAPER :)
utt_0072 utt 459.18 471.24 -X USING THIS METRIC, WE COMPARE THE ALIGNMENT SCORE OF A UNIFORM DISTRIBUTION WITH THE ALIGNMENT SCORE OF OUR MODEL ATTENTION. FOR THE MODEL ATTENTION, WE MEASURE ALIGNMENT WITH SCAT FOR THE ENCODER
utt_0074 utt 471.24 483.24 -X SELF-ATTENTION, THE DECODER CROSS-ATTENTION, AND THE DECODER SELF-ATTENTION. WE FIND THAT THE ALIGNMENT BETWEEN THE ENCODER SELF-ATTENTION AND SCAT IS SLIGHTLY BETTER THAN THE ALIGNMENT SCORE
utt_0076 utt 483.24 490.03 -X OF A UNIFORM DISTRIBUTION, BUT ATTENTIONS AND THE DECODED LAYERS ESPECIALLY HAVE VERY LOW ALIGNMENT.
utt_0077 utt 490.92 496.72 -X IN GENERAL, CONTEXT-AWARE TRANSLATION MODELS DO NOT SEEM TO PAY ATTENTION TO THE RELEVANT CONTEXT.
utt_0078 utt 498.57 503.41 -X WE, THEREFORE, USE SCAT TO TRY TO INCREASE THE MODEL-HUMAN ALIGNMENT.
utt_0079 utt 504.75 508.94 -X WE TRAIN A CONTEXT-AWARE MODEL ON OPENSUBTITLES WITH THE STANDARD
utt_0080 utt 508.97 522.09 -X NEGATIVE LOG-LIKELIHOOD LOSS. WE ADDITIONALLY SAMPLE FROM SCAT DURING TRAINING AND WE INTRODUCE THE ATTENTION REGULARIZATION LOSS TO SUPERVISE THE MODEL ATTENTION.
utt_0082 utt 522.09 527.21 -X WE MEASURE MODEL PERFORMANCE USING CORPUS-LEVEL BLEU AND COMET. HOWEVER,
utt_0083 utt 527.21 532.65 -X WORDS SUCH AS AMBIGUOUS PRONOUNS REPRESENT ONLY A SMALL PORTION OF ALL WORDS IN DATA,
utt_0084 utt 532.81 545.01 -X SO CORPUS-LEVEL METRICS SUCH AS BLEU AND COMET MAY NOT CLEARLY CAPTURE IMPROVEMENTS IN TRANSLATING DISCOURSE PHENOMENA THAT ARE STILL VERY IMPORTANT FOR DOCUMENT-LEVEL TRANSLATION.
utt_0086 utt 545.01 556.75 -X WE THEREFORE ALSO COMPUTE THE MEAN WORD F-MEASURE OF THE TRANSLATIONS OF THE AMBIGUOUS PRONOUNS WITH RESPECT TO THE REFERENCE PRONOUNS, AND WE ALSO PERFORM CONTRASTIVE EVALUATION,
utt_0088 utt 556.75 566.26 -X WHERE WE MEASURE HOW OFTEN THE MODEL ASSIGNS A HIGHER PROBABILITY TO THE CORRECT TRANSLATION THAN A TRANSLATION WHERE THE AMBIGUOUS PRONOUN IS INCORRECT.
utt_0090 utt 568.81 574.39 -X WE FIND THAT ATTENTION REGULARIZATION IMPROVES TRANSLATION ACROSS ALL METRICS
utt_0091 utt 574.80 587.54 -X AND ESPECIALLY ON METRICS THAT ARE TARGETED TO PRONOUNS. WE CAN CONCLUDE THAT REGULARIZING ATTENTION WITH SCAT CAN EFFECTIVELY IMPROVE AMBIGUOUS PRONOUN TRANSLATION.
utt_0093 utt 587.54 600.79 -X WE ALSO FIND THAT MODELS WITH ATTENTION REGULARIZATION OBTAIN BETTER ATTENTION ALIGNMENT WITH SCAT. WE CAN ALSO SEE THAT THE MODEL WITH ATTENTION REGULARIZATION
utt_0095 utt 600.79 605.41 -X ASSIGNS HIGHER ATTENTION TO THE WORDS REPORT AND RAPPORT IN THIS EXAMPLE
utt_0096 utt 605.52 611.03 -X WHILE TRANSLATING THE AMBIGUOUS PRONOUN, AND THEN IS ABLE TO TRANSLATE THE PRONOUN CORRECTLY.
utt_0097 utt 611.60 623.35 -X THIS SUGGESTS THAT MODELS THAT ATTENTION REGULARIZATION WITH SCAT CAN ENCOURAGE MODELS TO PAY THE RIGHT ATTENTION AND THUS ALLOWING THEM TO TRANSLATE AMBIGUOUS WORDS CORRECTLY.
utt_0099 utt 625.23 634.76 -X OUR PAPER CONTAINS MORE EXPERIMENTS THAT DEMONSTRATE THAT MODELS WITH ATTENTION REGULARIZATION WITH SCAT RELY MORE ON THE SUPPORTING CONTEXT THAT HAS BEEN SELECTED
utt_0101 utt 634.76 647.89 -X BY HUMANS, AND THAT REGULARIZING THE ENCODER SELF-ATTENTION GIVES THE LARGEST IMPROVEMENTS IN TRANSLATION PERFORMANCE COMPARED TO REGULARIZING OTHER TYPES OF MODEL ATTENTION. PERFORMANCE ON
utt_0103 utt 647.89 661.97 -X WORD-SENSE DISAMBIGUATION DOES NOT IMPROVE MUCH WHEN WE SUPERVISE THE MODEL ATTENTION USING HUMAN RATIONALES FOR PRONOUN ANAPHORA RESOLUTION. TO SUMMARIZE, WE ASKED HUMANS TO TELL US WHAT CONTEXT
utt_0105 utt 661.97 667.51 -X IS USEFUL TO TRANSLATE AMBIGUOUS WORDS AND WE COLLECTED A CORPUS OF fourteen zero SUPPORTING CONTEXT.
utt_0106 utt 668.24 674.94 -X THEN, WE USE THE SCAT DATASET TO MEASURE ALIGNMENT BETWEEN HUMAN AND MODEL ATTENTION,
utt_0107 utt 675.19 681.24 -X AND WE FIND THAT PREVIOUS CONTEXT-AWARE MODELS HAVE VERY LOW ALIGNMENT.
utt_0108 utt 681.24 693.50 -X WE, THEREFORE, USE SCAT TO REGULARIZE ATTENTION IN CONTEXT-AWARE TRANSLATION MODELS AND WE THUS OBTAIN BETTER MODEL-HUMAN ALIGNMENT, BETTER CONTEXT USAGE, AND BETTER TRANSLATION QUALITY.
utt_0110 utt 694.42 703.22 -X YOU CAN FIND MORE INFORMATION ON OUR WORK IN OUR PAPER AS WELL AS THE CODE AND DATA THAT ARE PUBLICLY AVAILABLE, AND WE THANK YOU FOR YOUR ATTENTION :)
