utt_0000 utt 0.81 7.54 -X HI, I'M WENCAN ZHANG A PHD STUDENT FROM THE UBICOMP LAB AT THE NATIONAL UNIVERSITY OF SINGAPORE.
utt_0002 utt 7.54 13.26 -X TODAY, LET ME INTRODUCE OUR PAPER TOWARDS RELATABLE EXPLAINABLE AI WITH THE PERCEPTUAL PROCESS
utt_0004 utt 14.83 17.84 -X HEY WENCAN, YOU ARE SOUNDING FEARFUL. CHEER UP!
utt_0005 utt 18.77 24.90 -X WELL, YOU'RE RIGHT. YOU KNOW, IT'S MY FIRST TIME TO PRESENT AT CHI, BUT
utt_0006 utt 25.93 27.79 -X HOW DO YOU KNOW THAT I'M FEARFUL?
utt_0007 utt 29.17 33.20 -X BECAUSE YOUR SPEECH LOOKS LIKE THIS AND THE HIGHLIGHTED REGIONS REFLECT FEAR.
utt_0008 utt 34.54 44.31 -X AS WE CAN SEE, ALTHOUGH THE SALIENCY MAP WITH THE SPECTROGRAM CAN FAITHFULLY EXPLAIN THE SPEECH RECOGNITION MODEL'S DECISION, IT DOESN'T MAKE SENSE FOR END USERS,
utt_0010 utt 44.94 48.08 -X SINCE THE INFORMATION IS TOO TECHNICAL TO UNDERSTAND
utt_0011 utt 48.14 50.58 -X AND DOESN'T PROVIDE RELATABLE SEMANTICS.
utt_0012 utt 50.77 57.36 -X MORE IMPORTANTLY, THE MODEL DOESN'T THINK IN A HUMAN-LIKE MANNER AND EXPLAIN ITSELF ACCORDINGLY.
utt_0013 utt 57.58 71.00 -X ALL THESE PITFALLS WILL LIMIT THE MODEL'S INTERPRETABILITY TO END USERS WHICH HINDERS THE DEPLOYMENT OF AI SERVICES IN VARIOUS REAL-WORLD APPLICATIONS.
utt_0015 utt 71.00 77.41 -X TO MITIGATE THE PREVIOUS PROBLEMS, WE ARGUE THAT EXPLAINABLE AI SHOULD BE RELATABLE TO
utt_0016 utt 77.65 83.73 -X ABSTRACT CONCEPTS, EXEMPLARS THAT ARE REPRESENTATIVE TO THE CONCEPT CLASS, AND
utt_0017 utt 83.86 92.44 -X CUES THAT DESCRIBE IN TERMS OF HUMAN-UNDERSTANDABLE SEMANTICS.
utt_0018 utt 92.56 98.26 -X INSPIRED BY THE HUMAN PERCEPTUAL PROCESS FROM COGNITIVE PSYCHOLOGY WHERE:
utt_0019 utt 98.26 101.69 -X GIVEN THE STIMULI, WE SELECT SALIENT PARTS
utt_0020 utt 102.13 115.13 -X ORGANIZE THEM INTO CUES AND INTERPRET THEM BY RECALLING RELEVANT CONCEPT AND ASSOCIATED CUES, COMPARING THEIR SIMILARITY TO THE STIMULI, AND CATEGORIZING TO A CONCEPT
utt_0022 utt 115.86 122.39 -X WE PROPOSE THE XAI PERCEPTUAL PROCESSING FRAMEWORK WITH CORRESPONDING CAPABILITIES.
utt_0023 utt 122.39 130.81 -X NEXT, LET'S SEE HOW THE PERCEPTUAL PROCESS CAN GUIDE US TOWARDS MORE USEFUL EXPLANATIONS.
utt_0024 utt 131.45 137.40 -X LET'S CONSIDER THE APPLICATION OF PREDICTING EMOTION FROM PEOPLE'S VOICES.
utt_0025 utt 137.40 142.62 -X SUPPOSE OUR AI HEARS THIS VOICE DOGS ARE SITTING BY THE DOOR,
utt_0026 utt 143.16 145.37 -X AND PREDICTS IT AS FEARFUL.
utt_0027 utt 146.17 150.04 -X WE CAN COMPARE IT WITH SOME OTHER COUNTERFACTUAL VOICE
utt_0028 utt 151.32 154.81 -X DOGS ARE SITTING BY THE DOOR.
utt_0029 utt 154.81 159.79 -X WE CAN ALSO ANALYZE HOW THE TWO VOICES ARE DIFFERENT WITH CONTRASTIVE CUES
utt_0030 utt 159.80 162.72 -X AND SEE WHICH PARTS WERE ESPECIALLY SALIENT.
utt_0031 utt 163.16 166.30 -X SO HOW CAN AI SUPPORT THESE EXPLANATIONS?
utt_0032 utt 166.97 172.54 -X INSPIRED FROM THE XAI PERCEPTUAL PROCESSING FRAMEWORK WITH DIFFERENT INTERPRETABILITY GOALS,
utt_0033 utt 172.79 177.21 -X WE PROPOSE REXNET, THE RELATABLE EXPLANATION NETWORK.
utt_0034 utt 177.21 182.21 -X STARTING WITH A CONVOLUTIONAL NEURAL NETWORK (CNN) TO PREDICT THE EMOTION OF A VOICE CLIP,
utt_0035 utt 182.36 185.95 -X WE DEVELOPED SEVERAL MODULES FOR DIFFERENT EXPLANATIONS.
utt_0036 utt 186.39 189.01 -X FIRST, IT GENERATES A SERIES IN MAP
utt_0037 utt 189.02 194.33 -X OF WHICH PARTS OF THE INPUTS ARE IMPORTANT FOR THE PREDICTION USING GRAD-CAM.
utt_0038 utt 194.33 198.40 -X SECOND, IT FOCUSES ON THE SALIENT REGIONS AND CALCULATES CUES,
utt_0039 utt 198.40 200.83 -X SUCH AS PITCH AND VOLUME OF THE VOICE.
utt_0040 utt 202.27 211.46 -X THIRD, IT GENERATES A SYNTHETIC EXAMPLE OF AN ALTERNATIVE PREDICTION CLASS, SUCH AS A COUNTEFACTUAL ANGRY VOICE.
utt_0042 utt 211.46 214.77 -X IT ALSO GENERATES THE SALIENCY (MAP) FOR THAT EXAMPLE
utt_0043 utt 214.78 220.16 -X AND CONTRASTS BETWEEN THE COUNTERFACTUAL AND FACTUAL INSTANCES.
utt_0044 utt 220.16 225.76 -X AND CALCULATES CUES FOR BOTH INSTANCES.
utt_0045 utt 225.76 232.61 -X WITH BOTH ABSOLUTE CUES, IT CAN THEN CALCULATE THEIR DIFFERENCE TO GET THE CONTRASTIVE CUES.
utt_0046 utt 233.60 242.40 -X FINALLY, REXNET TAKES ALL THIS INTERMEDIATE EXPLANATORY INFORMATION TO MAKE A FINAL CONCEPTUAL PREDICTION OF THE EMOTION.
utt_0048 utt 242.56 247.14 -X UNLIKE MOST XAI METHODS THAT PROVIDE POST-HOC EXPLANATIONS,
utt_0049 utt 247.49 255.72 -X REXNET IS DESIGNED TO BE INTRINSICALLY INTERPRETABLE AND PROVIDES ANTE-HOC EXPLANATIONS BASED ON CORRESPONDING MODULES.
utt_0051 utt 257.25 260.96 -X THERE ARE THREE MAIN EXPLAINABLE MODULES IN REXNET.
utt_0052 utt 261.31 266.34 -X CONTRASTIVE SALIENCY, COUNTERFACTUAL SYNTHETIC, AND CONTRASTIVE CUES.
utt_0053 utt 266.34 268.74 -X LET'S LOOK INTO MORE DETAILS.
utt_0054 utt 268.74 274.15 -X GIVEN THE ORIGINAL VOICE TO BE RECOGNIZED DOGS ARE SITTING BY THE DOOR,
utt_0055 utt 274.66 285.86 -X WE USE STARGAN, A GENERATIVE MODEL, TO CONSTRUCT REALISTIC SPEECH SAMPLES AS A COUNTERFACTUAL SYNTHETIC EXPLANATION, WHICH CONVERTS THE SPEECH INTO A SPECIFIC
utt_0057 utt 285.86 291.88 -X EMOTIONAL STYLE, SUCH AS ANGRY DOGS ARE SITTING BY THE DOOR.
utt_0058 utt 291.94 295.08 -X DURING THIS PROCESS OTHER SPEECH INFORMATION,
utt_0059 utt 295.08 299.05 -X SUCH AS THE SPEAKER'S IDENTITY OR THE LEXICAL CONTENT WOULD NOT CHANGE.
utt_0060 utt 299.11 304.90 -X THE COUNTERFACTUAL CAN PROVIDE USERS A REFERENCE STATE FOR THEIR AUDITORY PERCEPTION,
utt_0061 utt 305.15 310.06 -X BUT IT WOULD BE BETTER TO PROVIDE USERS MORE INFORMATION.
utt_0062 utt 310.06 316.97 -X THE SALIENCY MAP IS A COMMON TECHNIQUE TO EXPLAIN WHICH PIXELS ARE IMPORTANT FOR AN IMAGE RECOGNITION MODEL.
utt_0064 utt 316.97 324.58 -X INSPIRED BY THAT, WE USE THE SALIENCY BARS TO HIGHLIGHT IMPORTANT WORD SEGMENTS FOR RECOGNIZING EMOTION FROM VOICES.
utt_0066 utt 325.09 330.89 -X IN ADDITION, SOME SEGMENTS WOULD ALWAYS BE HIGHLIGHTED WITH REGARD TO ANY EMOTION,
utt_0067 utt 330.89 333.38 -X WHICH MAKES THEM LESS INDICATIVE.
utt_0068 utt 333.38 335.67 -X WE INTRODUCED A DISCOUNT FACTOR
utt_0069 utt 335.69 342.76 -X AND PROPOSED A CONTRASTIVE RESILIENCY TO DE-EMPHASIZE THE INFLUENCE FROM THOSE SEGMENTS.
utt_0070 utt 342.76 347.79 -X SIMILARLY, WE CAN GET THE CONTRASTIVE SALIENCY FOR THE COUNTERFACTUAL SAMPLE.
utt_0071 utt 348.33 354.06 -X PRIOR PSYCHOLOGY STUDIES INDICATE THAT VOCAL CUE PATTERNS VARY WITH EMOTIONS,
utt_0072 utt 354.06 356.87 -X WHICH CAN HELP PEOPLE DISTINGUISH BETWEEN EMOTIONS.
utt_0073 utt 357.35 371.08 -X INSPIRED BY THAT, WE FIRSTLY OBTAIN THE ABSOLUTE CUE PATTERNS FROM VOICE CLIPS, AND THEN PROVIDE THE CONTRASTIVE CUES AS ANOTHER EXPLANATION WHICH DESCRIBES A RELATIVE CUE RELATION.
utt_0075 utt 371.08 377.55 -X WE EVENTUALLY COMBINE THE PERCEPTION-LEVEL COUNTERFACTUAL SYNTHETICS AND THE SEMANTIC-LEVEL CONTRASTIVE CUES
utt_0078 utt 383.02 388.20 -X WE CONDUCTED A MODELING STUDY TO EVALUATE THE MODEL PERFORMANCE AND EXPLANATION FAITHFULNESS.
utt_0079 utt 388.71 396.14 -X WITH fourteen PARTICIPANTS, WE EXPLORED THE USAGE AND USABILITY OF RELATABLE EXPLANATIONS IN A FORMATIVE USER STUDY.
utt_0082 utt 399.27 404.62 -X WE QUANTIFIED THE USEFULNESS IN A SUMMATIVE USER STUDY.
utt_0083 utt 404.62 411.82 -X SPECIFICALLY, TO VERIFY WHETHER OUR METHOD IS GOOD ENOUGH IN TERMS OF THE PREDICTION PERFORMANCE AND EXPLANATIONS,
utt_0085 utt 412.27 417.81 -X WE COMPARE A BASE CNN SPEECH EMOTION RECOGNITION MODEL AGAINST REXNET.
utt_0086 utt 418.92 422.08 -X THE RESULTS FROM OUR MODELING STUDY INDICATES THAT
utt_0087 utt 422.32 425.94 -X REXNET CAN IMPROVE THE EMOTION RECOGNITION ACCURACY,
utt_0088 utt 426.06 431.31 -X PROBABLY SINCE THE MODEL IS TRAINED TO BE AWARE OF CUE INFORMATION.
utt_0089 utt 431.31 436.53 -X WE ALSO CONFIRM THAT REXNET CAN PROVIDE FAITHFUL CONTRASTIVE SALIENCY,
utt_0090 utt 436.53 439.68 -X REASONABLE RECONSTRUCTED COUNTERFACTUAL EXPLANATIONS
utt_0091 utt 439.95 443.47 -X AND ACCURATE CUE RELATIONS.
utt_0092 utt 443.47 451.06 -X NEXT, WE USE A RELATABLE XAI USER INTERFACE TO EVALUATE PARTICIPANTS ON A VOCAL EMOTION RECOGNITION TASK,
utt_0094 utt 451.06 454.50 -X BASED ON HUMAN SIMULATABILITY WHERE THEY NEEDED TO
utt_0095 utt 454.77 460.69 -X LISTEN TO THE VOICE CLIP WITH EXPLANATIONS DEPENDING ON THE PRE-ALLOCATED CONDITIONS,
utt_0096 utt 461.13 468.02 -X RATE HOW HELPFUL THE EXPLANATIONS WERE AND LABEL THE EMOTION IN A BALLS AND BINS QUESTION.
utt_0097 utt 468.02 476.60 -X HERE, THE BALLS AND BINS QUESTION CAN ACCURATELY CAPTURE THE USER'S CONFIDENCE OF THE CORRECT LABEL EVEN IF HER MOST LIKELY CHOICE IS WRONG.
utt_0099 utt 478.29 484.44 -X IN THE FORMATIVE USER STUDY, WE EXPLORED HOW USABLE ARE RELATABLE EXPLANATIONS.
utt_0100 utt 484.44 488.60 -X THE RESULTS SHOW THAT COUNTERFACTUAL SAMPLES ARE MORE INTUITIVE,
utt_0101 utt 488.60 495.09 -X WHILE CONTRASTIVE CUES AND CONTRASTIVE SALIENCY ARE USED TO CONFIRM USERS' INITIAL JUDGMENTS.
utt_0102 utt 495.09 505.62 -X THEY WOULD MAKE DECISIONS BY INTERPRETING EXPERIENTIALLY BASED ON THE VOICE THEY HEARD AND SEMANTICALLY BASED ON CUE DESCRIPTIONS.
utt_0104 utt 505.68 512.21 -X WE ALSO OBSERVED THE MISINTERPRETATION ON SALIENCY BARS. MAYBE IT'S TOO TECHNICAL FOR LAY USERS.
utt_0105 utt 512.21 519.89 -X WE ALSO IDENTIFIED THAT THE MACHINE-GENERATED SALIENCY BARS MAY NOT WELL ALIGN WITH THE USER'S MENTAL MODEL.
utt_0107 utt 519.89 523.99 -X TO ANSWER THE QUESTION HOW USEFUL ARE RELATABLE EXPLANATIONS?,
utt_0108 utt 524.21 533.75 -X WE ASKED PARTICIPANTS THEIR PERCEIVED EXPLANATION HELPFULNESS AND ALSO OBJECTIVELY MEASURED BY RECORDING WHETHER THEY COULD CORRECTLY LABEL THE EMOTION.
utt_0110 utt 533.75 540.82 -X WITH THE HELP OF AI AND EXPLANATIONS, COMPARED TO THE BASELINE CONDITION OF NO EXPLANATION (NONE),
utt_0111 utt 540.82 545.59 -X WE FOUND THAT PARTICIPANTS PERCEIVED ALL EXPLANATIONS AS MORE HELPFUL.
utt_0112 utt 545.59 551.23 -X HOWEVER, INCLUDING SALIENCY EXPLANATIONS MAY DEGRADE THEIR DECISION PERFORMANCE.
utt_0113 utt 551.38 557.85 -X THIS CAN BE EXPLAINED BY THE MISALIGNMENT ISSUE IN OUR PREVIOUS QUALITATIVE FINDINGS.
utt_0114 utt 557.91 562.46 -X THEREFORE, WE CONCLUDE THAT RELATABLE EXPLANATIONS ARE USEFUL,
utt_0115 utt 562.46 566.52 -X BUT THEY NEED TO BE COLLECTIVELY COHERENT.
utt_0116 utt 566.52 570.92 -X TO SUMMARIZE, WE CONTRIBUTE THE XAI PERCEPTUAL PROCESSING FRAMEWORK
utt_0117 utt 571.06 575.45 -X WITH THE REXNET MODEL THAT CAN PROVIDE MULTIPLE RELATABLE EXPLANATIONS.
utt_0118 utt 576.41 581.92 -X THIS IS THE FIRST TO PROVIDE HUMAN-UNDERSTANDABLE EXPLANATIONS FOR AUDIO PREDICTION.
utt_0119 utt 581.92 583.58 -1.6794 THANKS FOR LISTENING!
