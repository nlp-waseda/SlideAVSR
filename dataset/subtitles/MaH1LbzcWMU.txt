utt_0000 utt 0.22 10.56 -X WELCOME TO OUR TALK ON THE COMPARATIVE ANALYSIS OF CNN BASED SPATIAL TEMPORAL REASONING IN VIDEOS THIS IS THE FIRST AUTHOR WORK OF OKAN KÖPÜKLÜ A JOINT WORK WITH GERHARD RIGOLL AND I'M FABIAN
utt_0002 utt 10.56 21.65 -X HERZOG PRESENTING THIS PAPER TO YOU TODAY AS THE TITLE INDICATES OUR RESEARCH IS ON CNN BASED SPATIAL TEMPORAL MODELING IN VIDEOS AND EVEN THOUGH twoD CNNS ARE AN INCREDIBLE SUCCESS
utt_0004 utt 21.65 26.64 -X STORY FOR IMAGE PROCESSING IN RECENT YEARS VIDEOS ARE STILL RATHER DIFFICULT TO PROCESS
utt_0005 utt 27.76 39.96 -X twoD CNNS CAN BE EXTENDED TO threeD CNNS BUT FOR VIDEOS THAT ARE VERY LONG OR VIDEOS THAT HAVE VARYING LENGTHS THIS CAN BE VERY DIFFICULT TO PROCESS OUR ASSUMPTION IS THAT FOR LONG VIDEOS twoD CNN
utt_0007 utt 40.18 52.05 -X FEATURES ON SAMPLED FRAMES ARE STILL USEFUL WE THEREFORE SUGGEST THE FOLLOWING SPATIAL TEMPORAL MODELING ARCHITECTURE BASED ON twoD CNN FEATURE EXTRACTION ON SAMPLED FRAMES TO FURTHER COMPARE
utt_0009 utt 52.05 64.34 -X DIFFERENT SPATIOTEMPORAL MODELING TECHNIQUES: FIRST, A VIDEO OF ANY LENGTH CAN BE PROCESSED BY DIVIDING THE VIDEO INTO N SEGMENTS THEN WE REPRESENT EACH SEGMENT WITH ONE FRAME BY EQUIDISTANT SAMPLING THE
utt_0011 utt 64.34 76.92 -X SAMPLED IMAGES ARE THEN FORWARDED THROUGH A twoD CNN AND OBVIOUSLY EACH INDIVIDUAL FRAME CANNOT REPRESENT THE SPATIAL TEMPLE CONTENT OF THE VIDEO, SO WE USE THE EXTRACTED FEATURE VECTORS
utt_0013 utt 76.92 87.99 -X AND WE HAVE TO COMBINE THEM IN A SPATIAL TEMPORAL MODELING MODULE. IT IS IMPORTANT TO NOTE THAT THIS ARCHITECTURE WORKS END-TO-END AND AFTER HAVING ADDED THE ST-MODELING BLOCK, WE ARE ABLE
utt_0015 utt 87.99 100.33 -X TO COMPUTE CLASS SCORES FOR VIDEO CLASSIFICATION TASKS. HERE'S AN OVERVIEW OF THE SPATIOTEMPORAL TECHNIQUES THAT WE USED IN OUR PAPER THEY CAN BE CATEGORIZED INTO THREE GROUPS: THE FIRST GROUP ARE
utt_0017 utt 100.33 111.23 -X MULTI-LAYER PERCEPTRON METHODS. THESE METHODS USE A MULTI-LAYER PERCEPTRON AT LEAST ONCE IN THEIR ARCHITECTURE. THE SECOND GROUP ARE RECURRENT NEURAL NETWORK METHODS WHICH ARE QUITE AN INTUITIVE WAY
utt_0019 utt 111.23 124.44 -X TO PROCESS SEQUENTIAL INFORMATION AND THE THIRD GROUP ARE FULLY CONVOLUTIONAL METHODS WHICH DON'T USE A FULLY CONNECTED AND THEN NUMBER TO CLASSES LAYER AT THE END WITH A SOFTMAX CLASSIFICATION,
utt_0021 utt 124.63 139.42 -X INSTEAD THEY WORK IN A FULLY CONVOLUTIONAL WAY BY REDUCING THE PROBLEM WITH CONVOLUTIONS TO A NUMBER OF CLASSES FEATURE. WITHIN THE GROUP OF MULTI-LAYER PERCEPTRON METHODS WE FIRST INVESTIGATE A SIMPLE
utt_0023 utt 139.42 152.25 -X MLP WHICH JUST USES THE CONCATENATED FRAME FEATURES AND THEN ADDS TWO FULLY CONNECTED LAYERS AND A SOFT MAX LAYER FOR CLASSIFICATION. THIS IS THE SIMPLEST MODEL YOU CAN THINK OF. TEMPORAL
utt_0025 utt 152.25 162.45 -X SEGMENT NETWORKS AIM TO ACHIEVE LONG-RANGE TEMPORAL STRUCTURE MODELING USING A SPARSE SAMPLING STRATEGY THE EXTRACTED FRAME FEATURES ARE TRANSFORMED TO NUMBER OF CLASSES DIMENSION
utt_0027 utt 162.45 174.78 -X AND AVERAGED TO GET CLASS CONDITIONAL SCORES IN TEMPORAL RELATION NETWORKS FEATURES EXTRACTED FROM DIFFERENT SEGMENTS OF A VIDEO BY A twoD CNN ARE FED INTO DIFFERENT FRAME RELATION MODULES FOR EXAMPLE
utt_0029 utt 174.78 185.06 -X THE TWO FRAME RELATION MODELS CONSIDERS PAIRS OF FRAMES AND PASSES THEM THROUGH AN MLP BLOCK THE THREE FRAME RELATION MODULE CONSIDERS THREE TUPLES OF FRAMES AND PASSES THEM THROUGH
utt_0031 utt 185.06 196.80 -X MLP BLOCKS AND FINALLY WE AGGREGATE THE FEATURES THAT WE GET FROM THE INDIVIDUAL MODELS TO OBTAIN A FINAL CLASS SCORE. WITHIN THE GROUP OF RECURRENT NEURAL NETWORKS WE FIRST INVESTIGATE
utt_0033 utt 196.80 209.62 -X VANILLA RNNS SO THE STANDARD RNN ARCHITECTURES WITH TWO DIFFERENT ACTIVATION FUNCTIONS THE RECTIFIED LINEAR UNIT FUNCTION AND THE HYPERBOLIC TANGENT FUNCTION WE FEED THE OUTPUT OF THE LAST
utt_0035 utt 209.62 213.92 -X NODE TO A FULLY CONNECTED LAYER TO OBTAIN A VECTOR SIZE OF THE NUMBER OF CLASSES IN THE DATA SET
utt_0036 utt 214.11 224.29 -X BECAUSE VANILLA IRON ENDS ARE USUALLY SUBJECTED TO THE VANISHING GRADIENT PROBLEM WE ALSO INVESTIGATE LONG SHORT TERM MEMORY AND GATED RECURRENT UNIT MODELS WE ALSO INVESTIGATE BIDIRECTIONAL LONG
utt_0038 utt 224.29 235.51 -X SHORT TERM MEMORY SYSTEMS WHICH ARE SPECIAL FORM OF LSTMS BUT TRAINED IN BOTH DIRECTIONS FINALLY WE USE CONVOLUTIONAL LSDMS WHICH PROPOSE TO USE CONVOLUTIONAL STRUCTURES FOR THE LSTM TRANSITIONS
utt_0040 utt 235.51 245.96 -X FOR THE FULLY CONVOLUTIONAL METHODS ALL THE LAYERS ARE CONVOLUTIONAL LAYERS THEY DO NOT CONTAIN ANY LINEAR OR FULLY CONNECTED LAYERS AT THE END WHICH WOULD BE TYPICAL FOR A CLASSIFICATION TASK INSTEAD
utt_0042 utt 245.96 256.90 -X WE USE A SEQUENCE OF CONVOLUTIONAL LAYERS AND FINALLY AVERAGE POOLING TO REDUCE THE FEATURE SIZE TO NUMBER OF CLASSES DIMENSION FOR THE EVALUATION WE CONSIDER TWO DATA SETS THE SOMETHING SOMETHING
utt_0044 utt 256.90 267.66 -X DATA SET DEPICTED ABOVE IS A COLLECTION OF SEGMENTED VIDEO CLIPS THAT SHOW HUMANS PERFORMING PREDEFINED BASIC ACTIONS WITH EVERYDAY OBJECTS THE DATA SET CONSISTS OF two hundred and twenty eight hundred and forty-seven VIDEO CLIPS UNDER one hundred and twenty-four
utt_0046 utt 270.18 275.94 -X CLASSES THE JESTER DATA SET DEPICTED BELOW IS A LARGE HAND GESTURE DATA SET WHICH CONSISTS
utt_0047 utt 277.19 287.82 -X OF one hundred and forty-eight ninety-two VIDEO CLIPS UNDER twenty-seven CLASSES FOR CNN BACKBONES WE USE SQUEEZE NET AND B AND INCEPTION AND WE TRAIN WITH STOCHASTIC GRADIENT DESCENT WITH CROSS ENTROPY LOSS MOMENTUM AND WEIGHT DECAY
utt_0049 utt 287.84 297.87 -X WE USE DROPOUT AND SOME DATA AUGMENTATION HERE ARE ALL THE RESULTS OF OUR EXPERIMENTS FOR THE GESTURE DATA SET WE CONSIDERED EIGHT SEGMENTS AND FOR THE SOMETHING SOMETHING DATA SET WE CONSIDERED
utt_0051 utt 298.15 309.80 -X eight AND sixteen SEGMENTS FOR EACH OF THE EXPERIMENTS WE INVESTIGATED THE MODULES PERFORMANCE UNDER SQUEEZE NET BACKBONE AND BE AN INCEPTION BACKBONE FOR THE JESTER DATA SET OUT OF ALL ST MODELING TECHNIQUES
utt_0053 utt 309.80 316.20 -X TRN MULTISCALE twoDFCN threeDFCN AND CONVOLUTIONAL LSTM STAND OUT FOR CLASSIFICATION ACCURACY
utt_0054 utt 316.36 327.50 -X CONSIDERING THE RESOURCE EFFICIENCY THE SIMPLE MLP MODEL CAN ALSO BE PREFERRED OVER TR AND MULTISCALE BUT SURPRISINGLY RNN-BASED METHODS EXCEPT CONVOLUTIONAL LSDM WHICH FIRST COME TO MIND
utt_0056 utt 327.50 338.56 -X FOR MODELING SEQUENCES PERFORM WORSE THAN THESE TECHNIQUES SIMILARLY TO THE SOMETHING SOMETHING DATA SET THE threeD FCN CONVOLUTIONAL LSTM AND TR AND MULTISCALE AGAIN STANDOUT FOR CLASSIFICATION
utt_0058 utt 338.56 344.13 -X ACCURACY SPECIFICALLY threeDFCN WITH SQUEEZENET PERFORMS BEST OUTPERFORMING THE SECOND BEST MODEL
utt_0060 utt 350.70 359.68 -X PERFORM THE BEST BUT HAVE QUITE A HIGH NUMBER OF PARAMETERS AND THE SIMPLE MLP PERFORMS QUITE WELL WITH A LOWER NUMBER OF PARAMETERS THE CHOSEN BACKBONES CAN HEAVILY INFLUENCE THE RESULTS
