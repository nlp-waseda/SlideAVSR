utt_0000 utt 4.65 15.36 -X THIS WORK PRESENTS A NEURAL NETWORK-BASED FRAMEWORK FOR ESTIMATING KEYPOINT POSITION UNCERTAINTY IN VISUAL ODOMETRY. FEATURE-BASED FRAME-TO-FRAME POSE ESTIMATION MAKES USE OF
utt_0002 utt 15.36 25.79 -X IDENTIFYING CORRESPONDING KEYPOINTS IN TWO IMAGES. NOISY KEYPOINT POSITIONS LEAD TO SMALL ERRORS IN THE ESTIMATED POSE. ACCOUNTING FOR THIS NOISE DISTRIBUTION WAS SHOWN TO
utt_0004 utt 25.79 31.76 -X LEAD TO BETTER POSE ESTIMATES BY FOCUSING ON KEYPOINTS WITH LESS POSITIONAL NOISE. HOWEVER,
utt_0005 utt 31.76 42.84 -X NOT ALL KEYPOINT EXTRACTORS EXHIBIT THE SAME NOISE DISTRIBUTION, SUCH THAT THERE IS NO UNIFIED MODEL FOR KEYPOINT UNCERTAINTY.\NOUR FRAMEWORK LEARNS THE NOISE DISTRIBUTION FOR ANY KEYPOINT
utt_0007 utt 42.84 54.74 -X EXTRACTOR BY MAKING USE OF DIFFERENTIABLE NON-LINEAR LEAST SQUARES. DNLS ALLOWS OUR FRAMEWORK TO TRAIN A NEURAL NETWORK DIRECTLY FROM POSE ESTIMATION ERRORS. THE SO-OBTAINED
utt_0009 utt 54.74 67.17 -X COVARIANCES LEAD TO BETTER POSE ESTIMATES AND REDUCE LONG-TERM POSE DRIFT IN A VISUAL ODOMETRY SETTING.\NESTIMATING THE POSE BETWEEN TWO IMAGES IS A LONG-STANDING PROBLEM
utt_0011 utt 67.17 73.46 -X IN COMPUTER VISION.\NFEATURE-BASED APPROACHES USE CORRESPONDING KEYPOINTS AND GEOMETRIC CONSTRAINTS,
utt_0012 utt 73.46 88.49 -X SUCH AS THE EPIPOLAR CONSTRAINT, TO OPTIMIZE THE POSE.\N\NNOT
utt_0013 utt 88.49 99.10 -X ALL CORRESPONDING KEYPOINTS ARE EQUALLY WELL SUITED TO ACCURATELY ESTIMATE THE POSE AS KEYPOINT POSITIONS EXHIBIT SMALL ERRORS. RECENT LITERATURE HAS MODELED THIS SMALL
utt_0015 utt 99.10 110.68 -X ERROR AS RANDOM GAUSSIAN NOISE IN THE IMAGE PLANE AND DERIVED A PROBABILISTIC OPTIMIZATION SCHEME ACCOUNTING FOR THIS UNCERTAINTY.\NACCOUNTING FOR THE KEYPOINT
utt_0017 utt 110.68 123.85 -X UNCERTAINTY IN THE OPTIMIZATION LEADS TO REDUCED DRIFT IN TASKS SUCH AS VISUAL ODOMETRY.\N\NTO USE THIS PROBABILISTIC APPROACH, THE UNCERTAINTY OF THE KEYPOINTS HAS TO BE
utt_0019 utt 123.85 136.54 -X CORRECTLY ESTIMATED.\NHOWEVER, KEYPOINT EXTRACTORS EXHIBIT DIFFERENT ERROR DISTRIBUTIONS LEADING TO THE NECESSITY OF MODELING THE NOISE DISTRIBUTIONS FOR EACH KEYPOINT EXTRACTOR INDIVIDUALLY, AS DONE
utt_0021 utt 136.54 142.84 -X BY PREVIOUS LITERATURE WORK.\N\NTO ADDRESS THE DIFFICULTY OF CORRECTLY MODELING THE UNCERTAINTY,
utt_0022 utt 142.84 155.56 -X WE PROPOSE A DATA-DRIVEN FRAMEWORK THAT WORKS FOR ANY KEYPOINT EXTRACTOR USING A DEEP NEURAL NETWORK TO PREDICT THE POSITIONAL UNCERTAINTY DIRECTLY FROM THE IMAGES.\NOUR
utt_0024 utt 155.56 162.04 -X NETWORK LEARNS TO PREDICT A DENSE UNCERTAINTY MAP FROM IMAGES. COMBINED WITH KEYPOINT PREDICTIONS,
utt_0025 utt 162.04 172.72 -X THIS PRODUCES KEYPOINTS WITH THEIR CORRESPONDING UNCERTAINTY ESTIMATE, WHICH CAN BE USED IN THE AFOREMENTIONED PROBABILISTIC NORMAL EPIPOLAR CONSTRAINT OPTIMIZATION.\NWE
utt_0027 utt 172.72 183.10 -X TRAIN OUR NETWORK THROUGH DIFFERENTIABLE NON-LINEAR LEAST SQUARES DIRECTLY FROM THE POSE ESTIMATION ERROR.\NTHE NON-LINEAR LEAST SQUARES FORMULATION OF THE PNEC
utt_0029 utt 183.23 194.05 -X ALLOWS US TO USE IMPLICIT DIFFERENTIATION TO DETERMINE THE GRADIENT OF THE POSE ERROR WITH REGARD TO UNCERTAINTY ESTIMATES WHICH IS THEN USED TO TRAIN THE NETWORK TO PREDICT BETTER
utt_0031 utt 194.05 206.03 -X POSITIONAL UNCERTAINTIES THAT REDUCE THE POSE ESTIMATION ERROR. AS THE PNEC FOCUSES ON OPTIMIZING THE ROTATION OF THE POSE, WE ONLY USE THE ROTATIONAL ERROR AS A TRAINING
utt_0033 utt 206.03 220.10 -X SIGNAL.\NTRAINING ON THE ROTATIONAL ERROR REQUIRES DATASETS WITH ACCURATE POSE INFORMATION TO COMPARE OUR ESTIMATED POSES AGAINST THE GROUND TRUTH DATA. OBTAINING SUCH DATASETS IS CHALLENGING
utt_0035 utt 220.10 232.13 -X AND SIGNIFICANTLY REDUCES THE AVAILABLE DATA FOR OUR TRAINING. TO ADDRESS THIS, WE PROPOSE AN ALTERNATIVE TRAINING STRATEGY THAT REPLACES THE TWO-FRAME POSE ERROR WITH THE CYCLE CONSISTENCY
utt_0037 utt 232.13 239.11 -X BETWEEN A TUPLE OF IMAGES TO APPROXIMATE THE POSE ERROR. THIS ENABLES OUR FRAMEWORK TO BE
utt_0038 utt 239.11 252.02 -X TRAINED FULLY SELF-SUPERVISED, WITHOUT THE NEED FOR GROUND TRUTH POSE INFORMATION.\N\NWE EVALUATE THE GRADIENT WE OBTAIN FROM IMPLICIT DIFFERENTIATION IN SYNTHETIC
utt_0040 utt 252.02 257.16 -X EXPERIMENTS TO DEMONSTRATE ITS CAPABILITY TO DERIVE MEANINGFUL COVARIANCE ESTIMATES.
utt_0041 utt 259.46 271.94 -X FOR THIS, WE SAMPLED INDIVIDUAL POSE ESTIMATION PROBLEMS USING A KNOWN NOISE DISTRIBUTION FOR KEYPOINTS IN AN IMAGE PLANE. STARTING FROM AN ESTIMATE OF UNIFORM NOISE DISTRIBUTION,
utt_0043 utt 271.94 275.78 -X WE UPDATE OUR NOISE ESTIMATES DIRECTLY USING THE GRADIENT.
utt_0044 utt 276.23 288.93 -X THE EXPERIMENTS SHOW THAT FOLLOWING THIS GRADIENT LEADS TO A LOWER POSE ESTIMATION ERROR AND CORRECTLY IDENTIFIED NOISE DISTRIBUTIONS IN THE IMAGE PLANE. FOR MORE DETAILS, PLEASE REFER
utt_0046 utt 288.93 303.02 -X TO THE PAPER AND THE SUPPLEMENTARY MATERIAL EXPLAINING THE NEED FOR DIVERSE DATA.\N\NOUR WHOLE FRAMEWORK IS EVALUATED ON REAL-WORLD DATA.
utt_0048 utt 303.49 315.14 -X WE TRAIN NETWORKS ON THE KITTI DATASET TO PREDICT KEYPOINT POSITIONAL UNCERTAINTY FOR SUPERPOINT AND A KLT-TRACKER AS KEYPOINT DETECTORS REPRESENTING LEARNED AND CLASSICAL APPROACHES.
utt_0050 utt 315.59 321.96 -X FOR BOTH DETECTORS, WE EVALUATE OUR SUPERVISED AND SELF-SUPERVISED TRAINING STRATEGIES.
utt_0051 utt 322.15 329.00 -X ALL NETWORKS ARE TRAINED ON SEQUENCES zerominus seven OF THE KITTI DATASET AND EVALUATED ON SEQUENCES eightminus ten.
utt_0052 utt 330.34 342.33 -X AS A NETWORK ARCHITECTURE, WE CHOSE A UNET AS IT ALLOWS US TO INCORPORATE HIGH- AND LOW-LEVEL INFORMATION. WE COMPARE OUR PREDICTED COVARIANCES TO BOTH NON-PROBABILISTIC POSE-ESTIMATION
utt_0054 utt 342.33 347.21 -X ALGORITHMS AND THE PNEC WITH DIFFERENT UNCERTAINTY ESTIMATES FROM THE LITERATURE.
utt_0056 utt 350.60 355.82 -1.9681 ESTIMATION FOR SUPERPOINT, SO WE USE THE SUPERGLUE MATCHING CONFIDENCE AS A STAND-IN
