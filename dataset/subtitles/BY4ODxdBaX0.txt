utt_0000 utt 0.21 12.72 -X HI! I AM JAEWOOK LEE, AND TODAY, I WILL BE PRESENTING OUR WORK ON HOW DIFFERENT IMAGE EXPLORATION MODALITIES DESIGNED FOR BLIND OR VISUALLY IMPAIRED INDIVIDUALS CAN ENCOURAGE SKEPTICISM TOWARDS IMPERFECT AI-GENERATED IMAGE CAPTIONS.
utt_0003 utt 12.72 17.65 -X THIS WORK WAS DONE IN COLLABORATION WITH JAYLIN HERSKOVITZ, YI-HAO PENG, AND ANHONG GUO.
utt_0004 utt 18.57 23.79 -X TRADITIONALLY, BLIND OR VISUALLY IMPAIRED INDIVIDUALS RELY ON ALTERNATIVE TEXT, OR ALT-TEXT,
utt_0005 utt 23.79 26.71 -X TO UNDERSTAND THE CONTENTS OF AN IMAGE.
utt_0006 utt 26.71 30.99 -X HOWEVER, ALT-TEXT IS OFTEN MISSING, LEAVING MANY IMAGES INACCESSIBLE.
utt_0007 utt 31.34 37.84 -X AUTO-GENERATING ALT-TEXT IS A SCALABLE ALTERNATIVE, BUT AI-GENERATED CAPTIONS CAN BE INCORRECT OR INCOMPLETE.
utt_0009 utt 38.42 47.35 -X EVEN IF THE AUTO-GENERATED CAPTIONS ARE INACCURATE, WITHOUT THE MEANS TO VERIFY CORRECTNESS, BLIND OR VISUALLY IMPAIRED INDIVIDUALS PLACE A HIGH DEGREE OF TRUST IN THEM.
utt_0011 utt 48.46 63.43 -X IMAGE EXPLORATION SYSTEMS ATTEMPT TO RESOLVE THIS PROBLEM BY PROVIDING ADDITIONAL INFORMATION ABOUT AN IMAGE BEYOND A SINGLE CAPTION. IN THIS WORK, WE AIM TO UNDERSTAND WHICH IMAGE EXPLORATION MODALITIES COULD BEST SUPPORT BVI PEOPLE IN IDENTIFYING ERRORS IN AUTO-GENERATED
utt_0014 utt 63.43 64.15 -X IMAGE CAPTIONS.
utt_0015 utt 64.95 68.53 -X TO ACHIEVE THIS, WE COMPARED THREE IMAGE EXPLORATION SYSTEMS:
utt_0016 utt 68.75 72.76 -X FACEBOOK’S AUTOMATIC ALT TEXT MICROSOFT’S SEEING AI
utt_0017 utt 73.43 79.93 -X AND OUR IMAGEEXPLORER. IN THE NEXT FEW SLIDES, WE SHOWCASE HOW EACH OF THE THREE SYSTEMS WORK IN GREATER DETAIL.
utt_0019 utt 80.63 95.13 -X FIRST IS FACEBOOK’S AUTOMATIC ALT TEXT FEATURE, WHICH PROVIDES DETAILS ABOUT AN IMAGE AS A LIST OF TEXT THAT USERS CAN SWIPE THROUGH. INFORMATION IS DIVIDED INTO SEVERAL CATEGORIES INCLUDING POSITION INFORMATION, SIZE INFORMATION, AND ELEMENTS BY CATEGORY.
utt_0022 utt 95.22 100.73 -X 'POSITION INFORMATION, HEADING' 'ON THE LEFT, ONE PERSON. IN THE CENTER, ONE
utt_0023 utt 101.01 103.16 -X PERSON.' 'SIZE INFORMATION, HEADING'
utt_0024 utt 103.16 107.26 -X 'MINOR ELEMENTS, TWO PEOPLE.'
utt_0025 utt 107.26 114.52 -X SECOND IS MICROSOFT’S SEEING AI, WHICH PROVIDES A TOUCH-BASED INTERFACE, ENABLING USERS TO EXPLORE BY DRAGGING THEIR FINGERS ACROSS THE SCREEN.
utt_0027 utt 114.52 118.59 -X 'TWO ITEMS DETECTED. MOVE YOUR FINGER OVER THE SCREEN TO EXPLORE.'
utt_0028 utt 120.95 126.36 -X SEEING AI WILL PLAY A MELODY IF THEIR FINGERS DO NOT INTERSECT WITH ANY ELEMENTS OF INTEREST.
utt_0029 utt 126.45 132.35 -X WHEN THEY INTERSECT, SEEING AI WILL PLAY A “DING” AND VOCALIZE A DESCRIPTION OF THE INTERSECTED ELEMENT.
utt_0031 utt 132.35 138.46 -X 'CAT. CAT. DINING TABLE. CAT. DINING TABLE. CAT'
utt_0032 utt 145.11 150.40 -X THIRD IS IMAGEEXPLORER, OUR DESIGN PROBE THAT PROVIDES A MULTI-LAYERED TOUCH-BASED INTERFACE.
utt_0033 utt 150.40 155.90 -X IMAGEEXPLORER BEGINS BY VOCALIZING THE AUTO-GENERATED CAPTION AND THE NUMBER OF ELEMENTS IN THE IMAGE.
utt_0035 utt 155.93 161.31 -X 'PLEASE VIEW IN PORTRAIT. A BLACK BOX ON A TABLE. THERE ARE FOUR MAIN OBJECTS AVAILABLE.
utt_0036 utt 161.31 162.65 -X TOUCH TO EXPLORE.'
utt_0037 utt 163.45 174.40 -X USERS CAN TOUCH TO EXPLORE. WHEN USERS’ FINGERS INTERSECT WITH AN ELEMENT, IMAGEEXPLORER WILL FIRST VOCALIZE A DESCRIPTION OF THE INTERSECTED ELEMENT, SIMILAR TO SEEING AI. IF THE ELEMENT
utt_0039 utt 174.40 179.36 -X CONTAINS ADDITIONAL INFORMATION IN THE NEXT LAYER, IMAGEEXPLORER WILL SAY “DOUBLE TAP TO EXPLORE”.
utt_0041 utt 182.52 188.35 -X 'DINING TABLE, DOUBLE TAP TO EXPLORE. BOOK, DOUBLE TAP TO EXPLORE.'
utt_0042 utt 189.88 199.17 -X WHEN THIS USER DOUBLE TAPS ON “BOOK,” A FIRST LAYER ELEMENT, IMAGEEXPLORER REVEALS ITS SECOND LAYER ELEMENTS SUCH AS TEXT AND DRAWINGS.
utt_0044 utt 199.17 204.77 -X 'VIEWING BOOK twelve SUB-OBJECTS AVAILABLE. TOUCH TO EXPLORE. DOUBLE TAP ANYWHERE TO EXIT'
utt_0045 utt 206.49 215.30 -X 'MILK AND HONEY RUPI KAUR NEW YORK TIMES BESTSELLER. THE LOGO ON THE SHIRT. MILK. RUPI. HONEY.
utt_0046 utt 215.30 224.13 -X HONEY. MILK. AND. THE SHIRT IS WHITE. MILK AND HONEY RUPI KAUR NEW YORK TIMES BESTSELLER.'
utt_0047 utt 225.06 236.58 -X ONCE USERS ARE DONE EXPLORING AN ELEMENT IN MORE DETAIL, THEY CAN DOUBLE TAP ANYWHERE ON THE SCREEN TO RETURN TO THE FIRST LAYER. IMAGEEXPLORER WILL VOCALIZE THE NUMBER OF ELEMENTS THAT HAVE YET TO BE EXPLORED.
utt_0050 utt 236.70 239.78 -X 'GOING BACK TO THE WHOLE IMAGE THREE OBJECTS REMAINING.'
utt_0051 utt 241.82 251.59 -X TO IMPLEMENT IMAGEEXPLORER, WE USED THE MASK R-CNN MODEL FOR THE FIRST LAYER BECAUSE IT CAN GENERATE POLYGONAL BOUNDARIES. WE ALSO USED GOOGLE CLOUD VISION’S OBJECT, FACE,
utt_0053 utt 251.59 257.57 -X AND TEXT DETECTION AND LABELING MODELS AS WELL AS THE DENSECAP MODEL TO GENERATE A DETAIL-RICH SECOND LAYER.
utt_0055 utt 258.69 269.06 -X PARTICIPANTS WERE ASKED TO USE THE THREE SYSTEMS TO EXPLORE NINE IMAGES OF THREE DIFFERENT CAPTION QUALITIES. CAPTION QUALITY WAS DECIDED BASED ON DETAILEDNESS AND CORRECTNESS OF THE CAPTION.
utt_0058 utt 269.73 273.61 -X CAPTION QUALITY A REFERS TO CAPTIONS THAT ARE MOSTLY ACCURATE,
utt_0059 utt 274.47 280.55 -X B REFERS TO CAPTIONS THAT ARE PARTIALLY INACCURATE, AND C REFERS TO CAPTIONS THAT ARE INACCURATE.
utt_0061 utt 281.83 291.37 -X FROM OUR STUDY, WE OBSERVED THAT PARTICIPANTS WERE INITIALLY UNSUCCESSFUL IN DETERMINING WHICH CAPTIONS WERE ACCURATE AND WHICH WERE NOT PRIOR TO EXPLORING THE CORRESPONDING IMAGES.
utt_0063 utt 292.42 307.11 -X OVERALL, IMAGE EXPLORATION SYSTEMS WERE SUCCESSFUL IN ENCOURAGING SKEPTICISM TOWARDS IMPERFECT CAPTIONS. THIS IS SHOWN BY HOW PARTICIPANTS’ SCORES FOR IMAGES WITH LOWER QUALITY CAPTIONS DECREASED WHILE SCORES FOR IMAGES WITH HIGHER QUALITY CAPTIONS DID NOT SIGNIFICANTLY CHANGE.
utt_0066 utt 307.65 318.00 -X FOR IMAGE QUALITY A, ALTHOUGH PARTICIPANTS’ AVERAGE RATING DECREASED, THIS CHANGE WAS NOT SIGNIFICANT. ADDITIONALLY, EVEN WITH A SLIGHT DECREASE IN AVERAGE RATING POST-EXPLORATIONS,
utt_0068 utt 318.00 320.65 -X IT STILL REMAINED IN THE SLIGHTLY ACCURATE RANGE.
utt_0069 utt 321.32 333.00 -X FOR CAPTIONS OF IMAGE QUALITIES B AND C, THE AVERAGE RATINGS DECREASED SIGNIFICANTLY, WHICH SUGGESTS THAT PARTICIPANTS WERE ABLE TO CORRECTLY JUDGE THAT THOSE CAPTIONS WERE INACCURATE POST-EXPLORATIONS.
utt_0072 utt 334.09 345.20 -X AFTER EXPLORING AN IMAGE, PARTICIPANTS RELIED HEAVILY ON INFORMATION THEY GATHERED WHEN JUDGING CAPTION ACCURACY. FOR EXAMPLE, FOR IMAGE threeB, A CAT SITTING ON A CHAIR, SOME PARTICIPANTS
utt_0074 utt 345.20 359.95 -X WERE ABLE TO FIGURE OUT THAT THE CAT IS ON TOP OF A DINING TABLE AND NEXT TO TWO CHAIRS WHEN EXPLORING USING THE TWO TOUCH-BASED SYSTEMS. THEY DECREASED THEIR SCORES BECAUSE TOUCH EMPOWERED THEM TO UNDERSTAND THE SPATIAL RELATIONSHIP BETWEEN THE CAT, THE CHAIRS, AND THE DINING
utt_0077 utt 359.95 360.27 -X TABLE.
utt_0078 utt 362.06 374.29 -X ALTHOUGH ALL IMAGE EXPLORATION MODALITIES WERE SUCCESSFUL IN ENCOURAGING SKEPTICISM TOWARDS IMPERFECT CAPTIONS, IMAGEEXPLORER ELICITED THE MOST CORRECT EXPLANATIONS ACROSS ALL CAPTION QUALITIES DUE TO GREATER AMOUNT OF DETAIL.
