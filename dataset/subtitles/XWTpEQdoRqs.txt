utt_0000 utt 0.03 2.51 -X HI, THIS IS CHEN FROM UNIVERSITY OF MARYLAND.
utt_0001 utt 2.73 12.02 -X TODAY I’M GOING TO PRESENT OUR PAPER, DISTANTLY SUPERVISED EVIDENCE RETRIEVAL ENABLES QUESTION ANSWERING WITHOUT EVIDENCE ANNOTATION.
utt_0003 utt 12.02 15.02 -X THIS IS JOINT WORK WITH CHENYAN, JORDAN AND HAL.
utt_0004 utt 15.02 20.37 -X QUESTION ANSWERING HAS SIGNIFICANT ATTENTION IN BOTH RESEARCH COMMUNITIES AND INDUSTRIES.
utt_0005 utt 20.91 29.49 -X GIVEN AN INPUT QUESTION ``WHICH CITY IS FACEBOOK LOCATED``, CURRENT COMMERCIAL SEARCH ENGINES CAN DIRECTLY PREDICT THE CORRECT ANSWER, ``MENLO PARK``.
utt_0007 utt 29.49 34.90 -X ALSO THERE ARE SEVERAL HIGH QUALITY BENCHMARKS FOR INNOVATIVE MODELS, SUCH AS SQUAD, MS MARCO AND NATURAL QUESTIONS.
utt_0009 utt 34.90 40.79 -X SUCH A PROBLEM IS OFTEN CALLED OPEN-DOMAIN QUESTION ANSWERING, IN WHICH WE NEED TO FIND EVIDENCE FROM A LARGE CORPUS SUCH AS WIKIPEDIA AND FIND AN ANSWER.
utt_0011 utt 40.79 47.60 -X MOST CURRENT SYSTEMS HAVE TWO STEPS: A RETRIEVAL STEP THAT FINDS SOME RELEVANT EVIDENCE (USUALLY PASSAGES), AND A READING COMPREHENSION STEP THAT PREDICTS AN ANSWER FROM THE EVIDENCE.
utt_0014 utt 51.54 66.23 -X COMPLEX QUESTIONS LIKE MULTI-HOP QUESTIONS, AS SHOWN IN THIS EXAMPLE, WE NEED TO CHAINING TWO EVIDENCE PIECES ``FACEBOOK WAS LAUNCHED IN HARVARD UNIVERSITY`` AND ``HARVARD UNIVERSITY IS IN CAMBRIDGE`` TO FIND THE ANSWER.
utt_0017 utt 66.23 68.50 -X SEARCH ENGINES OFTEN FAIL TO ANSWER THEM.
utt_0018 utt 68.50 79.31 -X USING THE SAME FRAMEWORK, BUT RETRIEVING MULTIPLE EVIDENCE INSTEAD, STATE OF THE ART SYSTEMS ACHIEVE GREAT RESULTS ON BENCHMARK DATASET, HOTPOTQA.
utt_0020 utt 79.37 83.12 -X HOWEVER, ANSWERING MULTI-HOP QUESTIONS IS STILL DIFFICULT.
utt_0021 utt 83.12 85.75 -X LET’S TAKE A LOOK AT AN EXAMPLE.
utt_0022 utt 85.77 90.90 -X THE CORRECT EVIDENCE (RELEVANT SENTENCES IN FACEBOOK AND HARVARD UNIVERSITY WIKIPEDIA
utt_0023 utt 90.99 100.60 -X PAGE) IS GIVEN DURING TRAINING, WHICH IS HELPFUL FOR TRAINING NEURAL RETRIEVAL SYSTEMS, A KEY COMPONENT IN OPEN DOMAIN QA SYSTEMS.
utt_0025 utt 100.60 103.54 -X BUT THESE ANNOTATIONS ARE EXPENSIVE.
utt_0026 utt 103.54 109.52 -X FOR ANOTHER SINGLE-HOP QA DATASET, NATURAL QUESTIONS, BESIDES LABELING THE EVIDENCE PASSAGES,
utt_0027 utt 109.52 113.14 -X ADDITIONAL ANNOTATORS VERIFY THE CORRECTNESS OF THE LABELS.
utt_0028 utt 113.14 116.79 -X THE SITUATION IS EVEN MORE NUANCED FOR MULTI-HOP QUESTIONS.
utt_0029 utt 116.79 128.79 -X TO CONSTRUCT HOTPOTQA, TO MAKE SURE THERE ARE MULTIPLE PIECES OF EVIDENCE, THE LINKED WIKIPEDIA PASSAGES ARE PRE-GIVEN, AND ANNOTATORS WRITE QUESTIONS THAT USE BOTH PASSAGES.
utt_0031 utt 129.58 133.65 -X OBVIOUSLY THIS IS NOT THE MOST NATURAL WAY TO CREATE QUESTIONS!
utt_0032 utt 133.65 135.44 -X BUT WHAT ARE YOU GOING TO DO?
utt_0033 utt 135.44 137.56 -X YOU NEED THIS INTERMEDIATE DATA, RIGHT?
utt_0034 utt 137.56 141.11 -X EVEN THOUGH PREVIOUS WORK HAS FOUND ARTIFACTS IN THE DATASET.
utt_0035 utt 141.39 148.21 -X SO TO MITIGATE THESE ISSUES, OUR WORK FOCUSES ON A MORE GENERAL BUT CHALLENGING WEAKLY SUPERVISED
utt_0036 utt 150.99 152.44 -X SETTING.
utt_0037 utt 155.31 162.68 -X WE TRAIN QA SYSTEMS THAT DON’T NEED INTERMEDIATE EVIDENCE ANNOTATIONS, THEY ONLY NEED A QUESTION,
utt_0038 utt 162.68 165.46 -X THE ANSWER AND IT FIGURES OUT THE REST!
utt_0039 utt 165.46 173.97 -X BUT TO EXPLAIN HOW OUR SYSTEM WORKS, WE FIRST NEED TO TALK ABOUT HOW “NORMAL” OPEN DOMAIN QA WORKS FOR FULLY SUPERVISED MULTIHOP QUESTIONS.
utt_0041 utt 173.97 177.81 -X THEN WE INTRODUCE OUR METHOD, WHICH WE CALL, DISTDR FOR SHORT.
utt_0042 utt 178.51 185.65 -X MOST CURRENT OPEN-DOMAIN QA SYSTEMS USE DENSE PASSAGE RETRIEVAL AS THE RETRIEVER COMPONENT:
utt_0043 utt 185.65 191.06 -X GIVEN A QUESTION, BERT ENCODES THE QUESTION AND PUTS IT INTO A LATENT SPACE.
utt_0044 utt 191.06 195.03 -X ANOTHER BERT ENCODER CAN TAKE EVIDENCE PASSAGES AND EMBED THEM IN THE LATENT SPACE.
utt_0045 utt 195.03 200.79 -X FINDING EVIDENCE REQUIRES US TO TAKE THE SIMILARITY FUNCTION BETWEEN THE QUESTION EMBEDDING AND
utt_0046 utt 204.75 207.41 -X THE PASSAGE EMBEDDINGS AND TAKE THE CLOSEST ONE.
utt_0047 utt 207.41 212.92 -X UNLIKE FIXED REPRESENTATIONS, THESE TRAINABLE ENCODERS GIVE US A LOT OF FLEXIBILITY: WHICH
utt_0049 utt 215.41 225.37 -X FOR MULTI-HOP QUESTIONS, INSTEAD OF JUST LOOKING FOR EVIDENCE ONCE AS IN NORMAL QA, WE TAKE MULTIPLE DENSE RETRIEVAL STEPS FOR CHAINING MULTIPLE EVIDENCE PIECES.
utt_0051 utt 225.68 237.75 -X AFTER EACH RETRIEVAL STEP, WE COMBINE THE QUESTION AND ALREADY RETRIEVED EVIDENCE INTO A REFORMULATED QUERY, BY APPENDING THE RETRIEVED PASSAGE TOKENS TO THE QUESTION.
utt_0053 utt 237.88 249.82 -X OUR READER IS A BERT READING COMPREHENSION MODEL, THE INPUT IS A CONCATENATION OF QUESTION AND EVIDENCE (WHICH IS A SINGLE PASSAGE FOR SIMPLE QUESTIONS, OR A CHAIN OF PASSAGE FOR
utt_0055 utt 249.91 251.48 -X MULTI-HOP QUESTIONS).
utt_0056 utt 252.02 256.44 -X AND IT OUTPUTS A START AND END SPAN AS THE FINAL ANSWER.
utt_0057 utt 256.44 259.51 -X NOW LET’S DESCRIBE OUR PROPOSED METHOD, DISTDR.
utt_0058 utt 259.67 265.56 -X THIS IS A WEAKLY SUPERVISED SETTING: WE ONLY GET QUESTIONS AND ANSWERS DURING TRAINING.
utt_0059 utt 265.56 267.54 -X BUT WE STILL NEED EVIDENCE SOMEHOW!
utt_0060 utt 267.54 271.90 -X TO KNOW WHICH EVIDENCE WORKS, WE USE DISTANT SUPERVISION.
utt_0061 utt 271.90 285.08 -X WE USE A RETRIEVER TO SCORE RELEVANT EVIDENCE FOR EACH TRAINING QUESTION, OUR INTUITION IS THAT HIGHLY SCORED EVIDENCE BY THE RETRIEVER THAT CONTAINS THE ANSWER IS THE POSITIVE ONES.THIS
utt_0063 utt 285.08 293.75 -X IS BECAUSE WE HOPE RETRIEVERS, ALTHOUGH NOT PERFECT, COULD FIND SOME EVIDENCE THAT ARE SEMANTICALLY SIMILAR TO THE QUESTION.
utt_0065 utt 293.75 300.44 -X WE ALSO TAKE INSPIRATION FROM PREVIOUS WEAKLY SUPERVISED QA FOR SIMPLE QUESTIONS, FOR EXAMPLE
utt_0066 utt 300.95 306.27 -X FINDING A SINGLE PASSAGE FOR EACH QUESTION TO CONSTRUCT TRIVIAQA DATASET.
utt_0067 utt 307.25 314.59 -X THEY USE BMtwenty-five TO FIND TOP-K (K IS USUALLY BIG) PASSAGES AND MATCH THEM USING THE ANSWER.
utt_0068 utt 316.02 321.18 -X HOWEVER, THAT DOES NOT WORK WELL FOR MULTI-HOP QUESTIONS.
utt_0069 utt 321.18 326.71 -X THIS IS BECAUSE WE CANNOT USE TERM MATCHING TO FIND A CHAIN OF EVIDENCE PIECES.
utt_0070 utt 328.37 341.18 -X FOR EXAMPLE, ONE EVIDENCE PIECE IN THE CHAIN `` HARVARD UNIVERSITY IS IN CAMBRIDGE`` HAS NO TEXTUAL OVERLAP TO QUESTION ``WHICH CITY WAS FACEBOOK LAUNCHED``.
utt_0072 utt 344.73 355.04 -X A NATURAL CHOICE IS TO USE A DENSE RETRIEVAL MODEL, WHICH DOES NOT ONLY LOOK AT TEXTUAL OVERLAPS, BUT IT REQUIRES TRAINING LABELS, AND IS NOT AVAILABLE IN OUR SETTING.
utt_0074 utt 355.04 358.78 -X SO HERE WE USE DENSE RETRIEVAL, BUT TAKE A DIFFERENT APPROACH.
utt_0075 utt 359.48 364.89 -X WE ASSUME THAT WHICH EVIDENCE IS RELEVANT IS A LATENT VARIABLE WE NEED TO INFER.
utt_0076 utt 365.11 375.71 -X TO INFER THAT VARIABLE, WE USE EXPECTATION MAXIMIZATION: WE ALTERNATE BETWEEN GUESSING WHICH EVIDENCE IS GOOD AND LEARNING NEW RETRIEVERS.
utt_0078 utt 375.71 383.23 -X BUT WE NEED TO START SOMEWHERE, SO WE START WITH AN EVIDENCE FINDER TRAINED NOT ON MULTIHOP QA BUT RATHER ON OTHER DATASETS.
utt_0080 utt 385.05 388.67 -X THEN THE PROCESS OF ITERATIVE IMPROVEMENT CAN BEGIN.
utt_0081 utt 388.67 394.33 -X AT EACH E-STEP, WE USE THE CURRENT DENSE RETRIEVER TO GET A BUNCH OF EVIDENCE FROM WIKIPEDIA.
utt_0082 utt 396.31 400.32 -X THERE ARE OVER fiveM PAGES, SO WE CAN ONLY WORK WITH A SUBSET.
utt_0083 utt 400.60 408.06 -X WE GUESS AT THE GOOD AND BAD EVIDENCE (MORE ON THIS IN A SECOND), WHICH WE CALL HARD-E STEP.
utt_0085 utt 408.06 414.72 -X THEN AT M STEP, WE UPDATE THE MODEL, ASSUMING THE EVIDENCE FROM E-STEP IS THE CORRECT SOLUTION.
utt_0086 utt 414.72 426.05 -X AS SHOWN IN THIS FIGURE, WE HOPE AT EACH ITERATION, WE COULD CLOSE THE RELATIVELY DISTANCE BETWEEN QUESTION AND POSITIVE EVIDENCE IN THE LOW-DIMENSION SPACE, WHICH ENDS UP WITH RETRIEVING BETTER
utt_0088 utt 426.07 427.01 -X EVIDENCE.
utt_0089 utt 427.32 431.10 -X AND THE BETTER EVIDENCE COULD FURTHER IMPROVE THE MODEL.
utt_0090 utt 431.10 436.99 -X OK, GO THROUGH OUR DISTDR WITH AN EXAMPLE FROM THE HOTPOTQA DATASET SO I CAN EXPLAIN
utt_0091 utt 437.05 440.51 -X HOW WE CAN SEPARATE GOOD EVIDENCE FROM BAD EVIDENCE.
utt_0092 utt 440.51 444.48 -X THE QUESTION IS ``WHAT STATE DOES SANG-WOOK CHEONG WORK AS A MATERIAL SCIENTIST?``
utt_0093 utt 444.48 456.57 -X AND TO FIND THE ANSWER ``NEW JERSEY``, WE NEED CHAINING TWO EVIDENCE PIECES, ``SANG-WOOK CHEONG IS A MATERIAL SCIENTIST AT RUTGERS UNIVERSITY`` AND ``RUTGERS UNIVERSITY IS IN NEW JERSEY``.
utt_0096 utt 457.18 461.28 -X AT E-STEP, OUR GOAL IS TO COMPUTE THE MOST LIKELY EVIDENCE.
utt_0097 utt 461.72 473.54 -X WE FIRST USE DENSE RETRIEVER TO FIND TOP - K EVIDENCE, WHICH IS A SINGLE PASSAGE FOR SIMPLE QUESTIONS, AND A CHAIN (WITH TWO EVIDENCE PIECES) FOR MULTI-HOP QUESTIONS.
utt_0099 utt 473.54 479.36 -X THEN WE SPLIT THEM INTO POSITIVE AND NEGATIVE EVIDENCE BASED ON WHETHER IT CONTAINS THE ANSWER.
utt_0101 utt 479.39 486.82 -X THIS IS GOOD, BUT THERE’S PROBLEM, USING JUST ANSWER MATCHING COULD FIND SOME SPURIOUS EVIDENCE.
utt_0103 utt 486.82 494.59 -X FOR EXAMPLE, THE FOUNDATION OF WAYNE ALSO HAS THE ANSWER ``NEW JERSEY``, BUT IS NOT THE CORRECT EVIDENCE.
utt_0105 utt 494.59 500.00 -X TO MITIGATE THIS ISSUE, WE USE READER TO FILTER OUT THEM.
utt_0106 utt 500.35 508.90 -X SPECIFICALLY WE USE READER TO PREDICT AN ANSWER FOR EACH POSITIVE CANDIDATE EVIDENCE, AND ONLY KEEP THEM WHERE READER MAKES A CORRECT PREDICTION.
utt_0108 utt 508.90 515.36 -X THEN AT M-STEP, WE UPDATE THE QA SYSTEM USING THE QUESTION, ANSWER AND RETRIEVED EVIDENCE,
utt_0109 utt 515.36 518.94 -X INCLUDING BOTH RETRIEVER UPDATE AND READER UPDATE.
utt_0110 utt 519.45 527.14 -X WE EVALUATE DISTDR ON TWO BENCHMARKS: HOTPOTQA, A MULTI-HOP QA BENCHMARK, AND NATURAL QUESTIONS,
utt_0111 utt 527.14 529.22 -X A SIMPLE QA BENCHMARK.
utt_0112 utt 530.27 537.03 -X ON HOTPOTQA, OUR DISTDR IS SLIGHTLY BETTER THAN BEAMDR, USING THE SAME MODEL ARCHITECTURE,
utt_0113 utt 537.09 539.14 -X ON THE FULLY SUPERVISED SETTING.
utt_0114 utt 539.65 546.34 -X ON NATURALQUESTIONS, DISTDR IS ALSO COMPETITIVE TO FULLY-SUPERVISED DENSE RETRIEVAL METHODS,
utt_0115 utt 546.34 546.91 -X ANCE.
utt_0116 utt 547.20 558.08 -X SO THE TAKEAWAY IS WITH OUR DISTDR APPROACH, WE NO LONGER NEED EVIDENCE LABELS TO GET ON PAR PERFORMANCE, WITH VARIABLE TYPES OF QUESTIONS.
utt_0118 utt 558.08 559.52 -X WE LEAVE FULL RESULTS IN OUR PAPER.
utt_0119 utt 559.52 564.07 -X WE FURTHER CONDUCT ANALYSIS TO STUDY THE MODEL BEHAVIOR USING HOTPOTQA AS THE EXAMPLE.
utt_0120 utt 564.07 568.61 -X FIRST, THIS FIGURE SHOWS THE TRAINING DATA STATISTICS OVER ITERATIONS.
utt_0121 utt 568.61 573.22 -X WE CAN SEE THAT THE NUMBER OF EXAMPLES INCREASES OVER ITERATIONS, AND THE PERCENTAGE OF EVIDENCE
utt_0122 utt 573.79 576.71 -X THAT MATCHES THE GOLD ALSO INCREASES OVER ITERATIONS.
utt_0123 utt 576.77 580.80 -X IT IMPLIES THE RETRIEVER INCREASINGLY FINDS MORE ACCURATE EVIDENCE.
utt_0124 utt 580.80 588.07 -X NEXT WE CONDUCT AN ABLATION STUDY ON FILTERING METHODS, WE CAN SEE USING ANSWER FILTER IS NECESSARY, AND ADDITIONAL READER FILTER COULD FURTHER HELP, ALSO CONVERGES FASTER.
utt_0126 utt 588.07 593.00 -X ALTHOUGH DISTDR IS ON PAR WITH FULLY-SUPERVISED METHODS ONLY seventy% OF RETRIEVED EVIDENCE MATCHES THE GOLD.
utt_0128 utt 593.50 594.98 -X SO WHAT’S GOING ON THERE?
utt_0129 utt 594.98 603.20 -X TO FIND OUT, WE MANUALLY ANNOTATE fifty EXAMPLES WHERE EXTRACTED EVIDENCE DOES NOT MATCH THE GOLD.
utt_0131 utt 603.84 617.19 -X THIRTY EIGHT PERCENT OF THE QUESTIONS ARE ANSWERABLE VIA SINGLE EVIDENCE (SO THEY WEREN’T REALLY MULTIHOP), FROM THIS EXAMPLE, THE FIRST EVIDENCE ALREADY ANSWERS THE QUESTION, EVEN
utt_0133 utt 617.60 624.23 -X IF DISTDR FINDS THE INCORRECT SECOND EVIDENCE, IT ALREADY GETS THE MOST IMPORTANT SIGNAL.
utt_0134 utt 624.64 631.14 -X IN TWENTY EIGHT PERCENT OF THE QUESTIONS, DISTDR FINDS ALTERNATE CORRECT EVIDENCE.
utt_0135 utt 631.14 636.48 -X IN THIS EXAMPLE, EITHER OF THE MOVIES ``THE MIST`` AND ``THE GREEN MILE`` IS CORRECT AS
utt_0136 utt 636.64 641.06 -X THE FIRST EVIDENCE, AND DISTDR FINDS ANOTHER ONE, WHICH IS ALSO GOOD.
utt_0137 utt 641.63 647.01 -X AND LAST THIRTY FOUR PERCENT, THE EVIDENCE IS INCORRECT.
utt_0138 utt 647.01 659.85 -X IN THIS EXAMPLE, THE EVIDENCE IS INCORRECT, BUT AS WE CAN SEE, THERE’S ONLY ONE CANDIDATE THAT IS A COUNTY, SO THE READER MAKES THE CORRECT PREDICTION, BUT FOR THE WRONG REASON.
utt_0140 utt 660.16 665.06 -X HAVE A FAITHFUL SYSTEM IS AN IMPORTANT ONGOING RESEARCH DIRECTION.
utt_0141 utt 665.06 672.26 -X TO SUMMARIZE, WE PROPOSE DISTDR, A DENSE RETRIEVAL SYSTEM UNDER WEAK SUPERVISION.
utt_0142 utt 672.26 679.21 -X DISTDR ITERATIVELY FINDS MORE ACCURATE EVIDENCE, AND FURTHER ENCOURAGES THE MODEL TO THIS EVIDENCE.
utt_0143 utt 679.21 685.96 -X DISTDR IS ON-PAR WITH FULLY SUPERVISED COUNTERPARTS, WITHOUT USING ANY INTERMEDIATE ANNOTATIONS.
utt_0144 utt 685.96 698.69 -X FURTHER WORK COULD FOCUS ON MORE FAITHFUL QA SYSTEMS THAT MAKE CORRECT PREDICTION FOR THE RIGHT REASONS, AND ALSO OTHER TYPES OF COMPLEX QUESTIONS THAT DO NOT COME WITH EVIDENCE
utt_0146 utt 698.69 701.93 -4.7055 LABELS, E.G., QUESTIONS THAT NEED NUMERICAL REASONING.
