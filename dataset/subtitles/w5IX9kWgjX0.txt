utt_0000 utt 0.08 7.82 -X HELLO, I AM GOING TO PRESENT OUR WORK ON WALT: WATCH AND LEARN twoD AMODAL REPRESENTATION USING TIME-LAPSE IMAGERY.
utt_0002 utt 7.82 12.98 -X THIS PAPER IS A JOINT EFFORT BETWEEN MY SELF DINESH, ROBERT AND SRINIVAS AT CARNEGIE MELLON.
utt_0003 utt 13.80 22.07 -X THE GOAL OF THE PAPER IS TO LEARN AMODAL REPRESENTATION I.E. DETECTING AND SEGMENTING BOTH THE VISIBLE AND THE OCCLUDED REGIONS OF AN OBJECT.
utt_0005 utt 22.29 29.17 -X THIS REPRESENTATION WILL HELP IN TRACKING, RECONSTRUCTION AND OTHER DOWNSTREAM TASKS IN BUSY SCENES.
utt_0007 utt 30.22 34.74 -X ONE POSSIBILITY IS TO USE HUMAN ANNOTATIONS TO TRAIN THESE REPRESENTATIONS.
utt_0008 utt 34.74 42.10 -X BUT HUMAN ANNOTATORS PERFORM POORLY IN OCCLUDED REGIONS AS CAN BE SEEN FROM THE DISAGREEMENT BETWEEN MULTIPLE ANNOTATORS.
utt_0010 utt 42.25 46.48 -X THIS DISAGREEMENT INCREASE WITH INCREASE IN OCCLUSION PERCENTAGE.
utt_0011 utt 46.96 53.68 -X WE OBSERVE THIS ACROSS DIFFERENT REPRESENTATIONS .I.E. BOUNDING BOX AND INSTANCE SEGMENTATION.
utt_0012 utt 54.57 61.75 -X AND HUMAN ANNOTATIONS FOR AMODAL LEARNING IN CURRENT DATASETS LIKE COCO AND KITTI ARE VERY LIMITED.
utt_0014 utt 61.75 66.13 -X THUS, WE CANNOT LEARN ALL THE OCCLUSION CONFIGURATIONS OVER DIFFERENT OBJECT CATEGORIES.
utt_0015 utt 66.70 72.79 -X ON THE OTHER HAND MULTIPLE LARGE SYNTHETIC DATASETS HAVE BEEN PROPOSED TO TACKLE THE OCCLUSION PROBLEM.
utt_0017 utt 72.79 77.68 -X SUCH DATASETS CAN BE USED TO LEARN AMODAL REPRESENTATIONS FOR VIRTUAL ENVIRONMENTS,
utt_0018 utt 77.68 81.24 -X BUT DO NOT TRANSLATE WELL TO REAL DATA DUE TO DOMAIN GAP.
utt_0019 utt 82.00 94.00 -X IN THIS WORK WE PRESENT THE BEST OF BOTH THE REAL AND SYNTHETIC WORLDS FOR AUTOMATIC OCCLUSION SUPERVISION USING A LARGE READILY AVAILABLE SOURCE OF DATA: TIME-LAPSE IMAGERY.
utt_0021 utt 94.42 105.69 -X WE AUTOMATICALLY MINE UNOCCLUDED OBJECTS FROM THE TIME-LAPSE IMAGERY THAT CAN BE COMPOSITED BACK IN A REALISTIC WAY TO PROVIDE LARGE SCALE SUPERVISION FOR TRAINING.
utt_0023 utt 107.25 117.43 -X IN THE TIME-LAPSE STREAM, DETECTING UNOCCLUDED OBJECTS IS DISTINCTLY AN EASIER PROBLEM TO SOLVE COMPARED TO ANNOTATING OR DISTINGUISHING OBJECTS UNDER SEVERE OCCLUSIONS.
utt_0025 utt 118.42 121.30 -X GIVEN DETECTIONS OF EACH OBJECT IN THE IMAGE.
utt_0026 utt 121.30 126.10 -X WE COMPUTE THE INTERSECTION BETWEEN THE BOTTOM OF EACH BOUNDING BOX WITH OTHER BOUNDING BOXES.
utt_0027 utt 126.26 134.45 -X ASSUMING OBJECTS LIE ON A PLANE UNOCCLUDED OBJECTS ARE DETECTED USING A THRESHOLD ON THE OVERLAPPING REGION.
utt_0029 utt 134.45 138.39 -X THIS WAY WE AUTOMATICALLY DETECT A LARGE NUMBER OF UNOCCLUDED OBJECTS.
utt_0030 utt 138.45 143.80 -X ANY OF YOUR FAVOURITE PRETRAINED DETECTORS OR SEGMENTATION NETWORKS CAN BE USED HERE.
utt_0031 utt 145.84 152.92 -X WE USED SWIN BASED MASKRCNN WHICH HAD ACCURACY OF ninety PERCENT AND seventy-five PERCENT AP FOR UNOCCLUDED VEHCICLES AND PEOPLE RESPECTIVELY.
utt_0033 utt 154.80 158.81 -X WE SHOW RESULTS OF UNOCCLUDED OBJECT DETECTION OVER A TIME-LAPSE VIDEO.
utt_0034 utt 158.81 164.15 -X OBSERVE THAT OUR METHOD IS ABLE TO FIND UNOCCLUDED OBJECTS EVEN IN BUSY INTERSECTIONS.
utt_0035 utt 165.08 166.87 -X BEING PATIENT PAYS OFF HERE.
utt_0036 utt 166.87 173.14 -X OVER TIME, OUR METHOD DISCOVERS TENS OF THOUSANDS OF UNOCCLUDED OBJECTS AT DIVERSE POSITIONS,
utt_0037 utt 173.14 176.22 -X ORIENTATIONS AND APPEARANCES.
utt_0038 utt 176.95 182.07 -X THESE MINED UNOCCLUDED OBJECTS CAN BE COMPOSITED BACK INTO THE SCENE IN THE FOLLOWING WAY.
utt_0040 utt 183.19 187.48 -X WE COMPUTE THE BACKGROUND IMAGES FOR EACH HOUR OF DAY FROM THE TIME-LAPSE DATA.
utt_0041 utt 187.48 193.88 -X THEN UNOCCLUDED OBJECTS ARE COMPOSITED IN LAYERS BACK INTO THE BACKGROUND IMAGE.
utt_0042 utt 193.88 198.11 -X WE CALL THE RESULTING DATASET AS CLIP-ART WALT OR CWALT.
utt_0043 utt 201.08 205.98 -X DIVERSE OBJECTS ARE COMPOSITED BACK INTO THE IMAGE IN VARIOUS CONFIGURATIONS,
utt_0044 utt 205.98 209.79 -X SETTING THE STAGE TO LEARN AMODAL REPRESENTATION AUTOMATICALLY.
utt_0045 utt 210.10 215.99 -X HERE ARE EXAMPLES OF COMPOSITING FOR A VARIETY SCENES LIKE BOARDWALK, TRAFFIC INTERSECTIONS,
utt_0046 utt 215.99 218.76 -X SIDEWALKS AND BEACHES.
utt_0047 utt 218.76 225.76 -X THESE CWALT GENERATED IMAGES AND GROUNDTRUTH OCCLUSION CONFIGURATIONS ARE PASSED THROUGH A NETWORK TO LEARN AMODAL REPRESENTATIONS.
utt_0049 utt 225.76 229.02 -X GIVEN AN IMAGE AND GROUNDTRUTH FROM COMPOSITING.
utt_0050 utt 229.02 233.95 -X EVERY BOUNDING BOX CONTAINS THREE COMPONENTS .I.E THE OBJECT THAT NEEDS TO BE SEGMENTED,
utt_0051 utt 233.95 236.99 -X THE OCCLUDER AND THE OCCLUDED.
utt_0052 utt 237.11 241.85 -X DISENTAGLING THESE THREE OBJECTS PER BOUNDING BOX IMPROVES THE AMODAL REPRESENTATION.
utt_0053 utt 243.06 246.04 -X WE ILLUSTRATE THE PIPELINE TO LEARNTHESE THREE LAYERS.
utt_0054 utt 246.07 259.80 -X FIRST, SIMILAR TO MASKRCNN WE PASS THE ROI FEATURE FROM HRNETBACKBONE TO THE OCCLUDER NETWORK AND THEN THE OCCLUDED NETWORK.COMBINING THESE TWO REPRESENTATIONS WE PASS THE ADDED
utt_0056 utt 259.80 263.23 -X FEATURES THROUGH AN AMODALSEGMENTATION NETWORK.
utt_0057 utt 263.23 272.25 -X WE COMPUTE LOSS OF AMODAL SEGMENTATION AND BOUNDING BOX FOR EACHOF THE LAYERS INDIVIDUALLY USING THE GROUNDTRUTH OCCLUSION CONFIGURATIONS IN CWALT.
utt_0059 utt 272.86 277.85 -X WE COMPARE OUR METHOD TO OTHERNETWORKS TRAINED WITH THE SAME DATASETS.
utt_0060 utt 277.88 284.67 -X OBSERVE THAT OUR METHODIS ABLE TO PERFORM BETTER THAN PREVIOUS PROPOSED METHODS WITH INCREASING OCCLUSION PERCENTAGE.
utt_0062 utt 286.17 290.30 -X HERE ARE SOME SEGMENTATION RESULTSON PEOPLE WALKING ON A BOARDWALK.
utt_0063 utt 290.30 295.55 -X OBSERVE THE ACCURATE AMODALSEGMENTATION OF PEOPLE EVEN UNDER SEVERE OCCLUSIONS.
utt_0064 utt 295.55 301.89 -X THE PREDICTION ARECOMPUTED PER FRAME AND NO TEMPORAL SMOOTHING WAS USED.
utt_0065 utt 301.89 304.51 -X HERE ARE SEGMENTATION OF VEHICLESWITH LARGE OCCLUSIONS.
utt_0066 utt 304.51 313.12 -X WE DEMONSTRATE THAT LEARNING ROBUST AMODALREPRESENTATION AUTOMATICALLY IMPROVES TRACKING OF SEVERELY OCCLUDED OBJECTS.
utt_0068 utt 313.12 317.54 -X WE HAVE COLLECTED A LARGETIME-LAPSE DATASET OF one hundred CAMERAS CAPTURED ACROSS THE WORLD.
utt_0069 utt 317.54 321.02 -X WE HAVE RELEASEDDATA FROM twenty CAMERAS CAPTURED BY US.
utt_0070 utt 321.05 326.66 -X FOR ADDITIONAL RESULTS, CODE AND DATASET,PLEASE VISIT OUR WEBSITE WALT.CS.CMU.EDU.
utt_0071 utt 327.93 329.54 -1.3191 THANK YOU.
