utt_0000 utt 1.48 5.58 -X HELLO MY NAME IS ALEX MEI, I AM A MASTERS GRADUATE FROM UC SANTA BARBARA,
utt_0001 utt 5.58 7.09 -X AND TODAY I WILL BE PRESENTING FARM.
utt_0002 utt 12.27 16.98 -X THIS PRESENTATION CONTAINS EXAMPLES OF HARMFUL TEXT SO IF YOU ARE UNCOMFORTABLE,
utt_0004 utt 19.54 25.43 -X THE CURRENT AGE OF DIGITAL MEDIA HAS RAISED CONCERNS ABOUT PEOPLE’S PHYSICAL SAFETY.
utt_0005 utt 26.22 31.57 -X UNSAFE LANGUAGE CAN COME IN MANY FORMS. FIRST, THEY CAN BE OVERTLY UNSAFE,
utt_0006 utt 31.57 35.92 -X IN THAT THEY CAN BE CHARACTERIZED BY EXPLICITLY VIOLENT KEYWORDS.
utt_0007 utt 35.92 44.37 -X SECOND, THEY CAN BE INDIRECTLY UNSAFE, IN THAT THEY ARE NOT ACTIONABLE STATEMENTS BUT INSTEAD ENCOURAGE FUTURE EVENTS THAT CAN LEAD TO PHYSICAL HARM.
utt_0009 utt 44.37 47.22 -X OUR WORK FOCUSES ON COVERTLY UNSAFE TEXT,
utt_0010 utt 47.22 51.86 -X WHICH IS PHYSICALLY UNSAFE BUT REQUIRES AN ELEMENT OF REASONING TO DEDUCE.
utt_0011 utt 53.07 57.75 -X FOR MORE BACKGROUND INTO COVERTLY UNSAFE LANGUAGE, PLEASE REFER OUR PREVIOUS WORKS
utt_0012 utt 58.86 70.52 -X BECAUSE COVERTLY UNSAFE TEXT REQUIRES ADDITIONAL REASONING, IT IS IMPORTANT TO NOT ONLY BE CAPABLE OF IDENTIFYING SUCH TEXTS BUT ALSO EXPLAIN WHY SUCH TEXT IS UNSAFE,
utt_0014 utt 70.77 77.40 -X LEADING US TO OUR CENTRAL RESEARCH QUESTION: CAN LANGUAGE MODELS CORRECTLY IDENTIFY AND JUSTIFY
utt_0015 utt 78.07 82.52 -X WHETHER VARIOUS ACTIONS ARE SAFE OR UNSAFE IN DIFFERENT SCENARIOS.
utt_0016 utt 83.47 86.74 -X TO ANSWER THIS QUESTION, WE CONSIDER THREE MAIN DESIGN GOALS.
utt_0017 utt 86.74 100.25 -X WE WANT OUR SOLUTION TO BE (one) EXPLAINABLE – PROVIDE HUMAN INTERPRETABLE INSIGHTS INTO THE REASONING PROCESS (two) CREDIBLE – PROVIDE INFORMATION FROM CREDIBLE SOURCES AND (three) VERIFIABLE – ALLOW
utt_0020 utt 100.25 108.82 -X USERS TO EASILY FACT CHECK A GENERATED RATIONALE THESE CRITERIA WERE CHOSEN TO ALIGN WITH A USER-CENTERED IDEOLOGY TOWARD TRANSPARENT AI
utt_0022 utt 108.82 115.26 -X THAT PROVIDE STAKEHOLDERS THE RESOURCES TO DECIDE FOR THEMSELVES WHETHER TO TRUST AN AI SYSTEM
utt_0023 utt 116.05 125.02 -X FARM IS OUR ATTEMPT AT A SOLUTION THAT MEETS THESE DESIGN CRITERIA. IT IS A PIPELINE APPROACH CONSISTING OF THREE MAIN STEPS.
utt_0025 utt 125.11 131.32 -X FOR A GIVEN SAFETY SCENARIO, WE FIRST FOVEATE, OR IDENTIFY, THE FOCUS OF THE SCENARIO
utt_0026 utt 132.82 138.23 -X WE USE THIS FOVEATION TO QUERY CREDIBLE EXTERNAL SOURCES TO ATTRIBUTE TO
utt_0027 utt 138.93 149.98 -X FINALLY, WE PASS THE RETRIEVED SOURCES AND KNOWLEDGE INTO A LANGUAGE MODEL TO GENERATE A VERIFIABLE RATIONALE I WILL NOW GO OVER EACH STEP IN MORE DETAIL
utt_0029 utt 150.01 161.50 -X THE FOVEATION TASK IS A TEXT COMPLETION TASK GUIDED BY FEW-SHOT DEMONSTRATIONS TO IDENTIFY THE FOCUS ON A SCENARIO. COMPARED TO EXISTING WORK, OUR FOVEATION
utt_0031 utt 161.50 165.44 -X TASK IS UNCONSTRAINED TO CAPTURE THE COMPLEX NATURE OF A SAFETY SCENARIO.
utt_0032 utt 166.07 172.00 -X TO SELECT OUR FOVEATION, WE USE GREEDY DECODING TO APPROXIMATE THE MAXIMUM LIKELIHOOD FOVEATION.
utt_0033 utt 172.38 182.75 -X BY PERFORMING EXPLICIT FOVEATION, WE AIM TO BOTH DENOISE AND ADD INTERMEDIATE INTERPRETABILITY IN THE REASONING PROCESS. TO USE A CONCRETE EXAMPLE,
utt_0035 utt 182.75 195.81 -X A USER MAY ASK A LANGUAGE MODEL WHETHER THEY SHOULD TASTE A COLORFUL MUSHROOM THEY ENCOUNTER ON A HIKE IN THE WOODS. WE PROMPT THE LANGUAGE MODEL TO GENERATE EXPLICITLY GENERATE THE FOVEATION FROM THE GIVEN SCENARIO.
utt_0038 utt 198.30 203.97 -X ONCE WE HAVE IDENTIFIED OUR FOVEATION, WE SEEK TO ATTRIBUTE TO EXTERNAL KNOWLEDGE SOURCES.
utt_0039 utt 204.57 210.53 -X THIS DESIGN CHOICE PROVIDES A TIME-AGNOSTIC SOLUTION WITH NATURALLY BUILT-IN ATTRIBUTION.
utt_0040 utt 210.81 216.35 -X WE CONSIDER THREE SOURCES THAT BALANCE GENERALITY, CREDIBILITY, AND SCALABILITY.
utt_0041 utt 217.12 222.63 -X AN OPEN-DOMAIN WEB SEARCH LIKE GOOGLE IS THE MOST GENERAL AND UNRESTRICTED CHOICE.
utt_0042 utt 225.63 232.42 -X TO TRADEOFF GENERALITY FOR CREDIBILITY, WE TRY FILTERING GOOGLE FOR SPECIFIC WEBSITE DOMAINS.
utt_0043 utt 233.18 240.80 -X FINALLY, WE CONSIDER WIKIPEDIA AS KNOWLEDGE BASE WITH A LAYER OF FACT-CHECKING THAT MAINTAINS A LARGE SCALE OF GENERALIZED KNOWLEDGE.
utt_0045 utt 241.86 250.88 -X IN OUR CONCRETE EXAMPLE, WE EXTRACT INFORMATION THAT COLORFUL MUSHROOMS MAY RELATE TO MUSHROOM POISONING, WHICH HAS NUMEROUS PHYSICALLY HARMFUL EFFECTS WHEN CONSUMED.
utt_0047 utt 253.02 258.08 -X WITH OUR ATTRIBUTED KNOWLEDGE, WE PASS IT BACK INTO A LANGUAGE MODEL TO GENERATE RATIONALES.
utt_0048 utt 258.08 262.63 -X ONCE AGAIN, WE USE GREEDY DECODING AS A MECHANISM TO MITIGATE HALLUCINATION.
utt_0049 utt 263.07 267.85 -X OUR FEW-SHOT DEMONSTRATIONS ADDITIONALLY HELP US TO FORMAT OUR ANSWERS IN A TEMPLATE.
utt_0050 utt 268.77 276.87 -X IN OUR EXAMPLE, WE CAN SEE THAT THIS PIPELINED APPROACH GENERATES A CORRECT RATIONALE THAT EXPLAINS WHY TASTING WILD MUSHROOMS IS AN UNSAFE ACTION.
utt_0052 utt 278.59 290.31 -X OUR CLASSIFICATION RESULTS SHOW AN IMPRESSIVE INCREASE IN ACCURACY COMPARED TO THE BASELINE REPORTED IN THE SAFETEXT PAPER. TO PROVIDE A MORE FINE-GRAINED ANALYSIS,
utt_0054 utt 290.31 300.58 -X WE COMPARE THE DIFFERENT VARIATIONS OF FARM WITH RESPECT TO THE ATTRIBUTION SOURCE AND THE NUMBER OF SOURCES WE USE. WE HYPOTHESIZE THAT GOOGLE CREDIBLE SHOWS PEAK PERFORMANCE COMPARED TO GOOGLE
utt_0056 utt 303.40 312.78 -X BASE AND WIKIPEDIA AS IT BALANCES REPUTABILITY AND RELIABILITY WITH DATA AVAILABILITY. FOR THE NUMBER
utt_0057 utt 313.16 319.21 -X OF SNIPPETS, TOO MANY POTENTIAL SNIPPETS WOULD RESULT IN TOO MUCH NOISE FOR A MODEL TO REASON
utt_0059 utt 324.75 335.43 -X SOURCES AND DEPENDENCE ON A RELIABLE RANKING SYSTEM, POTENTIALLY INCREASING THE AMOUNT OF IRRELEVANT KNOWLEDGE OR MISINFORMATION. WE FIND THE OPTIMAL BALANCE AT three SNIPPETS.
utt_0061 utt 337.06 341.80 -X NEXT, WE DIVE INTO A FINE-GRAINED ERROR ANALYSIS OF GENERATED RATIONALES.
utt_0062 utt 342.28 354.40 -X THE FIRST TYPE IS FACTUALITY ERRORS, WHERE GENERATED RATIONALES CONTAIN INCORRECT INFORMATION. WE COMPARE FARM TO A BASELINE WITHOUT FOVEATION AND ATTRIBUTION
utt_0064 utt 358.44 369.90 -X TO EXTERNAL KNOWLEDGE. THE BASELINE MAY HALLUCINATE WITHOUT GROUNDING TO EXTERNAL KNOWLEDGE. FARM FIXES SUCH ISSUE, BUT MAY SUFFER FROM EXTERNAL MISINFORMATION.
utt_0066 utt 373.16 378.45 -X ENTAILMENT ERRORS OCCUR WHEN GENERATED RATIONALES DO NOT ENTAIL THE CONCLUSION.
utt_0067 utt 379.05 386.38 -X THE BASELINE MAY UNDER DEVELOP EXPLANATIONS THAT LEAD FROM ACTION TO HARM.
utt_0068 utt 387.11 393.58 -X FARM BENEFITS FROM SOURCES THAT EXPLICITLY STATE LOGICAL CONNECTIONS.
utt_0069 utt 394.51 403.81 -X FINALLY ATTRIBUTION ERRORS OCCUR WHEN THE SOURCE DOES NOT MATCH THE INFORMATION STATED IN THE RATIONALE. THE BASELINE HALLUCINATES NONEXISTENT SOURCES
utt_0071 utt 403.81 410.42 -X IN RATIONALES WHILE FARM’S ATTRIBUTION STEP CAN RETRIEVE AND GENERATE SPECIFIC LINKS.
utt_0072 utt 413.87 418.00 -X FOR MORE BACKGROUND, A PRINCIPLED MATHEMATICAL FORMULATION,
utt_0073 utt 418.00 421.94 -X AND SUPPLEMENTARY EXPERIMENTS AND ANALYSIS PLEASE REFER TO OUR PAPER.
utt_0074 utt 423.76 434.00 -X TO CONCLUDE THE PRESENTATION, WE ESTABLISH FARM AS A PROBLEM SOLVING TECHNIQUE THAT FIRST FOVEATES ON MISSING INFORMATION, RETRIEVES IT AND ATTRIBUTES IT TO TRUSTWORTHY SOURCES.
utt_0076 utt 434.32 440.27 -X THIS IS THEN UTILIZED FOR IN CONTEXT INFERENCE TO GENERATE HUMAN INTERPRETABLE RATIONALES.
utt_0077 utt 440.97 452.53 -X FARM IS A TIME-AGNOSTIC SOLUTION THAT IS EASILY VERIFIABLE AND ACHIEVES STATE-OF-THE-ART PERFORMANCE ON SAFETEXT WHILE IMPROVING FAITHFULNESS, ENTAILMENT, AND ATTRIBUTION
utt_0079 utt 454.26 466.69 -X ABILITIES IN RATIONALE GENERATION. WHILE WE DISCUSS FARM EXCLUSIVELY TODAY WITH RESPECT TO PHYSICAL SAFETY, A PROMISING FUTURE DIRECTION IS TO APPLY FARM IN A MORE GENERAL
utt_0081 utt 467.76 475.06 -4.2470 DOMAIN. IF YOU ARE INTERESTED, PLEASE CHECKOUT OUT CODEBASE AND REACH OUT IF YOU HAVE ANY QUESTIONS.
