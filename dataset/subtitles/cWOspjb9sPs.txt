utt_0000 utt 4.84 6.77 -X HELLO I AM MARIA BRAVO.
utt_0001 utt 6.99 21.65 -X I WOULD LIKE TO PRESENT OUR PAPER “OPEN VOCABULARY ATTRIBUTE DETECTION” WHERE WE DEVELOP A DENSE OBJECT-ORIENTED ATTRIBUTE DATASET TO FACILITATE THE VISUAL RECOGNITION ANALYSIS BEYOND THE OBJECT ACCURACY FOR VISION LANGUAGE MODELS.
utt_0004 utt 22.16 23.22 -X IN OUR WORK,
utt_0005 utt 23.25 27.09 -X WE INTRODUCE THE OPEN-VOCABULARY ATTRIBUTE DETECTION (OVAD) TASK,
utt_0006 utt 27.09 33.30 -X WHERE THE OBJECTIVE IS TO DETECT ALL OBJECTS AND PREDICT THEIR ASSOCIATED ATTRIBUTES.
utt_0007 utt 33.30 34.87 -X WE PROPOSE THE OVAD DATASET:
utt_0008 utt 34.87 41.11 -X A CLEAN AND DENSELY ANNOTATED EVALUATION DATASET DESIGNED FOR OPEN-VOCABULARY ATTRIBUTE DETECTION.
utt_0009 utt 41.11 44.53 -X WE PROVIDE AN ATTRIBUTE-FOCUSED BASELINE METHOD FOR THE OVAD TASK,
utt_0010 utt 44.53 50.26 -X WHICH OUTPERFORMS THE EXISTING OPEN-VOCABULARY MODELS THAT ONLY AIM FOR THE OBJECT CLASSES.
utt_0011 utt 50.61 57.49 -X FINALLY, WE BENCHMARKED THE ZERO-SHOT PERFORMANCE OF SEVERAL OPENSOURCE FOUNDATION MODELS ON VISUAL ATTRIBUTE,
utt_0012 utt 57.49 71.81 -X REVEALING THE CHALLENGES THEY ENCOUNTER IN ATTRIBUTE DETECTION. OPEN VOCABULARY RECOGNITION REFERS TO THE TASK OF RECOGNIZING AND UNDERSTANDING OBJECTS OR VISUAL CONCEPTS IN IMAGES BEYOND A CLOSED SET OF CATEGORIES. IT INVOLVES THE ABILITY TO
utt_0015 utt 71.81 76.53 -X DETECT AND IDENTIFY OBJECTS THAT MAY NOT HAVE BEEN PART OF THE TRAINING DATA,
utt_0017 utt 76.53 79.38 -X DEFINED BY TEXT QUERIES DURING INFERENCE.
utt_0018 utt 79.99 86.36 -X VISION LANGUAGE MODELS HAVE ENABLED THIS TASK BY MATCHING INFORMATION CONTAINED IN IMAGE-TEXT PAIRS.
utt_0021 utt 88.08 96.22 -X OPEN VOCABULARY TECHNIQUES HAVE MADE SIGNIFICANT ADVANCEMENTS IN VARIOUS TASKS LIKE IMAGE CLASSIFICATION, OBJECT DETECTION, AND SEMANTIC SEGMENTATION,
utt_0025 utt 96.22 100.89 -X EVEN ACHIEVING COMPARABLE PERFORMANCE AGAINST SUPERVISED METHODS. HOWEVER,
utt_0027 utt 100.89 107.32 -X MOST OF THE METHODS PRIMARILY FOCUSED ON NOUN CONCEPTS, LEAVING BEHIND RESEARCH ON FINE GRAINED DETAILS.
utt_0030 utt 109.75 117.63 -X RESEARCH ON ATTRIBUTE DETECTION WITHIN LANGUAGE MODELS REMAINS LIMITED AND UNEXPLORED.
utt_0033 utt 117.63 130.41 -X ATTRIBUTES OFFER A RICH INFORMATION ABOUT VISUAL ELEMENTS THAT GO BEYOND SIMPLE OBJECT RECOGNITION. BY DETECTING AND RECOGNIZING ATTRIBUTES, COMPUTER VISION SYSTEMS CAN CAPTURE AND REPRESENT A WIDE RANGE OF VISUAL CHARACTERISTICS
utt_0039 utt 130.46 133.02 -X SUCH AS COLOR, TEXTURE, POSE AND STATE.
utt_0040 utt 133.02 137.63 -X THESE LEADS TO A MORE COMPREHENSIVE AND DESCRIPTIVE UNDERSTANDING OF THE VISUAL CONTENT.
utt_0043 utt 139.03 141.92 -X ATTRIBUTES ARE IMPORTANT FOR AN OBJECT'S IDENTITY.
utt_0044 utt 141.92 156.00 -X THEY CAN HELP DISTINGUISH DIFFERENT INSTANCES OF THE SAME CLASS, SUCH AS THE CASE OF THE BLUE SCISSORS OR THE WHITE HORSE IN THE PICTURES. RECOGNIZING ATTRIBUTES CAN ENABLE BETTER BETTER INTERPRETATION OF THE SCENE AND DECISION MAKING, SUCH AS KNOWING WHEN TO STOP AT A RED TRAFFIC LIGHT.
utt_0052 utt 157.63 164.38 -X WE INTRODUCED THE OVAD TASK TO EVALUATE THE ABILITY OF VISUAL-LANGUAGE MODELS IN RECOGNIZING OBJECT ATTRIBUTES.
utt_0055 utt 164.38 171.87 -X THE OBJECTIVE IS TO DETECT AND RECOGNIZE AN OPEN-SET OF OBJECTS IN AN IMAGE TOGETHER WITH AN OPEN-SET OF ATTRIBUTES FOR EVERY OBJECT.
utt_0058 utt 172.12 181.18 -X THE OVAD TASK CONSISTS OF TWO STAGES. THE FIRST STAGE, KNOWN AS OPEN-VOCABULARY DETECTION, AIMS TO DETECT ALL OBJECTS IN THE IMAGE,
utt_0062 utt 181.18 195.52 -X INCLUDING NOVEL OBJECTS THAT HAVE NO BOUNDING BOX OR CLASS ANNOTATION DURING TRAINING. THE SECOND STAGE FOCUSES ON IDENTIFYING THE ATTRIBUTES ASSOCIATED WITH EACH DETECTED OBJECT. NONE OF THE ATTRIBUTES ARE ANNOTATED DURING TRAINING, MAKING THEM ALL NOVEL.
utt_0069 utt 195.52 204.23 -X WHILE ANALYZING PREVIOUS DATASETS THAT CONTAIN OBJECT AND ATTRIBUTE ANNOTATIONS,
utt_0071 utt 204.23 210.91 -X WE FOUND FOUR MAJOR TYPES OF ERRORS THAT MAKE THEM UNSUITABLE FOR EVALUATING THE OVAD TASK. ERRORS TYPE A
utt_0074 utt 211.42 225.03 -X INVOLVE OBJECTS WITH INCORRECT ATTRIBUTE ANNOTATION. TYPE B ERRORS OCCUR WHEN ATTRIBUTE ANNOTATIONS ARE MISSING FOR AN OBJECT. TYPE C ERROR REFERS TO AMBIGUOUS ANNOTATION. THIS ATTRIBUTES CANNOT BE ACCURATELY MARKED ONLY BASED
utt_0080 utt 225.03 239.59 -X ON THE GIVEN IMAGE DUE TO INCOMPLETE INFORMATION. FOR EXAMPLE, MARKING THE RED BAG AS MOVING OR THE BLUE ONE AS FULL REQUIRE TEMPORAL INFORMATION OR AN INSIDE VIEW OF THE BAG. TYPE D ERRORS CORRESPOND TO NON VISUAL ATTRIBUTES, FOR EXAMPLE THE WEIGHT OR SMELL OF AN OBJECT.
utt_0087 utt 239.59 249.89 -X TO ADDRESS THESE ISSUES AND PROVIDE A RELIABLE ATTRIBUTE BENCHMARK, WE CREATED A NEW EVALUATION DATASET THAT ENSURES CORRECT, DENSE, UNAMBIGUOUS AND VISUALLY CONSISTING ANNOTATIONS.
utt_0092 utt 251.84 258.44 -X WE INTRODUCED THE OVAD BENCHMARK, AN EVALUATION DATASET SPECIFICALLY DESIGNED FOR OPEN-VOCABULARY ATTRIBUTE DETECTION.
utt_0095 utt 258.44 271.72 -X THE OVAD BENCHMARK HAS ALL ATTRIBUTES MARKED EITHER AS POSITIVE, NEGATIVE, OR UNKNOWN FOR EACH OBJECT. THIS TYPE OF ANNOTATION RESULTS IN DENSE ANNOTATIONS FOR EVERY OBJECT AND MINIMIZES THE MISSING TYPE ERRORS. NEGATIVE ATTRIBUTE NEGATIVE ATTRIBUTE ANNOTATIONS ENABLE QUANTIFYING FALSE
utt_0103 utt 271.72 273.96 -X POSITIVE PREDICTIONS. DURING EVALUATION,
utt_0104 utt 273.96 275.82 -X ATTRIBUTES MARKED AS UNKNOWN ARE EXCLUDED,
utt_0105 utt 275.82 282.02 -X REPRESENTING CASES WHERE EITHER THE ATTRIBUTE IS UNKNOWN FOR AN INSTANCE, OR A CLEAR DISCRETE LABEL CANNOT BE ASSIGNED.
utt_0108 utt 282.02 287.27 -X WE MANUALLY EXCLUDED INFEASIBLE OBJECT-ATTRIBUTE COMBINATION DURING ANNOTATION TO PREVENT INCORRECT TYPE ERRORS.
utt_0111 utt 287.30 293.03 -X THE BENCHMARK UNDERGOES DIFFERENT STAGES AND RIGOROUS QUALITY TESTING TO ENSURE ANNOTATION CONSISTENCY.
utt_0114 utt 296.49 308.20 -X THE OVAD EVALUATION DATASET IS FULLY ANNOTATED BY HUMANS. IT CONTAINS AN AVERAGE OF ninety-six ATTRIBUTE ANNOTATIONS PER OBJECT INSTANCE, MAKING IT THE MOST DENSELY ANNOTATED OBJECT-LEVEL ATTRIBUTE DATASET.
utt_0119 utt 308.20 309.58 -X THE DATA SET CONSISTS OF one point four
utt_0120 utt 309.83 312.11 -X MILLION ATTRIBUTE ANNOTATION ACROSS two thousand
utt_0121 utt 312.29 314.59 -X TEST IMAGES. IT CONSIDERS
utt_0122 utt 315.40 319.80 -X one hundred and seventeen ATTRIBUTE CATEGORIES ORGANIZED INTO A HIERARCHY OF nineteen ATTRIBUTE TYPES, COVERING
utt_0124 utt 319.82 324.68 -X eighty OBJECT CATEGORIES. THE OVAD TASK CAN BE EVALUATED IN TWO SETTINGS:
utt_0126 utt 324.68 332.17 -X (one) THE FULL BENCHMARK EVALUATION, WHERE MODELS ARE REQUIRED TO DETECT AND CLASSIFY ALL OBJECTS ALONG WITH THEIR ATTRIBUTES.
utt_0129 utt 332.17 339.31 -X AND THE (two) BOX-ORACLE EVALUATION, WHERE OBJECT BOXES ARE PROVIDED, AND ONLY ATTRIBUTE CLASSIFICATION IS ASSESSED.
utt_0132 utt 340.78 355.21 -X WE PRESENT A BASELINE METHOD FOR THE OVAD TASK, WHICH AIMS TO TRAIN A VISION MODEL CAPABLE OF DETECTING OBJECTS AND THEIR ATTRIBUTES IN AN OPEN-VOCABULARY SETTING. OUR METHOD INVOLVES A TWO-STAGE DETECTOR THAT MATCHES IMAGE REGIONS WITH TEXT EMBEDDINGS. DURING TRAINING,
utt_0139 utt 355.21 360.72 -X WE USE IMAGE-CAPTION PAIRS AND OBJECT DETECTION ANNOTATIONS FROM BASE OBJECT CLASSES.
utt_0141 utt 360.72 372.30 -X WE EXTRACT RELEVANT PARTS OF THE CAPTIONS, INCLUDING NOUNS AND NOUN COMPLEMENTS, AS SIGNALS FOR LEARNING VISUAL-TEXT ALIGNMENT. DURING INFERENCE, OUR MODEL GENERATES VISUAL EMBEDDINGS FOR OBJECTS,
utt_0146 utt 372.30 376.72 -X ENABLING THE DETECTION OF BOTH BASE AND NOVEL OBJECTS, ALONG WITH THEIR ATTRIBUTE.
utt_0148 utt 377.32 381.97 -X WE COMPARED OUR OVAD-BASELINE WITH PREVIOUS OPEN-VOCABULARY DETECTION MODELS.
utt_0150 utt 381.97 392.37 -X ALTHOUGH THE OPEN-VOCABULARY DETECTION METHODS WERE ORIGINALLY INTENDED FOR OBJECT RECOGNITION RATHER THAN ATTRIBUTE DETECTION, ALL METHODS ACHIEVED RESULTS ABOVE CHANCE LEVEL.
utt_0155 utt 392.37 393.78 -X NOTABLY, METHODS THAT INCORPORATE
utt_0161 utt 400.88 402.16 -X APPROACHES THAT USE SINGLE TEXT
utt_0163 utt 403.70 408.98 -X WE ALSO TESTED LARGE PRETRAINED VISION-LANGUAGE MODELS ON OUR ATTRIBUTE EVALUATION BENCHMARK. WE OBSERVE THAT
utt_0168 utt 411.63 417.59 -X ASPECTS LIKE ATTRIBUTES. WE COMPARED MODELS WITH VARYING TRAINING DATASET SIZES AND PARAMETERS. WE FOUND THAT THE
utt_0172 utt 418.90 426.96 -X GREATER IMPACT THAN ITS QUANTITY OR MODEL SIZE. ADDITIONALLY, WE NOTICED THAT A FINE-GRAINED ALIGNMENT BETWEEN IMAGE REGIONS AND TEXT SIGNIFICANTLY IMPROVES THE UNDERSTANDING OF VISUAL
utt_0181 utt 432.98 433.59 -X TRAINED VERSIONS.
utt_0182 utt 433.59 435.09 -X TO CONCLUDE, FURTHER RESEARCH ON
utt_0184 utt 436.63 439.38 -X THE OVAD BENCHMARK PROVIDES A SIGNIFICANT STEP TOWARDS TESTING VISION-LANGUAGE
utt_0190 utt 445.17 446.87 -6.7643 DETAILS AND THANK YOU FOR YOUR ATTENTION.
