utt_0001 utt 1.33 2.51 -X MY NAME IS DA YAN.
utt_0002 utt 2.67 8.40 -X I AM AN ASSISTANT PROFESSOR OF COMPUTER SCIENCE FROM THE UNIVERSITY OF ALABAMA AT BIRMINGHAM.
utt_0003 utt 8.62 22.13 -X TODAY, I WILL PRESENT OUR PAPER TITLED “DISTRIBUTED TASK-BASED TRAINING OF TREE MODELS,” WHICH DESCRIBES THE DESIGN OF OUR DISTRIBUTED SYSTEM NAMED TREESERVER, FOR TRAINING TREE ENSEMBLE
utt_0005 utt 22.13 26.26 -X MODELS OVER LARGE TABULAR DATA.
utt_0007 utt 31.63 40.72 -X HERE, WE SHOW A DATA TABLE WHERE EACH ROW FOLLOWS A PATH FROM THE ROOT OF THE DECISION TREE TO A LEAF NODE WHICH GIVES THE PREDICTED LABEL.
utt_0009 utt 40.75 46.99 -X FOR EXAMPLE, RECORD # five HAS Aone LESS THAN forty SO IT GOES TO THE LEFT NODE (MOVE MOUSE),
utt_0010 utt 46.99 52.95 -X AND SINCE Atwo IS PHD, IT FURTHER GOES TO THE LEFT CHILD (MOVE MOUSE)
utt_0011 utt 52.95 55.83 -X WHICH IS A LEAF NODE THAT GIVES THE PREDICTION ‘NO.’
utt_0012 utt 56.85 65.30 -X WE CAN SEE THAT EACH NODE IN A DECISION TREE IS ASSOCIATED WITH A SUBSET OF ROWS IN THE DATA TABLE.
utt_0014 utt 65.30 73.01 -X DECISION TREES CAN BE USED BY THE IDEA OF BAGGING AND BOOSTING TO CREATE LARGE ENSEMBLE MODELS THAT ARE MORE ACCURATE.
utt_0016 utt 73.20 85.62 -X FOR EXAMPLE, THE RECENTLY PROPOSED DEEP FOREST MODEL CAN CONTAIN MANY TREES, MAKING IT IMPORTANT TO HAVE AN EFFICIENT PARALLEL TREE CONSTRUCTION SYSTEM.
utt_0018 utt 85.62 92.11 -X RECALL THAT AT EACH NODE, WE COMPUTE A CONDITION TO SPLIT THE ROWS INTO THE LEFT AND RIGHT CHILDREN NODES.
utt_0020 utt 92.46 96.24 -X HERE WE REVIEW HOW SUCH A SPLIT-CONDITION IS CALCULATED.
utt_0021 utt 97.04 105.36 -X CONSIDER Aone, WHERE WE TRY DIFFERENT SPLIT-CONDITIONS AND THEIR RESULTING IMPURITY SCORES SUCH AS ENTROPY AND VARIANCE.
utt_0023 utt 105.90 109.14 -X HERE, Aone&LTfive LEADS TO AN IMPURITY OF one0.
utt_0024 utt 111.12 114.51 -X Aone&LTone0 LEADS TO AN IMPURITY OF five WHICH IS SMALLER.
utt_0025 utt 116.33 121.04 -X Aone&LTone5 LEADS TO AN IMPURITY OF one0 WHICH IS LARGER AGAIN.
utt_0026 utt 121.04 127.09 -X SO, WE SELECT THE SECOND CONDITION FOR Aone WHICH HAS THE SMALLEST IMPURITY.
utt_0027 utt 127.09 131.67 -X WE DO THE SAME TO FIND THE BEST SPLIT-CONDITION FOR Atwo, Athree AND Afour.
utt_0028 utt 134.86 140.31 -X THE OVERALL BEST SPLIT-CONDITION WITH THE MINIMUM IMPURITY IS THEREFORE Atwo&LTsix.
utt_0029 utt 143.37 155.51 -X IN RECENT YEARS, THERE ARE TWO TRENDS IN BUILDING TREE MODELS, INCLUDING BUILDING LARGER AND LARGER MODELS SUCH AS DEEP FORESTS WITH MANY TREES, AND USING SCALABLE DISTRIBUTED SYSTEMS
utt_0031 utt 155.51 162.55 -X TO BUILD THE MODELS FROM LARGE TABULAR DATA USING PARALLEL AND DISTRIBUTED INFRASTRUCTURE.
utt_0032 utt 163.54 171.19 -X OUR TREESERVER SYSTEM FEATURES TWO DESIGNS THAT ARE DIFFERENT FROM PRIOR SYSTEMS FOR CONSTRUCTING DECISION TREES.
utt_0034 utt 171.19 179.48 -X FIRSTLY, TREESERVER PARTITIONS A DATA TABLE BY COLUMNS TO DIFFERENT MACHINES RATHER THAN BY ROWS AS IN SPARK MLLIB OR XGBOOST.
utt_0036 utt 180.69 193.33 -X SECONDLY, TREESERVER USES A TASK-BASED PARALLEL EXECUTION MODEL CALLED T-THINKER TO MAKE SURE THAT CPU CORES IN A DISTRIBUTED CLUSTER ARE FULLY UTILIZED.
utt_0038 utt 193.33 200.21 -X RECALL THAT TO COMPUTE A NODE SPLIT-CONDITION, WE NEED TO FIND THE BEST SPLIT-CONDITION FOR EACH COLUMN AI.
utt_0040 utt 200.66 211.96 -X AND FOR EACH COLUMN WE ACTUALLY NEED TO TRY MANY ALTERNATIVE SPLIT-VALUES TO PARTITION THE ROWS, SO IF THE ROWS ARE ON DIFFERENT MACHINES, A LOT OF COMMUNICATION IS NEEDED
utt_0042 utt 212.02 215.67 -X FOR EACH SPLIT-VALUE OF EACH COLUMN.
utt_0043 utt 216.08 230.13 -X IN CONTRAST, OUR TREESERVER SYSTEM PARTITIONS THE DATA TABLE BY COLUMNS SO THAT EACH MACHINE THAT HOLDS A COLUMN AI CAN COMPUTE THE BEST SPLIT-CONDITION OF AI BY ITSELF WITHOUT COMMUNICATION.
utt_0045 utt 230.13 241.59 -X IN FACT, EXISTING SYSTEMS THAT ADOPT ROW-PARTITIONING CANNOT COMPUTE THE EXACT SPLIT-CONDITION DUE TO THE OVERWHELMING AMOUNT OF COMMUNICATION, AND THEY HAVE TO USE APPROXIMATE METHODS TO
utt_0047 utt 241.59 245.40 -X REDUCE THE NUMBER OF SPLIT-VALUES THAT THEY EXAMINE.
utt_0048 utt 245.62 258.52 -X ON THIS SLIDE, THE PARAGRAPH ON THE LEFT SHOWS THAT PLANET, WHICH IS GOOGLE’S TREE BUILDING MAPREDUCE ALGORITHM AND LATER ADOPTED BY SPARK MLLIB, USES APPROXIMATE EQUIDEPTH HISTOGRAMS
utt_0050 utt 258.58 269.75 -X WHILE THE PARAGRAPH ON THE RIGHT SHOW THAT XGBOOST USES WEIGHTED QUANTILE SKETCHES TO FIND GOOD APPROXIMATE SPLIT-VALUES.
utt_0052 utt 269.75 280.02 -X BESIDES COLUMN-BASED PARTITIONING, THE OTHER DESIRABLE FEATURE OF TREESERVER IS THAT IT USES A TASK-BASED EXECUTION MODEL TO KEEP CPU CORES EFFECTIVELY UTILIZED.
utt_0054 utt 280.88 294.36 -X SPECIFICALLY, WHEN THE NUMBER OF ROWS FALLING INTO A NODE IS SMALL ENOUGH, IT IS MORE EFFICIENT TO LET A MACHINE PULL ALL THESE ROWS TO ITS LOCAL MEMORY AND CONSTRUCT THE ENTIRE SUBTREE WITHOUT COMMUNICATION.
utt_0057 utt 294.36 306.74 -X FOR EXAMPLE, NODE Xseven ON THIS SLIDE ONLY HAS TWO ROWS eight AND nine, SO WE LET A MACHINE PULL THESE TWO ROWS TO ITS LOCAL MEMORY TO CONSTRUCT THE GREEN SUBTREE.
utt_0059 utt 308.27 318.61 -X SINCE TREESERVER ADOPTS A COLUMN-BASED PARTITIONING, WE ACTUALLY NEED TO PULL THE COLUMNS FOR THOSE TWO ROWS FROM DIFFERENT MACHINES.
utt_0061 utt 318.61 324.69 -X HERE, OUR TASK-BASED COMPUTING MODEL IS CALLED T-THINKER, AND IT WAS PROPOSED EARLY ON AS
utt_0062 utt 324.79 326.68 -X A CCC GREAT INNOVATIVE IDEA.
utt_0063 utt 327.25 338.20 -X THE IDEA IS THAT IF THE COMPUTATION COST IS HIGH AND SUPERLINEAR TO THE DATA SIZE, AS LONG AS THE DATA SIZE IS REASONABLY LARGE, THE COMPUTATION COST WOULD BE HIGH ENOUGH
utt_0065 utt 338.20 350.01 -X TO JUSTIFY THE LINEAR COST OF PULLING THE DATA TO LOCAL MEMORY, AND AS LONG AS TASK COMPUTATION AND DATA COMMUNICATION ARE PROPERLY OVERLAPPED, WE CAN KEEP CPU CORES BUSY.
utt_0067 utt 351.73 359.19 -X BESIDES TREESERVER, WE HAVE DEVELOPED TWO OTHER SYSTEMS BASED ON T-THINKER’S TASK-BASED COMPUTING MODEL.
utt_0069 utt 359.19 369.72 -X THE FIRST ONE IS G-THINKER, WHICH IS A DISTRIBUTED PROGRAMMING FRAMEWORK FOR WRITING SUBGRAPH FINDING ALGORITHMS SUCH AS DENSE SUBGRAPH MINING AND SUBGRAPH MATCHING, AND THE RESULTED
utt_0071 utt 369.72 375.51 -X WORKS HAVE BEEN PUBLISHED IN TOP VENUES SUCH AS VLDB, ICDE AND VLDB JOURNAL.
utt_0072 utt 377.14 390.78 -X THE SECOND SYSTEM IS PREFIXFPM, WHICH IS A PARALLEL PROGRAMMING FRAMEWORK FOR MINING FREQUENT PATTERNS OF ANY USER-SPECIFIED TYPE, SUCH AS SUBSEQUENCES, SUBGRAPHS, SUBTREES OR EVEN SUBMATRICES.
utt_0075 utt 391.38 397.66 -X THE RESULTED WORKS HAVE BEEN PUBLISHED IN TOP VENUES SUCH AS VLDB, ICDE AND TODS.
utt_0076 utt 400.02 403.22 -X NEXT, LET’S TAKE A LOOK AT OUR DESIGN OF TREESERVER.
utt_0077 utt 403.76 409.98 -X INITIALLY, OUR DATA TABLE IS STORED ON HADOOP DISTRIBUTED FILE SYSTEMS, ORGANIZED IN COLUMN MAJOR ORDER.
utt_0079 utt 411.06 423.06 -X TREESERVER ADOPTS A MASTER-WORKERS ARCHITECTURE, WHERE THE COLUMNS ARE LOADED INTO THE MEMORY OF DIFFERENT WORKERS EACH COLUMN HAS MULTIPLE REPLICAS IN DIFFERENT WORKERS FOR FAULT TOLERANCE
utt_0081 utt 423.06 428.86 -X AND TO PROVIDE MORE WORKER CANDIDATES IN TAKING COLUMN-RELATED TASKS TO IMPROVE LOAD BALANCING.
utt_0082 utt 430.71 436.50 -X END USERS SPECIFY THEIR MODEL REQUIREMENTS AND SUBMIT THEM AS JOBS TO THE MASTER OF TREESERVER,
utt_0083 utt 436.53 441.88 -X WHICH DISASSEMBLES THESE MODELS INTO INDIVIDUAL TREES TO BUILD WITH THE HELP OF WORKERS,
utt_0084 utt 442.68 448.09 -X AND WHICH FINALLY REASSEMBLES THE CONSTRUCTED TREES INTO THE REQUESTED ENSEMBLE MODELS.
utt_0085 utt 449.36 454.94 -X THE MASTER CONTROLS THE PACE OF TREE BUILDING TO MAKE SURE THAT THE MEMORY CONSUMPTION IS BOUNDED.
utt_0087 utt 455.09 459.80 -X SPECIFICALLY, IT ONLY ALLOWS A FIXED NUMBER OF TREES TO BE ACTIVE UNDER CONSTRUCTION,
utt_0088 utt 459.83 466.91 -X AND A NEW TREE STARTS ITS CONSTRUCTION ONLY IF SOME EXISTING TREE IS FULLY CONSTRUCTED WITH RESOURCES RELEASED.
utt_0090 utt 468.02 471.03 -X WE HAVE TWO KINDS OF TASKS IN TREESERVER.
utt_0091 utt 471.03 476.25 -X WHEN THE NUMBER OF TRAINING ROWS FALLING INTO A NODE IS LARGE, WE LET THE WORKERS COLLABORATE
utt_0092 utt 476.28 481.91 -X TO COMPUTE THE OVERALL BEST SPLIT-CONDITION, AND THE WORKER TASKS HERE ARE COLUMN-TASKS,
utt_0093 utt 481.91 484.79 -X WHICH ARE NETWORK-INTENSIVE.
utt_0094 utt 484.79 493.08 -X WHEN THE NUMBER OF ROWS FALLING INTO A NODE IS SMALL ENOUGH, WE LET A PARTICULAR WORKER COLLECT ALL THESE ROW DATA FROM OTHER WORKERS INTO ITS OWN MEMORY,
utt_0096 utt 493.21 498.30 -X SO THAT THE WORKER CAN CONSTRUCT THE ENTIRE SUBTREE UNDER THE NODE WITHOUT COMMUNICATION,
utt_0097 utt 498.30 506.94 -X WHICH IS CPU-INTENSIVE WE CALL THE WORKER THAT IS ASSIGNED TO CONSTRUCT THE SUBTREE UNDER A NODE AS THE KEY WORKER OF THAT NODE.
utt_0099 utt 507.96 518.81 -X SINCE COLUMN-TASKS ARE IO-BOUND AND SUBTREE-TASKS ARE CPU-BOUND, WE WOULD LIKE THEM TO COEXIST TO KEEP BOTH NETWORK AND CPU CORES BUSY SIMULTANEOUSLY.
utt_0101 utt 518.81 524.35 -X FOR THIS REASON, THE MASTER ADOPTS A BFS AND DFS HYBRID METHOD TO SCHEDULE TASKS.
utt_0102 utt 524.92 532.54 -X INITIALLY, TASKS FOR BUILDING THE TOP-LEVEL TREE NODES ARE SCHEDULED IN BFS MANNER TO CREATE ENOUGH PARALLELISM.
utt_0104 utt 533.37 545.72 -X ONCE A NODE HAS THE NUMBER OF ROWS BELOW eighty THOUSAND, THE TASKS FOR THE NODES IN ITS SUBTREE ARE THEN SCHEDULED IN DEPTH FIRST MANNER SO THAT SUBTREE TASKS CAN BE REACHED SOONER THAN BFS.
utt_0107 utt 547.48 558.68 -X MOREOVER, IF THE NUMBER OF ROWS AT A NODE IS BELOW ten THOUSAND, THE BUILDING OF THE ENTIRE SUBTREE IS TREATED AS A SUBTREE-TASK FOR COMPUTE-INTENSIVE PROCESSING BY SOME KEY WORKER.
utt_0110 utt 558.68 560.00 -X AND THIS PROCESS GOES ON.
utt_0111 utt 564.28 567.61 -X IN TREESERVER, THERE ARE TWO KINDS OF COMMUNICATION CHANNELS.
utt_0112 utt 568.06 573.88 -X ONE IS BETWEEN MASTER AND WORKERS, WHICH SENDS THE TASK CONTROL MESSAGES FROM THE MASTER,
utt_0113 utt 573.88 578.56 -X AND SENDS THE COMPUTED TASK RESULTS TOWARDS THE MASTER.
utt_0114 utt 578.56 584.60 -X THE OTHER IS BETWEEN WORKERS TO COLLECT DATA FROM EACH OTHER, AS IS NEEDED BY THE KEY WORKERS
utt_0115 utt 584.82 586.30 -X OF SUBTREE-TASKS.
utt_0116 utt 587.99 591.48 -X NEXT, WE CONSIDER THE COMPONENTS INSIDE THE MASTER.
utt_0117 utt 591.96 601.21 -X THE MASTER KEEPS A MAIN THREAD THAT FETCHES PENDING TASKS FOR WORKER ASSIGNMENT, AS WELL AS A RECEIVING THREAD THAT RECEIVES COMPUTED TASK RESULTS.
utt_0119 utt 602.01 611.87 -X IN THIS SLIDE, WE SEE THAT TASK three, WHICH IS THE TASK FOR NODE three, IS AT THE FRONT OF THE PENDING TASK BUFFER AND THUS WILL BE FETCHED BY THE MAIN THREAD FIRST.
utt_0121 utt 613.40 619.96 -X SINCE NODE three HAS three00 THOUSAND ROWS, THE MAIN THREAD DECIDES THAT IT SHOULD BE PROCESSED AS COLUMN-TASKS.
utt_0123 utt 621.11 626.56 -X TASK three IS INSERTED TO A TASK TABLE THAT KEEPS TRACK OF THE CURRENT BEST SPLIT-CONDITION,
utt_0124 utt 626.81 635.13 -X AND THE COLUMN-TASKS ARE SENT TO DIFFERENT WORKERS TO OBTAIN THE BEST SPLIT-CONDITION OF INDIVIDUAL COLUMNS.
utt_0126 utt 635.22 645.40 -X ASSUME THAT A SPLIT-CONDITION IS SENT BACK, THE RECEIVING THREAD THEN UPDATES THE TABLE ENTRY FOR TASK three ACCORDING TO THAT SPLIT-CONDITION.
utt_0128 utt 645.78 656.09 -X WHEN THE LAST SPLIT-CONDITION IS RECEIVED, THE RECEIVING THREAD OBTAINS THE OVERALL BEST SPLIT-CONDITION FOR NODE three, CREATES NODE three WITH THIS CONDITION AND ADDS
utt_0130 utt 656.09 663.42 -X IT TO THE CORRESPONDING TREE UNDER CONSTRUCTION, AND REMOVES THE ENTRY FOR TASK three IN THE TASK TABLE.
utt_0132 utt 663.42 668.54 -X USING THE SPLIT-CONDITION, ROWS OF NODE three ARE PARTITIONED INTO NODE four AND NODE five,
utt_0133 utt 668.54 671.77 -X WHICH CREATES TWO NEW TASKS four AND five.
utt_0134 utt 673.31 678.01 -X SINCE NODE four HAS sixty THOUSAND ROWS WHICH IS BELOW THE eighty THOUSAND THRESHOLD, IT SHOULD
utt_0135 utt 678.39 684.93 -X BE SCHEDULED IN DFS ORDER AND IS THUS PUT TO THE FRONT OF THE PENDING TASK BUFFER.
utt_0139 utt 694.17 696.70 -X INTO THE TASK TABLE.
utt_0140 utt 696.70 700.45 -X NEXT, WE LOOK AT THE COMPONENTS INSIDE A WORKER MACHINE.
utt_0141 utt 700.45 713.73 -X THERE IS A MAIN THREAD THAT KEEPS RECEIVING THE ASSIGNED TASKS, A RECEIVING THREAD THAT RECEIVES THE REQUESTED DATA, AND A POOL OF COMPUTING THREADS THAT ARE THE ACTUAL WORKHORSE OF TASK COMPUTATION.
utt_0144 utt 713.73 718.30 -X IN THIS SLIDE, ASSUME THAT A SUB-TREE TASK FOR NODE six IS RECEIVED.
utt_0145 utt 718.94 731.55 -X THE MAIN THREAD THEN REQUESTS COLUMN DATA FROM OTHER WORKERS FOR NODE six'S ROWS, AND MEANWHILE, INSERTS AN ENTRY FOR TASK six IN THE TASK TABLE TO WAIT FOR THE DATA COLLECTION.
utt_0147 utt 731.64 735.23 -X IF THE LAST DATA RESPONSE IS RECEIVED FOR TASK six,
utt_0148 utt 736.60 746.14 -X TASK six IS THEN MOVED INTO THE TASK BUFFER WAITING FOR COMPUTATION BY AN AVAILABLE COMPUTING THREAD.
utt_0150 utt 746.87 753.50 -X AFTER A COMPUTING THREAD FETCHES TASK six AND HAS COMPUTED THE SUBTREE ROOTED AT NODE six,
utt_0151 utt 753.69 758.50 -X THIS SUBTREE IS THEN SENT BACK TO THE MASTER.
utt_0152 utt 758.50 764.58 -X SO FAR, WE HAVE NOT DISCUSSED HOW THE ROWS OF A NODE IS KEPT WITH ITS CORRESPONDING TASK,
utt_0153 utt 764.60 766.43 -X WHICH WE ADDRESS NEXT.
utt_0154 utt 767.77 773.25 -X A NAÏVE SOLUTION IS TO KEEP THE ROW INDICES WITH THE TASK OBJECTS ON THE MASTER SIDE.
utt_0155 utt 773.60 788.32 -X IN THIS SLIDE, TASK Tthree IS UNDER PROCESSING WITH ITS TASK OBJECT IN THE TASK TABLE KEEPING THE ROW INDICES FOR NODE Xthree, AND WORKERS Wone AND Wtwo CURRENTLY COMPUTING THE BEST SPLIT-CONDITIONS
utt_0157 utt 788.32 791.10 -X FOR THEIR COLUMNS.
utt_0158 utt 791.10 796.13 -X NOW ASSUME THAT BOTH WORKERS HAVE SENT BACK THEIR BEST SPLIT-CONDITIONS FOUND,
utt_0159 utt 797.21 810.78 -X THEN THE RECEIVING THREAD OF THE MASTER OBTAINS THE OVERALL BEST SPLIT CONDITION, USES IT TO GENERATE Tsix AND Tseven WITH THEIR CORRESPONDING ROW INDEX SETS, AND REMOVE Tthree FROM THE TASK
utt_0161 utt 810.78 812.29 -X TABLE.
utt_0162 utt 812.51 817.95 -X THEN ASSUME THAT Tseven IS FETCHED BY THE MAIN THREAD FOR PROCESSING,
utt_0163 utt 817.95 824.37 -X IT IS PUT INTO THE TASK TABLE ALONG WITH ITS INDICES, WHILE THE TASKS ASSIGNED FOR NODE
utt_0164 utt 824.38 828.77 -X Xseven ARE ALSO SENT ALONG WITH THE ROW INDEX SET WITH eight AND nine.
utt_0165 utt 830.11 837.02 -X HERE, SINCE Wtwo CONTAINS THE BEST SPLIT-CONDITION OF Xthree, WE CALL Wtwo AS Tthree’S DELEGATE WORKER,
utt_0166 utt 838.78 843.84 -X AND Tseven’S PARENT WORKER WHICH MEANS THE DELEGATE WORKER OF Tseven’S PARENT.
utt_0167 utt 843.84 857.22 -X WE CAN SEE THAT THE MASTER HAS TO KEEP THE ROW INDICES FOR EVERY TREE NODE, AND IT HAS TO SEND THE INDICES ALONG WITH TASK ASSIGNMENT TO WORKERS, CAUSING MASTER-SIDE COMMUNICATION
utt_0169 utt 857.22 862.85 -X BOTTLENECK THAT DELAYS THE CONTROL MESSAGES, AS WELL AS CREATING HUGE MEMORY COST AT THE MASTER.
utt_0171 utt 864.13 878.53 -X NOTE THAT SINCE Wtwo HAS THE SELECTED SPLIT-CONDITION Athree, IT KNOWS HOW TO PARTITION THE ROW INDICES INTO THOSE FOR NODES Xsix AND Xseven SO IT IS MORE REASONABLE FOR Wtwo INSTEAD OF THE MASTER, TO
utt_0173 utt 878.53 879.91 -X KEEP THE ROW INDICES FOR Xthree.
utt_0174 utt 881.76 892.26 -X MOREOVER, SINCE DIFFERENT NODES HAVE DIFFERENT DELEGATE WORKERS, THE MEMORY AND COMMUNICATION COST IS WELL DISTRIBUTED AMONG THE WORKERS.
utt_0176 utt 892.26 897.60 -X FOLLOWING THIS IDEA, OUR SOLUTION IS TO LET A CHILD TASK DIRECTLY ASK THE PARENT WORKER
utt_0177 utt 897.69 902.82 -X FOR THE ROW INDICES, SO THAT THE MASTER DOES NOT NEED TO KEEP ANY ROW INDICES.
utt_0178 utt 903.77 907.49 -X WITH THIS SCHEME, LET US FIRST CONSIDER A SUBTREE-TASK.
utt_0179 utt 908.67 915.55 -X INITIALLY, THE MASTER SENDS THE SUBTREE-TASK TO ITS SELECTED KEY WORKER WITHOUT ANY ROW INDICES.
utt_0181 utt 915.93 928.74 -X THEN, THE KEY WORKER FIRST REQUESTS THE ROW INDICES FOR THE CURRENT NODE X FROM ITS PARENT WORKER PA, SO THAT IT CAN GET THOSE ENTRIES FOR THE TARGET COLUMN OF PREDICTION WHICH IS LOCALLY LOADED.
utt_0184 utt 929.34 933.92 -X IT ALSO REQUESTS THE COLUMN DATA FOR THE ATTRIBUTES FROM OTHER WORKERS.
utt_0185 utt 934.65 948.51 -X THESE REQUESTS DO NOT CONTAIN ROW INDICES EITHER, AND THE WORKERS OBTAIN THE ROW INDICES OF NODE X BY CONTACTING THE PARENT WORKER THEMSELVES, AND GET THE COLUMN VALUES FOR THOSE ROWS BACK TO THE KEY WORKER.
utt_0188 utt 949.37 958.79 -X NOTE THAT AS SOON AS THE LAST ROW-INDEX REQUEST FOR NODE X IS RESPONDED, THE PARENT WORKER CAN RELEASE X‘S ROW INDICES FROM ITS MEMORY.
utt_0190 utt 958.79 968.80 -X AS SOON AS ALL ROW-INDEX REQUESTS OF X AND ITS SIBLING NODE ARE SERVED, THE TASK OBJECT OF PA CAN BE DELETED FROM THE PARENT WORKER’S TASK TABLE.
utt_0192 utt 970.08 982.34 -X FINALLY, SINCE THE KEY WORKER HAS GOT THE ENTIRE DATA TABLE FOR NODE X, IT CREATES THE SUBTREE ROOTED AT X AND SENDS IT BACK TO THE MASTER.
utt_0194 utt 982.59 984.52 -X NEXT CONSIDER THE COLUMN TASK.
utt_0195 utt 985.60 989.32 -X INITIALLY, THE MASTER SENDS THE COLUMN-TASKS TO THE WORKERS.
utt_0196 utt 990.46 1002.07 -X THE TASKS ARE NOT SENT WITH THE ROW INDICES, SO THE WORKERS NEED TO GET THE ROW INDICES FROM THE PARENT WORKER THEMSELVES, AND THE PARENT WORKER WILL DELETE THE OBJECT FOR THE
utt_0198 utt 1002.07 1011.52 -X PARENT NODE OF X FROM ITS TASK TABLE AS SOON AS IT SERVES THE ROW INDICES FOR THE LAST DATA REQUEST OF NODE X AND ITS SIBLING NODE.
utt_0200 utt 1011.52 1017.03 -X THEN, EACH WORKER FINDS THE BEST SPLIT-CONDITION OF ITS LOCALLY-LOADED COLUMNS FOR X'S ROWS,
utt_0201 utt 1017.22 1021.03 -X AND RETURNS THE BEST SPLIT-CONDITION BACK TO THE MASTER.
utt_0202 utt 1021.47 1034.20 -X FINALLY, THE MASTER DECIDES THE OVERALL BEST SPLIT-CONDITION FOR NODE X AND NOTIFIES THE WORKERS TO DELETE THE TASK OBJECTS FOR X THE DELEGATE WORKER OF X WILL NOT DELETE THE
utt_0204 utt 1034.20 1042.69 -X TASK OBJECT UNTIL IT HAS SERVED ALL ROW-INDEX REQUESTS OF ITS TWO CHILD-TASKS.
utt_0205 utt 1042.69 1055.14 -X THE MASTER ALSO TRACKS THE WORKLOADS OF COMMUNICATION AND COMPUTATION FOR EACH ASSIGNED TASK UNDER PROCESSING, SO THAT IT CAN ASSIGN EACH NEXT TASK TO THE PROPER WORKERS TO MINIMIZE THE LOAD IMBALANCE.
utt_0208 utt 1055.49 1059.97 -X FOR MORE DETAILS ON THE WORKER ASSIGNMENT, PLEASE REFER TO OUR PAPER.
utt_0209 utt 1061.73 1071.94 -X WE ALSO USE TREESERVER TO BUILD THE DEEP FOREST MODEL PROPOSED BY ZHIHUA ZHOU’S GROUP, WHICH CONTAINS MANY TREES TO CONSTRUCT.
utt_0211 utt 1071.94 1081.96 -X NOTABLY, EACH INTERMEDIATE FOREST LAYER HAS AN INPUT OF VERY HIGH DIMENSION WITH THOUSANDS OF DATA COLUMNS.
utt_0213 utt 1081.96 1095.88 -X TO MAKE COLUMN ASSIGNMENT EFFICIENT, WE GROUP COLUMNS INTO SMALL SUBGROUPS, AND EACH SUBGROUP IS ASSIGNED AS THE SMALLEST UNIT RATHER THAN INDIVIDUAL COLUMNS TO REDUCE THE WORKER ASSIGNMENT COMPUTATION COST.
utt_0216 utt 1096.51 1110.76 -X ON HDFS, WE ALSO OPTIMIZE OUR DATA ORGANIZATION INTO BLOCK FILES AS SHOWN IN THIS SLIDE, SO THAT WE CAN LOAD ROW PARTITIONS AND COLUMN PARTITIONS EASILY FOR PROCESSING BY DIFFERENT WORKERS IN PARALLEL.
utt_0219 utt 1111.59 1122.76 -X NOTE THAT TREE CONSTRUCTION AT EACH LAYER REQUIRES PARALLEL COLUMN PROCESSING, WHILE AFTER THE TREES ARE CONSTRUCTED, THE DATA ROWS ARE PASSED INTO THESE TREES IN PARALLEL
utt_0221 utt 1122.76 1127.53 -X FOR FEATURE RE-REPRESENTATION TO PREPARE FOR THE INPUTS TO THE NEXT LAYER.
utt_0222 utt 1129.92 1137.72 -X OUR EXPERIMENTS SHOW THAT OUR TREESERVER SYSTEM IS UP TO ten TIMES FASTER THAN EXISTING SYSTEMS
utt_0223 utt 1138.27 1145.35 -X SUCH AS SPARK MLLIB AND XGBOOST, AND IS ABLE TO CONSTRUCT LARGE DEEP FOREST MODELS EFFICIENTLY.
utt_0224 utt 1147.43 1152.10 -3.6748 THANKS FOR YOUR ATTENTION AND PLEASE FEEL FREE TO CONTACT ME IF YOU HAVE ANY QUESTIONS.
