utt_0000 utt 1.29 3.28 -X HI, MY NAME IS YUNZHU LI.
utt_0001 utt 3.34 8.94 -X TODAY WE ARE PRESENTING TO YOU OUR RECENT WORK ON VISUAL GROUNDING OF LEARNED PHYSICAL MODELS.
utt_0002 utt 9.16 19.70 -X THIS WORK IS DONE IN COLLABORATION WITH TORU LIN, KEXIN YI, DAN BEAR, DAN YAMINS, JIAJUN WU, JOSH TENENBAUM AND ANTONIO TORRALBA.
utt_0004 utt 21.01 30.45 -X UNDERSTANDING THE PHYSICAL PROPERTIES OF INTERACTING OBJECTS HAS BEEN A LONG-STANDING GOAL IN COMPUTER VISION, ROBOTICS, AND ARTIFICIAL INTELLIGENCE.
utt_0006 utt 30.93 44.27 -X AS HUMANS, BY MERELY WATCHING OBJECTS INTERACT, WE ARE ABLE TO DISTINGUISH BETWEEN DIFFERENT OBJECT INSTANCES, REASON ABOUT THEIR PHYSICAL PROPERTIES, AND MAKE PREDICTIONS ON THEIR FUTURE MOVEMENTS.
utt_0009 utt 45.20 54.58 -X MORE IMPRESSIVELY, THIS ABILITY APPLIES TO NOT ONLY RIGID BODIES, BUT ALSO DEFORMABLE OBJECTS SUCH AS ELASTIC MATERIALS AND FLUIDS.
utt_0011 utt 54.73 60.48 -X GIVEN THE EXAMPLE SHOWN IN THE VIDEOS, HUMANS CAN AUTOMATICALLY IDENTIFY THE SEPARATION
utt_0012 utt 60.53 68.08 -X BETWEEN LIQUID AND SOLID, ESTIMATE THEIR PHYSICAL PROPERTIES SUCH AS VISCOSITY, STIFFNESS, AND GRAVITY,
utt_0013 utt 68.82 73.81 -X AND PREDICT KEY FEATURES OF THEIR FUTURE MOTION THROUGH MENTAL SIMULATION.
utt_0014 utt 75.38 81.04 -X LET ME GIVE YOU AN INTUITIVE EXAMPLE, DIFFERENT PHYSICAL PARAMETERS CAN LEAD TO DRASTICALLY
utt_0015 utt 81.10 85.56 -X DIFFERENT BEHAVIORS, LIKE THE SOFTER ROPE WILL BE MORE BOUNCY.
utt_0016 utt 85.68 89.46 -X THE BOXES WILL FALL FASTER IF THE GRAVITY IS LARGER.
utt_0017 utt 90.29 97.46 -X HUMANS CAN ESTIMATE THE PHYSICAL PARAMETERS AND PREDICT THE FUTURE USING THE INTUITIVE PHYSICS ENGINE IN OUR BRAIN.
utt_0019 utt 98.07 110.07 -X IF THE PREDICTION DOES NOT MATCH THE OBSERVATION, WE CAN CORRECT OUR ESTIMATION BY MINIMIZING THE DISCREPANCY BETWEEN OUR MENTAL SIMULATION AND THE ACTUAL OBSERVATION.
utt_0021 utt 110.07 121.24 -X FOR COMPUTATIONAL SYSTEMS, PHYSICAL REASONING ON INTERACTING DEFORMABLE OBJECTS HAS BEEN A HIGHLY CHALLENGING TASK, DUE TO THE DIVERSE DYNAMICAL CHARACTERISTICS OF DIFFERENT MATERIALS
utt_0023 utt 121.39 123.06 -X AND THEIR INTERACTIONS.
utt_0024 utt 123.31 134.68 -X TAKE FLUID AS AN EXAMPLE: FLUIDS CAN DEFORM, SEPARATE, MERGE, AND OSCILLATE INTO ARBITRARY SHAPES, AND SOME ARE HARD TO PERCEIVE DUE TO THEIR TRANSPARENT NATURE.
utt_0026 utt 135.89 146.81 -X IN THIS WORK, WE EMPLOY A PARTICLE-BASED INTERMEDIATE REPRESENTATION FOR REPRESENTING OBJECTS OF DIFFERENT MATERIALS DUE TO ITS GENERALIZATION ABILITY AND FLEXIBILITY.
utt_0028 utt 148.15 157.85 -X WE PROPOSE A MODEL THAT JOINTLY ESTIMATES THEIR PHYSICAL PROPERTIES AND REFINES THE PARTICLE LOCATIONS USING A LEARNED VISUAL PRIOR AND A DYNAMIC PRIOR.
utt_0030 utt 159.00 172.22 -X OUR MODEL, NAMED VISUALLY GROUNDED PHYSICS LEARNER (VGPL), TAKES A SEQUENCE OF IMAGE FRAMES AS INPUT, REASONS ABOUT THE UNDERLYING PHYSICAL PROPERTIES, AND MAKES FUTURE PREDICTIONS.
utt_0032 utt 173.05 187.48 -X THE INPUT FRAMES FIRST GO THROUGH THE PERCEPTION MODULE, ALSO KNOWN AS THE VISUAL PRIOR, WHICH RECONSTRUCTS THE INPUT SCENE IN PARTICLE REPRESENTATION BY GIVING A PROPOSAL ON PARTICLE POSITIONS AND INSTANCE SEGMENTATION.
utt_0035 utt 188.85 200.92 -X AN INFERENCE MODULE OPERATES ON THOSE PARTICLES, PREDICTING AND REFINING ESTIMATES OF PARTICLE LOCATIONS AND THEIR PHYSICAL PARAMETERS, SUBJECT TO THE CONSTRAINTS IMPOSED BY THE DYNAMICS
utt_0037 utt 200.92 204.73 -X PRIOR, WHICH WE REFER TO AS VISUAL GROUNDING.
utt_0038 utt 205.97 212.44 -X THE DYNAMICS MODULE TAKES IN OUTPUTS FROM THE INFERENCE MODULE AND PREDICTS PARTICLE POSITIONS INTO THE FUTURE.
utt_0040 utt 213.78 221.85 -X WE EVALUATE OUR MODEL IN ENVIRONMENTS INVOLVING INTERACTIONS BETWEEN RIGID OBJECTS, ELASTIC MATERIALS, AND FLUIDS.
utt_0042 utt 223.29 237.76 -X WITHIN A FEW OBSERVATION STEPS, OUR MODEL IS ABLE TO PERFORM A DYNAMICS-GUIDED INFERENCE TO REFINE THE STATE ESTIMATION AND REASON ABOUT THE PHYSICAL PROPERTIES, WHICH ALLOWS US TO MAKE PREDICTIONS INTO THE FUTURE.
utt_0045 utt 238.46 246.40 -X NEXT, I WILL FIRST DISCUSS THE RELATED WORK AND THEN, GO THROUGH THE DETAILS OF OUR MODEL AND THE EXPERIMENTAL RESULTS.
utt_0047 utt 247.64 254.33 -X LEARNING-BASED PARTICLE DYNAMICS HAS RECENTLY GAINED ATTENTION IN PHYSICAL REASONING AND CONTROL.
utt_0049 utt 254.68 263.84 -X PARTICLES PROVIDE A DENSE AND FLEXIBLE REPRESENTATION THAT IS WELL-SUITED FOR REPRESENTING OBJECTS WITH DIVERSE MATERIAL AND DYNAMICAL PROPERTIES.
utt_0051 utt 264.15 270.85 -X PARTICLES ALSO FACILITATE RELATIONAL INDUCTIVE BIASES FOR MORE GENERALIZABLE DYNAMICS MODELING.
utt_0052 utt 273.40 281.95 -X STILL, IT REMAINS AS A QUESTION THAT HOW WELL THEY CAN HANDLE RAW VISUAL INPUTS AND ADAPT TO ENVIRONMENTS OF UNKNOWN PHYSICAL PROPERTIES.
utt_0054 utt 282.30 289.25 -X INFERENCE AND VISUAL GROUNDING OF THE ESSENTIAL PHYSICAL PROPERTIES REMAIN A CHALLENGING RESEARCH PROBLEM.
utt_0056 utt 290.91 297.06 -X OTHER PEOPLE HAVE TRIED DIFFERENTIATING THROUGH PHYSICS-BASED SIMULATORS TO EXTRACT GRADIENTS,
utt_0057 utt 297.21 302.94 -X WHICH SHOWED STRONG RESULTS IN SOLVING INVERSE PROBLEMS OF VARIOUS PHYSICAL ENVIRONMENTS.
utt_0058 utt 304.54 317.06 -X HOWEVER, THEY USUALLY MAKE STRONG ASSUMPTIONS ON THE STRUCTURE OF THE SYSTEM AND THEIR OPTIMIZATION PROCESS FOR DEALING WITH THE INVERSE PROBLEMS IS USUALLY BOTH TIME-CONSUMING AND PRONE TO LOCAL OPTIMUM.
utt_0061 utt 317.95 323.52 -X ALSO, MOST OF THEM DIRECTLY OPERATE ON THE STATE INFORMATION OF THE DYNAMICAL SYSTEMS,
utt_0062 utt 323.52 326.43 -X LACKING A WAY OF HANDLING RAW VISUAL INPUTS.
utt_0063 utt 328.64 342.43 -X OUR WORK AIMS TO BRIDGE THE PERCEPTION GAP, ENABLE PHYSICAL REASONING FROM VISUAL PERCEPTION AND PERFORM DYNAMICS-GUIDED INFERENCE TO DIRECTLY PREDICT THE OPTIMIZATION RESULTS, WHICH WILL ALLOW US
utt_0065 utt 342.43 346.27 -X QUICK ADAPTATION TO ENVIRONMENTS WITH UNKNOWN PHYSICAL PROPERTIES.
utt_0066 utt 348.29 354.13 -X TO FORMULATE THE PROBLEM, CONSIDER A SYSTEM THAT CONTAINS M OBJECTS AND N PARTICLES
utt_0067 utt 355.36 357.28 -X GIVEN THE VISUAL OBSERVATION O
utt_0068 utt 357.89 364.16 -X OUR MODEL FIRST USES A LEARNED VISUAL PRIOR FV TO OBTAIN A PROPOSAL OF THE PARTICLE POSITION
utt_0069 utt 364.51 371.33 -X Xˆ AND THE GROUPING INFORMATION Gˆ FOR EACH PARTICLE, INDICATING THE INSTANCE IT BELONGS TO.
utt_0070 utt 372.70 383.81 -X OUR MODEL ALSO INCORPORATES A LEARNED DYNAMICS PRIOR FD THAT PREDICTS FUTURE STATES BASED ON THE HISTORY OF PARTICLE POSITIONS AND PHYSICAL PROPERTIES OF THE SYSTEM.
utt_0072 utt 384.80 389.32 -X THESE PROPERTIES, INCLUDING THE RIGIDNESS OF EACH OBJECT INSTANCE Qˆ
utt_0073 utt 390.18 393.03 -X AND THE ENVIRONMENTAL PHYSICAL PARAMETERS Pˆ.
utt_0074 utt 395.04 409.67 -X THE REASON FOR MODELING THE RIGIDNESS OF THE OBJECTS IS BECAUSE ALL PARTICLES BELONGING TO A RIGID OBJECT ARE SUBJECT TO RIGID MOTION, WHEREAS WE DO NOT IMPOSE ANY CONSTRAINTS IF A PARTICLE BELONGS TO A DEFORMABLE OBJECT.
utt_0077 utt 411.27 414.73 -X BOTH P AND Q ARE INFERRED BY AN INFERENCE MODULE FI.
utt_0078 utt 415.59 429.96 -X WHICH ALSO GENERATES AN OFFSET ∆Xˆ TO REFINE THE PROPOSED PARTICLE LOCATIONS, SUCH THAT THE DYNAMICS MODEL CAN EXPLAIN THE OBSERVATIONS AND PREDICT THE PARTICLE TRAJECTORIES INTO THE FUTURE.
utt_0081 utt 430.88 442.38 -X OUR INFERENCE MODULE FI IS TUNED TO MINIMIZE THE FOLLOWING OBJECTIVE, SUBJECT TO THE CONSTRAINTS INDUCED BY THE FIXED VISUAL AND DYNAMICAL PRIORS, FV AND FD.
utt_0083 utt 442.95 446.38 -X NEXT, I WILL GO THROUGH THE DETAILS OF EACH MODULE.
utt_0084 utt 447.08 452.12 -X THE VISUAL PRIOR FV TAKES IN A SEQUENCE OF VISUAL OBSERVATION IMAGES O
utt_0085 utt 453.16 463.14 -X AND THEN PREDICTS THE POSITION OF THE PARTICLES AND THE PROBABILITY DISTRIBUTION OVER ALL OBJECT INSTANCES THAT THE PARTICLE MIGHT BELONG TO.
utt_0087 utt 465.00 471.18 -X THE VISUAL PRIOR IS TRAINED ON THE GROUND-TRUTH PARTICLE STATES ACQUIRED FROM THE PHYSICS ENGINE.
utt_0089 utt 471.27 477.35 -X THE FULL LOSS FUNCTION IS WRITTEN AS HERE WHERE H STANDS FOR THE CROSS ENTROPY LOSS.
utt_0090 utt 479.05 493.42 -X HERE WE SHOW SOME QUALITATIVE RESULTS OF OUR VISUAL PRIOR IN ENVIRONMENTS INVOLVING (one) INTERACTIONS BETWEEN FLUIDS AND RIGID OBJECTS (two) A BALL HANGING ON A ROPE, AND (three) RIGID CUBES FALLING DOWN AND COLLIDING WITH EACH OTHER
utt_0094 utt 498.57 508.87 -X AS FOR THE DYNAMICS PRIOR, THE POSITIONS OF THE PARTICLES X DEFINE A POINT CLOUD THAT INDICATES THE SPATIAL SPAN OF THE OBJECTS IN THE ENVIRONMENT.
utt_0096 utt 509.22 514.41 -X THE PARTICLES FORM GROUPS G TO REPRESENT DIFFERENT OBJECT INSTANCES.
utt_0097 utt 516.10 524.14 -X EACH PARTICLE HAS A BINARY RIGIDITY LABEL Q THAT INDICATES WHETHER THE OBJECT IT BELONGS TO IS A RIGID BODY.
utt_0099 utt 524.36 528.56 -X RIGID OBJECTS WILL BE CONSTRAINED TO ONLY EXERT RIGID MOTIONS.
utt_0100 utt 529.26 535.44 -X FINALLY, THE ENVIRONMENT ALSO HAS A SET OF REAL-VALUED PHYSICAL PARAMETERS P, E.G., VISCOSITY,
utt_0101 utt 535.44 537.32 -X GRAVITY, STIFFNESS, ETC.
utt_0102 utt 538.34 544.30 -X SPECIFICALLY, WE USE THE DYNAMIC PARTICLE INTERACTION NETWORK (DPI-NET) (LI ET AL., two thousand and nineteen)
utt_0103 utt 544.30 553.20 -X TO PERFORM DYNAMICAL UPDATE ON THE PARTICLE STATE USING GRAPH NEURAL NETWORKS AND SPATIAL MESSAGE PASSING.
utt_0105 utt 553.20 558.06 -X HERE WE SHOW SOME QUALITATIVE RESULTS OF OUR DYNAMICS PRIOR IN VARIOUS ENVIRONMENTS.
utt_0106 utt 562.86 571.50 -X THE KEY STEP OF GROUNDING A LEARNED DYNAMICS MODEL TO VISUAL INPUTS IS TO INFER THE PHYSICAL PROPERTIES UNDERLYING THE OBSERVED SYSTEM
utt_0108 utt 572.75 578.77 -X IN OUR CASE, THE RIGIDNESS OF THE OBJECTS Q, AND THE ENVIRONMENTAL PHYSICAL PARAMETERS P.
utt_0109 utt 579.85 588.21 -X WE APPLY AN INFERENCE MODULE FI TO PREDICT THESE PROPERTIES FROM THE OBSERVED PARTICLE PROPOSALS GENERATED BY THE VISUAL PRIOR.
utt_0111 utt 589.64 594.32 -X THE MODULE ALSO OUTPUTS REFINEMENT ON THE PARTICLES’ POSITIONS ∆Xˆ.
utt_0112 utt 595.08 602.45 -X THE INFERENCE MODULE FI IS ALSO A VARIANT OF GRAPH NEURAL NETWORKS THAT AGGREGATE BOTH SPATIAL AND TEMPORAL INFORMATION.
utt_0114 utt 602.80 609.39 -X PLEASE REFER TO OUR PAPER FOR MORE DETAILS OF THE MODEL.
utt_0115 utt 609.39 624.14 -X NEXT WE WILL PRESENT THE EXPERIMENTAL RESULTS IN THE FOLLOWING THREE ENVIRONMENTS, WHERE WE AIM TO INVESTIGATE HOW ACCURATE THE FOLLOWING ESTIMATIONS ARE AND WHETHER THEY HELP WITH FUTURE PREDICTION: (one) RIGIDNESS ESTIMATION
utt_0118 utt 624.14 627.31 -X (two) PARAMETER ESTIMATION (three) POSITION REFINEMENT
utt_0119 utt 629.49 635.03 -X WE FIRST SHOW THE RESULTS ON PREDICTED PARTICLE POSITIONS AFTER twenty TIME STEPS.
utt_0120 utt 635.05 646.55 -X HERE, WE COMPARE THE GROUND TRUTH WITH THE RESULTS OF OUR MODEL, TOGETHER WITH A VERSION WITHOUT RIGIDNESS ESTIMATION.
utt_0122 utt 646.55 651.35 -X FROM THE VIDEOS, WE CAN SEE THAT WITHOUT PROPER ESTIMATION OF THE RIGIDNESS,
utt_0123 utt 651.35 661.43 -X (A) THE RIGID CUBE MELTS INTO THE FLUIDS AND (B) IN THE BOX FALLING ENVIRONMENT, THE RIGID CUBE SCATTERS OR DISTORTS.
utt_0124 utt 669.87 675.76 -X HERE WE SHOW THE QUANTITATIVE RESULTS OF OUR MODEL’S PERFORMANCE ON ESTIMATING THE RIGIDNESS
utt_0125 utt 675.79 678.71 -X IN THE ROPE ENVIRONMENT AND THE FLUID ENVIRONMENT.
utt_0126 utt 679.09 692.12 -X THE INFERENCE MODULE WAS TRAINED ON INPUTS WITH ONLY ten TIME STEPS, SHOWN HERE USING THE ORANGE DASHED LINE, BUT THE MODEL CAN EXTRAPOLATE TO BOTH SHORTER AND LONGER INPUT SEQUENCE.
utt_0128 utt 692.66 698.52 -X LONGER OBSERVATION SEQUENCE LEADS TO HIGHER ACCURACY, WHICH IS IN LINE WITH OUR INTUITION.
utt_0129 utt 700.50 703.83 -X NEXT, WE SHOW THE RESULTS ON PARAMETER ESTIMATION.
utt_0130 utt 703.83 717.21 -X AGAIN, THE VIDEO SHOWS THE RESULTS ON PREDICTED PARTICLE POSITIONS INTO THE FUTURE BY COMPARING THE GROUND TRUTH WITH THE RESULTS OF OUR MODEL, TOGETHER WITH A VERSION WITHOUT PARAMETER ESTIMATION.
utt_0132 utt 720.59 727.35 -X AS CAN BE SEEN FROM THE VIDEO, IF THE MODEL DOES NOT PROPERLY ESTIMATE THE PARAMETERS,
utt_0133 utt 727.35 730.52 -X THE CUBES EITHER FALL TOO FAST OR TOO SLOW.
utt_0134 utt 730.87 734.71 -X THE ROPE EITHER CONTRACTS TOO MUCH OR TOO LITTLE.
utt_0135 utt 742.64 752.34 -X HERE, WE COMPARE OUR MODEL WITH DENSEPHYSNET (XU ET AL., two thousand and nineteen) AND ANOTHER MODEL WHOSE DYNAMICS PRIOR DOES NOT IMPOSE ANY CONSTRAINTS FOR RIGID BODY MOTION.
utt_0137 utt 752.85 759.64 -X WE MEASURE THE PERFORMANCE USING THE MEAN ABSOLUTE ERROR BETWEEN EACH MODELS PREDICTION AND THE GROUND TRUTH.
utt_0139 utt 760.12 764.38 -X NUMBERS IN PARENTHESES REPORT THE STANDARD DEVIATION.
utt_0140 utt 766.96 770.01 -X THE THIRD PART IS THE PERFORMANCE ON POSITION REFINEMENT.
utt_0141 utt 770.13 776.63 -X THE VIDEOS SHOW THE QUALITATIVE RESULTS ON PREDICTING THE FUTURE WITH AND WITHOUT THE POSITION REFINEMENT.
utt_0143 utt 783.70 792.83 -X PARTICLE POSITIONS PROPOSED BY THE VISUAL PRIOR, SHOWN USING THE BLUE BAR, AND AFTER REFINEMENT
utt_0144 utt 793.40 797.59 -X USING OUR INFERENCE MODULE, SHOWN AS ORANGE BARS.
utt_0146 utt 802.87 803.71 -X THE EVALUATION METRIC.
utt_0147 utt 803.71 806.78 -X IN ALL ENVIRONMENTS, THE MEAN SQUARED ERROR DECREASES AFTER REFINEMENT.
utt_0148 utt 806.97 813.15 -X FINALLY, WE SHOW THE MEAN SQUARED ERROR BETWEEN THE FUTURE PREDICTIONS OF THE PARTICLE POSITIONS
utt_0149 utt 813.56 816.60 -X AND THE GROUND TRUTH ON ALL ENVIRONMENTS.
utt_0153 utt 832.54 839.93 -X SIMULTANEOUSLY REASON ABOUT PHYSICS AND MAKE FUTURE PREDICTIONS BASED ON VISUAL AND DYNAMICS PRIORS.
utt_0156 utt 844.48 844.96 -X AND FLUIDS.
utt_0157 utt 845.30 854.05 -X EXPERIMENTS SHOW THAT OUR MODEL CAN INFER THE PHYSICAL PROPERTIES WITHIN A FEW OBSERVATION STEPS,
utt_0158 utt 854.87 861.66 -X WHICH ALLOWS THE MODEL TO QUICKLY ADAPT TO UNSEEN SCENARIOS AND MAKE ACCURATE PREDICTIONS INTO THE FUTURE.
