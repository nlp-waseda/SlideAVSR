utt_0000 utt 0.26 6.70 -X WELCOME, THIS IS THE CVPR two thousand and twenty-one PRESENTATION ON OUR PAPER “HOW WELL DO SELF-SUPERVISED MODELS TRANSFER?”
utt_0002 utt 6.83 11.92 -X THIS WORK WAS COMPLETED BY MYSELF: LINUS ERICSSON, HENRY GOUK AND TIMOTHY M. HOSPEDALES.
utt_0003 utt 12.17 15.25 -X I’LL START BY DESCRIBING A STANDARD SUPERVISED PIPELINE.
utt_0004 utt 15.28 23.12 -X GIVEN A DATASET OF IMAGES, HUMAN ANNOTATORS OFTEN SPEND THOUSANDS OF HOURS MANUALLY CREATING LABELS WHICH A MODEL THEN CAN BE TRAINED TO PREDICT.
utt_0006 utt 23.12 29.68 -X THIS PIPELINE LIMITS THE NUMBER OF IMAGES THAT CAN BE USED IN TRAINING AS THE ANNOTATION PROCESS IS SLOW AND EXPENSIVE.
utt_0008 utt 29.68 36.40 -X SELF-SUPERVISED LEARNING ATTEMPTS TO SOLVE THESE PROBLEMS BY INSTEAD AUTOMATICALLY GENERATING PSEUDO-LABELS FROM THE STRUCTURE OF THE DATA.
utt_0010 utt 36.40 42.93 -X THIS CAN ALLOW USING MORE IMAGES FOR TRAINING WHILE STILL MAINTAINING THE POWERFUL DISCRIMINATIVE FRAMEWORK OF SUPERVISED LEARNING.
utt_0012 utt 43.02 51.86 -X AFTER TRAINING, THE REPRESENTATIONS CAN BE TRANSFERRED TO NEW TASKS AND DOMAINS, THEREBY REDUCING THE NEED FOR LARGE AMOUNTS OF LABELLED DATA IN DOWNSTREAM TRAINING.
utt_0014 utt 51.86 61.85 -X IN THE PAST COUPLE OF YEARS, SELF-SUPERVISED METHODS HAVE IMPROVED SIGNIFICANTLY AND NOW APPROACH SUPERVISED PERFORMANCE ON THE STANDARD IMAGENET BENCHMARK, WHEN USING IDENTICAL ARCHITECTURE.
utt_0016 utt 61.85 68.98 -X DESPITE STILL BEING BEHIND ON IMAGENET, THERE HAS BEEN INITIAL EVIDENCE THAT SELF-SUPERVISED MODELS TRANSFER BETTER TO NEW TASKS.
utt_0018 utt 68.98 79.13 -X IN THIS WORK, WE STUDY THIS TRANSFER PERFORMANCE OF SELF-SUPERVISED PRE-TRAINED MODELS, TRYING TO ANSWER THE FOLLOWING QUESTIONS: HOW DOES SELF-SUPERVISED TRANSFER COMPARE TO SUPERVISED TRANSFER?
utt_0021 utt 79.16 81.88 -X IS THERE A BEST SELF-SUPERVISED METHOD OVERALL?
utt_0022 utt 81.97 85.43 -X HAS THE COMMUNITY OVERFIT TO IMAGENET AS A BENCHMARK?
utt_0023 utt 85.43 91.07 -X AND, DO SELF-SUPERVISED AND SUPERVISED FEATURES REPRESENT THE SAME INFORMATION?
utt_0024 utt 91.07 97.27 -X TO ANSWER THESE QUESTIONS, WE OBTAINED thirteen PRE-TRAINED SELF-SUPERVISED MODELS, ALONG WITH A SUPERVISED BASELINE.
utt_0026 utt 97.27 106.88 -X ALL MODELS USE THE SAME RESNETfifty ARCHITECTURE, AND WERE PRE-TRAINED ON IMAGENET BY THE ORIGINAL AUTHORS WITHOUT USING ANY LABELS, APART FROM THE SUPERVISED MODEL.
utt_0028 utt 106.88 114.46 -X DIFFERENCES IN MODELS STEM FROM THEIR TRAINING OBJECTIVES AND HYPERPARAMETER DETAILS LIKE EPOCHS, BATCH SIZE AND DATA AUGMENTATION.
utt_0030 utt 114.58 124.93 -X OUR TRANSFER EVALUATION COVERS A WIDE RANGE OF TASKS, INCLUDING MANY-SHOT AND FEW-SHOT RECOGNITION, OBJECT DETECTION, SURFACE NORMAL ESTIMATION AND SEMANTIC SEGMENTATION.
utt_0032 utt 125.02 133.89 -X THE DATASETS WE USE EXHIBIT A WIDE RANGE OF SIMILARITY TO THE SOURCE IMAGENET DATA, FROM THE VERY SIMILAR CIFARten TO THE VERY DIFFERENT MEDICAL X-RAY IMAGES.
utt_0034 utt 134.04 135.81 -X NOW WE PRESENT OUR RESULTS.
utt_0035 utt 135.87 140.26 -X ON THE X-AXIS WE PLOT THE IMAGENET ACCURACY OF THE PRE-TRAINED MODEL.
utt_0036 utt 140.35 145.22 -X AND ON THE Y-AXIS THE AVERAGE LOGIT-TRANSFORMED TRANSFER PERFORMANCE.
utt_0037 utt 145.47 156.67 -X IN ADDITION TO COVERING DIFFERENT TASKS AND DATASETS, WE ALSO LOOK AT BOTH LINEAR EVALUATION AND FINETUNING IN THE MANY-SHOT SETTING, SMALL DOMAIN SHIFT AND LARGE DOMAIN SHIFT IN THE
utt_0039 utt 156.67 167.55 -X FEW-SHOT SETTING, OBJECT DETECTION FROM A FROZEN AND FINETUNED BACKBONE AND FINALLY OUR TWO DENSE PREDICTION TASKS OF SURFACE NORMAL ESTIMATION AND SEMANTIC SEGMENTATION.
utt_0041 utt 167.65 170.95 -X WITH THESE RESULTS WE CAN ANSWER SOME OF OUR EARLIER QUESTIONS.
utt_0042 utt 170.95 176.71 -X WE FIRST LOOK AT HOW THE SELF-SUPERVISED MODELS COMPARE TO THE SUPERVISED BASELINE REPRESENTED BY THE GREEN STAR.
utt_0044 utt 176.71 183.17 -X ACROSS ALL BUT ONE SETTING, SELF-SUPERVISED MODELS OUTPERFORM SUPERVISION, SHOWING THEIR SUPERIOR TRANSFER ABILITY.
utt_0046 utt 183.17 191.37 -X BUT, THERE IS NO SINGLE MODEL THAT DOMINATES ALL SETTINGS, SHOWING THE COMMUNITY STILL HAS A WAY TO GO TO REACH TRULY GENERAL FEATURES.
utt_0048 utt 191.37 195.37 -X TO ANSWER OUR THIRD QUESTION WE LOOK AT THE CORRELATIONS IN OUR RESULTS.
utt_0049 utt 195.37 210.18 -X WE FIND THAT IMAGENET PERFORMANCE IS HIGHLY CORRELATED WITH MANY-SHOT RECOGNITION IN BOTH THE LINEAR AND FINETUNED SETTINGS, BUT THE CORRELATION IS WEAKER AND WEAKER AS WE LOOK AT FEW-SHOT RECOGNITION, OBJECT DETECTION AND THE TWO DENSE PREDICTION TASKS.
utt_0052 utt 210.18 218.06 -X THIS SHOWS THAT IN ORDER TO ACHIEVE MORE GENERALISABLE REPRESENTATIONS IN THE FUTURE, THE COMMUNITY NEEDS TO CONSIDER WIDER BENCHMARKS FOR EVALUATION.
utt_0054 utt 218.47 222.54 -X NEXT, WE LOOK AT THE PROPERTIES OF THE FEATURES PRODUCED BY THE MODELS.
utt_0055 utt 222.54 226.76 -X WE FIND THAT THE SUPERVISED BASELINE CAN BETTER RECONSTRUCT IMAGES FROM ITS FEATURE VECTORS,
utt_0056 utt 226.76 231.69 -X AND PART OF THE REASON IS THAT SELF-SUPERVISED MODELS TEND TO LOSE COLOUR INFORMATION,
utt_0057 utt 231.72 235.47 -X LIKELY DUE TO THE HEAVY DATA AUGMENTATION USED DURING TRAINING.
utt_0058 utt 235.47 243.02 -X THE SELF-SUPERVISED MODELS ALSO HAVE A WIDER ATTENTIVE FOCUS, IN CONTRAST TO THE HIGH SPATIAL FOCUS OF THE SUPERVISED BASELINE.
utt_0060 utt 243.05 251.31 -X FINALLY, WE FIND THAT MODELS TRAINED THROUGH SELF-SUPERVISION TEND TO PRODUCE BETTER CALIBRATED CLASSIFIERS FOR DOWNSTREAM RECOGNITION TASKS.
utt_0062 utt 251.85 260.37 -X TO CONCLUDE, IN THIS PAPER WE HAVE CONDUCTED THE FIRST THOROUGH AND UP-TO-DATE EMPIRICAL EVALUATION OF STATE-OF-THE-ART SELF-SUPERVISED TRANSFER.
utt_0064 utt 260.37 265.17 -X WE HAVE FOUND THAT THE BEST SELF-SUPERVISED MODELS USUALLY TRANSFER BETTER THAN SUPERVISION,
utt_0065 utt 265.17 270.83 -X BUT THE BEST MODEL CHOICE DEPENDS ON THE DOWNSTREAM TASK IN QUESTION, AS NO MODEL DOMINATES OVERALL.
utt_0066 utt 270.89 276.46 -X IMAGENET PERFORMANCE IS NOT RELIABLY REPRESENTATIVE OF NON-RECOGNITION TASKS OR UNSTRUCTURED DATA,
utt_0067 utt 276.49 283.18 -X MEANING THAT RESEARCHERS SHOULD ADOPT A WIDER RANGE OF BENCHMARKS TO BETTER IMPACT THE BROADER COMPUTER VISION COMMUNITY.
utt_0069 utt 283.18 287.76 -X FINALLY, SELF-SUPERVISED FEATURES TEND TO: DISCARD COLOUR INFORMATION,
utt_0070 utt 287.76 291.38 -X ATTEND TO WIDER REGIONS OF THE IMAGE WHEN MAKING DECISIONS,
utt_0071 utt 291.38 299.28 -X AND HAVE BETTER UNCERTAINTY CALIBRATION FOR RECOGNITION TASKS THANK YOU FOR LISTENING AND PLEASE FIND OUR FULL PAPER AND CODEBASE THROUGH THESE LINKS.
