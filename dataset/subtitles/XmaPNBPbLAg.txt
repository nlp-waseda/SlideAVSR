utt_0000 utt 1.07 6.00 -X HI, I’M YOUNG-HO KIM, A RESEARCH SCIENTIST AT NAVER AI LAB.
utt_0001 utt 6.35 15.06 -X I WILL INTRODUCE OUR PROJECT ON LEVERAGING PRE-TRAINED LANGUAGE MODELS TO STREAMLINE NATURAL LANGUAGE INTERACTION FOR SELF-TRACKING.
utt_0003 utt 15.06 18.07 -X THIS WORK WAS DONE IN COLLABORATION WITH MY COLLEAGUES,
utt_0004 utt 18.07 21.20 -X SUNGDONG KIM, MINSUK CHANG, AND SANG-WOO LEE.
utt_0005 utt 23.37 28.21 -X SELF-TRACKING IS A PREVALENT PRACTICE WITH LONG HISTORY.
utt_0006 utt 28.21 33.36 -X PEOPLE OFTEN KEEP JOURNALS TO RECORD THEIR ACTIVITIES AND REFLECT ON THEIR PAST DAYS,
utt_0007 utt 33.65 39.73 -X OR TO TRACK HABITUAL BEHAVIORS VISUALLY.
utt_0008 utt 39.73 49.43 -X SELF-TRACKING CAN BE DEFINED AS A SYSTEMATIC AND ITERATIVE PROCESS OF COLLECTING, EXPLORING, AND REFLECTING ON THE PERSONAL HEALTH/ACTIVITY DATA.
utt_0010 utt 50.58 57.88 -X THIS RESEARCH PARTICULARLY FOCUSES ON THE DATA COLLECTION ASPECT OF SELF-TRACKING.
utt_0011 utt 57.88 66.07 -X NOWADAYS WE SEE MANY DIGITAL TOOLS FOR SELF-TRACKING, WHICH LISTEN TO NATURAL LANGUAGE QUERIES DESCRIBING ACTIVITY LOGS.
utt_0012 utt 66.90 71.38 -X FOR EXAMPLE, WE CAN LOG OUR WATER INTAKE ON A SMART SPEAKER,
utt_0013 utt 72.15 75.51 -X OR RECORD PHYSICAL ACTIVITY ON A SMARTWATCH.
utt_0014 utt 77.87 83.19 -X IT IS IMPORTANT TO BE ABLE TO EXTRACT STRUCTURED DATA POINTS FROM NATURAL LANGUAGE QUERIES,
utt_0015 utt 83.44 96.28 -X BECAUSE THESE DATA CAN BE FURTHER USED FOR VARIOUS COMPONENTS OF SELF-TRACKING, INCLUDING DATA VISUALIZATION, CONTEXTUALIZED INTERVENTION, OR EVEN SHARING DATA AMONG DIFFERENT PLATFORMS.
utt_0017 utt 98.39 107.26 -X UNFORTUNATELY, THE EXISTING SELF-TRACKING SYSTEMS LARGELY DEPEND ON BESPOKE AND RULE-BASED NATURAL LANGUAGE UNDERSTANDING.
utt_0018 utt 107.26 110.84 -X FOR EXAMPLE, GIVEN AN NLU FOR FOOD TRACKING,
utt_0019 utt 111.16 114.97 -X THE SYSTEM MAY NOT UNDERSTAND QUERIES FOR PRODUCTIVITY.
utt_0020 utt 115.22 122.20 -X WE NEED A NEW IMPLEMENTATION THAT EXPANDS RULES TO COVER A NEW TOPIC.
utt_0021 utt 122.20 129.27 -X IN ADDITION, EXISTING APPROACHES ARE USUALLY NOT ROBUST TO INDIVIDUALIZED PHRASING PATTERNS,
utt_0022 utt 129.46 133.56 -X ESPECIALLY IF THE PATTERN IS OUT OF THE DEVELOPER’S ANTICIPATION.
utt_0023 utt 136.44 141.44 -X ALTHOUGH NEURAL-NETWORK-BASED MODELS TEND TO WORK NICELY FOR MANY NLP TASKS,
utt_0024 utt 141.69 145.47 -X TRAINING MODELS IN THE SELF-TRACKING CONTEXT IS NOT EASY.
utt_0025 utt 146.68 150.33 -X THERE EXIST A NUMBER OF DIFFERENT TOPICS IN SELF-TRACKING,
utt_0026 utt 150.68 155.20 -X AS WELL AS A WIDE VARIETY OF DATA SCHEMAS FOR EACH TOPIC.
utt_0027 utt 155.96 159.90 -X CONSIDERING NUMEROUS DIFFERENT INSTANCES OF NL QUERIES,
utt_0028 utt 160.44 164.73 -X IT IS OVERWHELMING TO COLLECT A SUFFICIENT AMOUNT OF TRAINING DATASET.
utt_0029 utt 167.03 171.49 -X SO IN THIS WORK, WE AIMED TO BUILD A UNIFIED NLP FRAMEWORK
utt_0030 utt 171.67 175.74 -X THAT CAN UNDERSTAND NATURAL LANGUAGE QUERIES IN A BROAD RANGE OF TOPICS,
utt_0031 utt 176.22 180.22 -X BE EASILY PERSONALIZED TO INDIVIDUALIZED PHRASING PATTERNS,
utt_0032 utt 180.79 183.68 -X AND THAT WE CAN BUILD WITHOUT A LOT OF TRAINING DATASET.
utt_0033 utt 186.36 190.66 -X HERE WE INTRODUCE A NOVEL NLP TASK FOR UNDERSTANDINGSELF-TRACKING QUERIES.
utt_0034 utt 191.96 195.26 -X GIVEN A NATURAL LANGUAGE QUERY AND A DATA SCHEMA,
utt_0035 utt 196.28 199.87 -X THE NLU SHOULD EXTRACT A SUBSET OF FIELD VALUES.
utt_0036 utt 200.51 206.24 -X IN THIS EXAMPLE, THE QUERY SPECIFIES TWO OF THE THREE DATA FIELDS OF THE SCHEMA.
utt_0037 utt 208.89 215.87 -X TO EFFECTIVELY RESOLVE THE TASK, WE INCORPORATED PRE-TRAINED, LARGE-SCALE LANGUAGE MODELS SUCH AS GPTminus three.
utt_0038 utt 216.96 220.61 -X AS THESE MODELS HAVE LEARNED A BROAD SPACE OF COMMON SENSE,
utt_0039 utt 220.67 224.77 -X EGOCENTRIC PHRASES, OR SYNONYMS FOR MANY KEYWORDS,
utt_0040 utt 224.93 228.48 -X THEIR KNOWLEDGE IS RELEVANT TO SELF-TRACKING SCENARIOS.
utt_0041 utt 229.53 234.66 -X HERE IS AN ANATOMY OF ZERO-SHOT LEARNING OF THE TASK ON GPTminus three.
utt_0042 utt 235.65 239.72 -X WE FEED THE DATA SCHEMA AND THE INPUT QUERY TO GPTminus three,
utt_0043 utt 240.19 242.37 -X TO EXTRACT THE STRUCTURED DATA.
utt_0044 utt 244.35 247.01 -X SINCE SELF-TRACKING IS AN ITERATIVE PROCESS,
utt_0045 utt 247.01 249.12 -X FOR THE SECOND DATA ENTRY,
utt_0046 utt 249.25 252.74 -X THE SYSTEM CAN USE THE PRIOR LOG AS ONE-SHOT SAMPLE.
utt_0047 utt 254.27 258.53 -X THE MODEL MAY BECOME MORE ROBUST AS THE USER HAS MORE EXAMPLES.
utt_0048 utt 258.85 262.57 -X BUT IT MAY NOT PERFORM WELL WHEN THERE ARE NO PRIOR ENTRIES.
utt_0049 utt 265.54 272.84 -X OUR MAIN IDEA IS TO TRANSFORM THE TARGET TASK INTO ten-SHOT LEARNING, USING SYNTHETIC SOURCE SAMPLES.
utt_0050 utt 273.70 278.98 -X THESE SAMPLES CONSIST OF SYNTHESIZED ENTRIES IN VARIOUS SELF-TRACKING TOPICS.
utt_0051 utt 279.27 288.81 -X FOR EXAMPLE, THE SYSTEM GRABS eight SAMPLES FROM THE SOURCE INVENTORY TO COMPLEMENT THE USER SAMPLES, TO GUARANTEE ten EXAMPLES IN A PROMPT.
utt_0053 utt 290.72 293.00 -X TO CREATE SYNTHETIC SOURCE SAMPLES,
utt_0054 utt 293.51 297.67 -X WE FIRST MANUALLY CREATED twenty-four SEED TRACKING SCHEMAS
utt_0055 utt 297.70 301.42 -X REFERRING TO THE SELF-TRACKING LITERATURE AND APP SURVEYS.
utt_0056 utt 303.78 307.82 -X WE THEN RANDOMLY GENERATED five hundred and four SAMPLE INSTANCES IN THESE SCHEMAS.
utt_0057 utt 309.00 313.93 -X AFTER GENERATING NATURAL LANGUAGE QUERIES THAT DESCRIBE THESE INSTANCES USING GPTminus three,
utt_0058 utt 315.17 320.33 -X WE INSPECTED EACH CASE AND CORRECTED MISMATCHES BETWEEN THE QUERY AND THE INSTANCE.
utt_0059 utt 323.14 325.77 -X TO ASSESS THE EFFECT OF PROMPT AUGMENTATION,
utt_0060 utt 326.05 330.28 -X WE CONDUCTED A PRELIMINARY EVALUATION USING THE SOURCE SAMPLES.
utt_0061 utt 331.81 336.94 -X WE EXTRACTED ONE DATA SCHEMA AT A TIME AND TREATED IT AS A USER SCHEMA.
utt_0062 utt 339.08 342.99 -X WE THEN ITERATED OVER EACH SAMPLE AS A TEST CASE,
utt_0063 utt 343.21 346.89 -X TREATING OTHER SAMPLES AS PRIOR ENTRIES OF THE USER.
utt_0064 utt 348.97 356.40 -X AS BASELINES, WE TESTED PURE ZERO-SHOT LEARNING WITH NEITHER PRIOR ENTRIES NOR PROMPT AUGMENTATION.
utt_0065 utt 357.00 358.86 -X AS IN-CONTEXT LEARNING CASES,
utt_0066 utt 359.27 363.60 -X WE TESTED FIVE DIFFERENT SCENARIOS WITH PROMPT AUGMENTATION,
utt_0067 utt 364.17 367.44 -X FROM ZERO TO FOUR PRIOR ENTRIES OF THE USER.
utt_0068 utt 369.13 373.13 -X THESE SETTINGS SIMULATE A USER COLLECTING DATA OVER TIME.
utt_0069 utt 375.27 384.56 -X WE INVESTIGATED THE JOINT GOAL ACCURACY AND Fminus one SCORE FOR CLOSE-ENDED FIELDS SUCH AS NUMBERS, SHORT-FORM TEXTS, OR MULTIPLE CHOICES.
utt_0071 utt 384.56 392.82 -X FOR BOTH METRICS, THE PROMPT AUGMENTATION SIGNIFICANTLY BOOSTED THE PERFORMANCE EVEN IN ZERO-SHOT.
utt_0073 utt 394.41 397.55 -X ALSO, THE PERFORMANCE TENDED TO INCREASE
utt_0074 utt 397.61 400.02 -X WITH A FEW MORE PRIOR EXAMPLES.
utt_0075 utt 402.57 410.10 -X FOR OPEN-ENDED TEXT FIELDS, WE CALCULATED BLEUminus four AND ROUGE-L SCORES AS PERFORMANCE METRICS.
utt_0076 utt 411.95 417.39 -X WE OBSERVED THE SIMILAR BOOST IN PERFORMANCE AS THE CLOSE-ENDED FIELDS.
utt_0077 utt 419.63 424.02 -X NOW WE’LL DISCUSS THE RESULTS FOCUSING ON HOW HCI CAN PLAY THE ROLE.
utt_0078 utt 426.89 429.65 -X ALTHOUGH OUR APPROACH SHOWED PROMISING OUTCOMES,
utt_0079 utt 429.68 432.72 -X THE JOINT GOAL ACCURACY INDICATES THAT
utt_0080 utt 432.88 437.75 -X MORE THAN ONE-THIRD OF THE TRIES MAY CONTAIN ERRONEOUS PARTIAL RESULTS.
utt_0081 utt 438.42 441.17 -X APART FROM IMPROVING THE MODEL PERFORMANCE,
utt_0082 utt 441.33 447.32 -X WE SHOULD CONSIDER INVOLVING USER INTERACTION METHODS TO ADDRESS THE ERRONEOUS CASES,
utt_0084 utt 447.60 449.88 -X SINCE THERE ARE NO one hundred% PERFECT MODELS.
utt_0085 utt 450.93 458.07 -X FOR EXAMPLE, ERROR RECOVERY INTERACTION METHODS SUCH AS ROLL-BACK BUTTONS ARE REQUIRED FOR USER INTERFACES.
utt_0087 utt 459.70 463.27 -X ALSO, WE CAN MAKE THE SYSTEM NUDGE THE USER
utt_0088 utt 463.63 472.41 -X TO PROVIDE SEVERAL EXAMPLE QUERIES BEFORE THE FIRST USE OF A DATA SCHEMA, FOR CALIBRATION.
utt_0090 utt 472.41 476.53 -X WE NOTE THAT THE PROPOSED TASK CAN BE ADDRESSED BY MULTI-TURN CONVERSATION,
utt_0091 utt 476.85 481.69 -X BECAUSE IT IS AN EXTENDED FORM OF DIALOG STATE TRACKING.
utt_0092 utt 481.69 488.95 -X WE MAY DESIGN A CONVERSATIONAL AGENT TO GUIDE THE USER FILLING OUT THE INFORMATION ACCORDING TO THE DATA SCHEMA.
utt_0095 utt 488.95 493.59 -X WHEN THE USER PROVIDES ONLY PARTIAL INFORMATION OF THE SCHEMA,
utt_0096 utt 494.55 498.71 -X THE AGENT MAY ASK BACK TO PROVIDE THE REST OF THE INFORMATION.
utt_0097 utt 499.48 503.06 -X SUCH AN APPROACH WOULD BE EFFECTIVE FOR VOICE UIS.
utt_0098 utt 504.76 506.71 -X NOW I’LL SUMMARIZE THIS WORK.
utt_0099 utt 507.44 512.54 -X IN THIS WORK, WE INTRODUCED A NOVEL NLP TASK FOR SELF-TRACKING,
utt_0100 utt 512.54 514.97 -X ALONG WITH A FRAMEWORK THAT SOLVES THE TASK.
utt_0101 utt 515.93 523.64 -X THE PRELIMINARY EVALUATION SUGGESTED THAT AUGMENTING PROMPTS USING SYNTHETIC SAMPLES CAN BOOST UP THE TASK PERFORMANCE.
utt_0103 utt 524.25 529.37 -X AND THE PERFORMANCE TENDED TO INCREASE WITH MORE PAST ENTRIES OF THE USER.
utt_0104 utt 530.17 538.24 -X IN CLOSING, WE CALL FOR BOTH NLP AND HCI RESEARCHERS TO COLLABORATE IN THE FIELD OF SELF-TRACKING
utt_0105 utt 538.26 544.19 -X TO DESIGN EFFECTIVE NATURAL LANGUAGE INTERACTIONS WHICH ARE BOTH PERFORMANT AND USABLE.
utt_0106 utt 544.19 548.35 -X FOR MORE INFORMATION, PLEASE REFER TO OUR PAPER.
utt_0107 utt 548.35 550.52 -3.2273 THANK YOU FOR LISTENING TO THIS TALK.
