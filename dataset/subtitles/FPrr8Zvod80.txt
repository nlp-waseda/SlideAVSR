utt_0000 utt 0.97 4.46 -X HI, I AM SHIZHE, I AM A POSTDOC RESEARCHER AT INRIA.
utt_0001 utt 4.46 14.26 -X I WILL PRESENT OUR WORK “THINK GLOBAL, ACT LOCAL: DUAL-SCALE GRAPH TRANSFORMER FOR VISION-AND-LANGUAGE NAVIGATION”.
utt_0003 utt 14.26 24.40 -X VISION-AND-LANGUAGE NAVIGATION (VLN FOR SHORT) AIMS TO TRAIN AUTONOMOUS AGENTS THAT CAN FOLLOW NATURAL LANGUAGE INSTRUCTIONS TO NAVIGATE IN REALISTIC ENVIRONMENTS.
utt_0005 utt 26.03 29.43 -X INITIAL VLN WORKS MAINLY USE FINE-GRAINED INSTRUCTIONS.
utt_0006 utt 29.87 35.22 -X SUCH STEP-BY-STEP INSTRUCTIONS ARE CUMBERSOME AND LESS PRACTICAL IN REAL LIFE.
utt_0007 utt 36.69 39.80 -X IT IS MORE CONVENIENT TO USE HIGH-LEVEL INSTRUCTIONS.
utt_0008 utt 40.11 49.20 -X THIS TASK, HOWEVER, IS MORE CHALLENGING AS IT REQUIRES FINE-GRAINED OBJECT GROUNDING AS WELL AS THE EFFICIENT EXPLORATION IN THE ENVIRONMENTS.
utt_0010 utt 50.35 55.48 -X THE EXISTING VLN WORKS HOWEVER ARE INEFFICIENT IN EXPLORATION.
utt_0011 utt 55.57 61.75 -X THEY EITHER RELY ON A RECURRENT STATE OR SEQUENTIAL MEMORY TO CAPTURE THE WHOLE NAVIGATION HISTORY,
utt_0012 utt 62.00 65.97 -X WHICH ARE INSUFFICIENT TO CAPTURE THE RICH SPACE-TIME STRUCTURE.
utt_0013 utt 67.38 71.67 -X MOREOVER, THESE APPROACHES ONLY ALLOW TO MAKE LOCAL ACTIONS.
utt_0014 utt 71.96 83.61 -X IF AN AGENT NEEDS TO BACKTRACK N STEPS TO A NEW LOCATION, IT HAS TO RUN THE MODEL FOR N TIMES, WHICH INCREASES INSTABILITY AND COMPUTATION.
utt_0016 utt 83.64 94.30 -X TO ADDRESS THESE LIMITATIONS, IN THIS WORK, WE EXPLICITLY BUILD A MAP TO SUPPORT GLOBAL ACTIONS FOR EFFICIENT EXPLORATION.
utt_0018 utt 94.42 98.49 -X OUR MODEL IS CALLED DUET: DUAL SCALE GRAPH TRANSFORMER.
utt_0019 utt 98.87 104.28 -X IT CONSISTS OF TWO MODULES, TOPOLOGICAL MAPPING AND GLOBAL ACTION PLANNING.
utt_0020 utt 105.05 109.85 -X AT EACH STEP, THE TOPOLOGICAL MAPPING MODULE IS USED TO UPDATE THE MAP.
utt_0021 utt 111.19 118.20 -X THEN THE GLOBAL ACTION PLANNING MODULE USES THE INSTRUCTION AND THE MAP TO PREDICT THE NEXT LOCATION.
utt_0023 utt 119.64 125.28 -X WE WILL COMPUTE A SHORTEST PATH GIVEN THE MAP TO MAKE LOCAL ACTIONS IN THE ENVIRONMENT.
utt_0024 utt 127.74 134.36 -X IN THE TOPOLOGICAL MAPPING, WE FIRST ENCODE THE NEWLY OBSERVED PANORAMA VIA A TRANSFORMER ENCODER.
utt_0026 utt 134.43 140.00 -X BOTH THE VIEW IMAGES AND FINE-GRAINED OBJECT REPRESENTATIONS ARE CONSIDERED IN THE ENCODING.
utt_0027 utt 141.47 147.23 -X THEN WE ADD NEW NODES AND EDGES TO THE GRAPH, AND ALSO UPDATE THE NODE REPRESENTATIONS.
utt_0028 utt 148.89 153.34 -X FOR GLOBAL ACTION PLANNING, WE PROPOSE A DUAL-SCALE ENCODER.
utt_0029 utt 153.34 161.63 -X IT AIMS TO BALANCE THE COMPLEXITY ON REASONING OVER THE LARGE GRAPHS AND FINE-GRAINED CROSS-MODAL MATCHING.
utt_0031 utt 161.63 169.57 -X THE COARSE-SCALE ENCODER USES COARSE-GRAINED GRAPH REPRESENTATIONS TO PREDICT A GLOBAL ACTION VIA A GRAPH TRANSFORMER.
utt_0033 utt 170.36 177.92 -X THE FINE-SCALE ENCODER USES FINE-GRAINED REPRESENTATION OF CURRENT LOCATION TO PREDICT A LOCAL ACTION.
utt_0034 utt 177.92 180.19 -X WE DYNAMICALLY FUSE THE TWO ENCODERS.
utt_0035 utt 182.17 184.99 -X WE APPLY A TWO-STAGE TRAINING APPROACH FOR DUET.
utt_0036 utt 185.47 191.43 -X IN THE FIRST STAGE, WE PRETRAIN DUET WITH BEHAVIOR CLONING AND TWO AUXILIARY TASKS.
utt_0037 utt 192.03 200.07 -X IN THE SECOND STAGE, WE FINE-TUNE THE MODEL WITH A PSEUDO DEMONSTRATOR SINCE WE CAN OBTAIN THE SHORTEST PATH IN TRAINING PHASE.
utt_0039 utt 202.40 207.81 -X WE EVALUATE DUET ON BOTH VLN WITH HIGH-LEVEL INSTRUCTIONS AND FINE-GRAINED INSTRUCTIONS,
utt_0040 utt 208.06 212.29 -X INCLUDING REVERIE, SOON , RtwoR AND RfourR DATASETS.
utt_0041 utt 213.60 217.99 -X WE USE BOTH NAVIGATION AND OBJECT GROUNDING METRICS IN EVALUATION.
utt_0042 utt 218.69 221.64 -X WE CARRY OUT ABLATIONS ON REVERIE DATASET.
utt_0043 utt 221.83 225.25 -X WE FIRST EVALUATE THE PROPOSED DUAL-SCALE ENCODERS.
utt_0044 utt 225.25 231.14 -X &LTBR&GT THE COARSE SCALE ENCODER ACHIEVES HIGHER SR DUE TO THE GLOBAL ACTION SPACE.
utt_0045 utt 232.03 238.07 -X THE FINE-SCALE ENCODER HOWEVER, LEARNS BETTER STOPPING CRITERION DUE TO FINE-GRAINED REPRESENTATIONS
utt_0046 utt 239.33 244.28 -X THE DYNAMIC FUSION IS SUPERIOR THAN AVERAGE FUSION TO COMBINE THE TWO ENCODERS
utt_0047 utt 246.05 248.62 -X WE THEN EVALUATE THE TRAINING ALGORITHMS.
utt_0048 utt 249.64 255.82 -X THE AUXILIARY LOSSES ARE MORE BENEFICIAL TO THE OBJECT GROUNDING COMPARED TO THE BEHAVIOR CLONING BASELINE.
utt_0050 utt 257.25 260.75 -X RL FURTHER SIGNIFICANTLY IMPROVES THE NAVIGATION PERFORMANCE.
utt_0051 utt 262.79 266.70 -X AND OUR PROPOSED PID TRAINING IS MORE EFFECTIVE THAN RL
utt_0052 utt 269.80 276.01 -X OUR DUET MODEL OUTPERFORMS THE STATE-OF-THE-ART METHODS BY A LARGE MARGIN ON REVERIE AND SOON DATASETS.
utt_0054 utt 276.01 279.31 -X THE ABSOLUTE GAINS ON SR ARE MORE THAN twenty%.
utt_0055 utt 281.45 285.64 -X OUR MODEL ACHIEVED THE FIRST PLACE ON VLN CHALLENGES AT ICCV two thousand and twenty-one.
utt_0056 utt 288.94 294.86 -X FOR VLN WITH FINE-GRAINED INSTRUCTIONS, OUR DUET MODEL ALSO ACHIEVES BETTER SR ON BOTH RtwoR AND RfourR DATASETS.
utt_0059 utt 296.62 298.73 -X THANK YOU FOR LISTENING.
utt_0060 utt 298.73 302.00 -2.1253 PLEASE VISIT OUR PROJECT WEBSITE FOR MORE INFORMATION.
