utt_0000 utt 0.52 3.41 -X IN THIS WORK, WE INTRODUCE PLANEDEPTH,
utt_0001 utt 3.66 13.39 -X A SELF-SUPERVISED MONOCULAR DEPTH ESTIMATION METHOD VIA ORTHOGONAL PLANES.
utt_0002 utt 13.39 25.25 -X FOR THE OUTDOOR DRIVE SCENES, WE PROPOSE TO USE FRONTAL-PARALLEL PLANES AND GROUND PLANES TO MODEL VERTICAL OBJECTS AND THE GROUND, RESPECTIVELY. THIS APPROACH ENABLES US TO
utt_0004 utt 25.25 30.51 -X SEGMENT THE GROUND IN AN UNSUPERVISED MANNER, AND PREDICT SMOOTH DEPTH FOR THE GROUND,
utt_0005 utt 30.51 44.53 -X WHICH IS IMPORTANT FOR AUTONOMOUS DRIVING. THE PREDEFINED PLANES PROVIDE DEPTH CANDIDATES FOR EACH RAY. BASED ON THIS, WE PROPOSE TO MODEL THE DEPTH AS A MIXTURE LAPLACE DISTRIBUTION ALONG
utt_0007 utt 44.53 50.32 -X THE RAY, WITH EACH CANDIDATE REPRESENTING THE MEAN OF A PEAK IN THE DISTRIBUTION.
utt_0008 utt 50.32 62.17 -X WE ALSO ADDRESS THE ISSUE OF ARTIFACTS CAUSED BY OCCLUSION IN THE POST-PROCESSING. WITH OUR BILATERAL MASK TO FURTHER IMPROVE THE SELF-DISTILLATION LABEL AND FINAL RESULTS.
utt_0010 utt 66.07 79.93 -X SINCE THE WIDELY USED RESIZING CROPPING AUGMENTATION CAUSE GROUND SLOPES, THE GROUND AND THE VERTICAL OBJECT BECOME NO LONGER ORTHOGONAL. WE HAVE TO RECTIFY OUR GROUND PLANES ACCORDINGLY,
utt_0012 utt 80.69 94.55 -X WHICH COULD BE SEEN HERE. WE RECTIFY THE PARAMETERS OF PREDEFINED PLANES USING THE RESIZING CROPPING MATRIX, ENSURING THAT THEY REMAIN PARALLEL TO THE GROUND. HOWEVER, WE FOUND
utt_0014 utt 94.55 109.47 -X THAT THE NETWORK STILL HARDLY USES THE GROUND PLANES.THIS CAN BE ATTRIBUTED TO THE VARIATIONS IN GROUND DEPTH CANDIDATES FOR EACH PIXEL CAUSED BY THE RECTIFICATION PROCESS. SO THE NETWORK HAS TO
utt_0016 utt 109.47 116.00 -X PREDICT THE CURRENT RECTIFICATION FIRST, AND THEN PREDICT THE DEPTH, WHICH MAKE IT HARD TO LEARN.
utt_0017 utt 116.92 123.23 -X TO ADDRESS THIS PROBLEM, WE INPUT THE PARAMETERS OF RESIZING CROPPING DURING TRAINING VIA NEURAL
utt_0018 utt 123.26 128.83 -X POSITIONAL ENCODING TO INFORM THE NETWORK ABOUT THE CURRENT RECTIFICATION STATUS.
utt_0019 utt 130.33 136.16 -X IN THIS WAY, WE CAN ATTAIN IMPROVED SEGMENTATION AND SMOOTHER DEPTH FOR THE GROUND.
utt_0020 utt 138.23 149.34 -X PREVIOUS METHODS WARP SOURCE IMAGE TO THE REFERENCE VIEW USING PLANES AND THEN COMPOSE THEM TO A SYNTHETIC IMAGE BEFORE COMPUTING Lone ERROR, WHICH INTRODUCES A NON-TRIVIAL
utt_0022 utt 150.01 156.93 -X CHALLENGE. AS DIFFERENT WEIGHTS MAY RESULT IN IDENTICAL SYNTHETIC COLOR.
utt_0023 utt 156.93 167.65 -X TO ADDRESS THIS CHALLENGE, OUR MIXTURE LAPLACE LOSS IS ACTUALLY COMPUTES THE ERROR INDIVIDUALLY ON EACH WARPED PLANE BEFORE COMPOSITION, WHILE INCORPORATING THE INHERENT
utt_0025 utt 167.65 172.38 -X UNCERTAINTY OF THE DISTRIBUTION. THIS APPROACH ENHANCES TRAINING STABILITY.
utt_0026 utt 172.57 181.03 -X WE MINIMIZE THE NEGATIVE LOG-LIKELIHOOD OF THE PROBABILITY DISTRIBUTION AS OUR LOSS FUNCTION.
utt_0027 utt 181.21 193.15 -X AS DONE IN THE PREVIOUS METHOD, IF WE ALWAYS USE LEFT VIEW AS INPUT AND COMPUTE LOSS ON THE RIGHT VIEW, THE OCCLUSION WILL ONLY OCCUR ON THE LEFT SIDE OF OBJECTS IN THE LEFT VIEW.
utt_0029 utt 193.85 206.82 -X SO ALL DEPTH ARTIFACTS CAUSED BY OCCLUSION WILL APPEAR ON THE LEFT OF OBJECTS IN ALL INPUT IMAGES.TAKE ADVANTAGE OF THIS, FOR EACH SINGLE INPUT IMAGE, WE CAN GET TWO DEPTH MAPS:
utt_0031 utt 207.07 217.96 -X ONE WITH ONLY LEFT ARTIFACTS AND ANOTHER WITH ONLY RIGHT ARTIFACTS. THEN TOGETHER WITH THE OCCLUSION MASK COMPUTE FROM PROBABILITY VOLUME, WE CAN FILTER THE ARTIFACT.
utt_0033 utt 222.63 229.06 -X SIMILARLY, IF WE APPLIED THE WIDELY USED POST-PROCESSING TO FURTHER IMPROVE THE RESULTS,
utt_0034 utt 229.06 241.13 -X THE ARTIFACTS WILL OCCUR ON BOTH SIDES OF OBJECTS, THEN, WE COULD FILTER THEM WITH OUR BILATERAL MASK TO GET BETTER POST-PROCESSING RESULTS AND SELF-DISTILLATION LABELS.
utt_0036 utt 241.67 247.43 -X EXTENSIVE EXPERIMENTS DEMONSTRATE THE EFFECTIVENESS AND EFFICIENCY OF OUR METHOD.
utt_0037 utt 252.96 257.74 -3.3785 THANK YOU FOR WATCHING HERE ARE SOME VISUAL RESULTS IF YOU ARE INTERESTED.
