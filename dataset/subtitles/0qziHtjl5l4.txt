utt_0000 utt 0.19 5.81 -X WE INTRODUCE PARTGLOT, LEARNING SHAPE PART SEGMENTATION FROM LANGUAGE REFERENCE GAMES.
utt_0001 utt 6.25 17.11 -X threeD PART SEGMENTATION IS AN ESSENTIAL TASK IN MANY APPLICATIONS. HOWEVER, TYPICAL SUPERVISED METHODS REQUIRE MANUAL PART ANNOTATIONS ON threeD SHAPES.
utt_0002 utt 17.45 25.62 -X ANNOTATING PARTS ON threeD SHAPES IS A NON-TRIVIAL TASK THAT REQUIRES LOTS OF HUMAN HOURS AND EXPERTISE.
utt_0003 utt 25.62 35.47 -X AND SUCH A CHALLENGE IN ANNOTATION HAS BEEN A BOTTLENECK IN DEALING WITH DIVERSE SHAPES AMID THE MASSIVE INCREASE IN THE DEMAND FOR PARSING threeD SHAPES.
utt_0004 utt 35.53 44.88 -X COMPARING WITH THIS, DESCRIBING A threeD SHAPE WITH NATURAL LANGUAGE IS A MUCH EASIER TASK THAT DOES NOT REQUIRE ANY EXPERTISE OR LOTS OF WORK.
utt_0005 utt 44.98 55.25 -X HENCE, WE PROPOSE PARTGLOT, A FRAMEWORK FOR LEARNING PART SEGMENTATION ONLY FROM A LINGUISTIC DESCRIPTION OF A SHAPE, WITHOUT ANY PART ANNOTATIONS.
utt_0006 utt 55.66 65.97 -X WE DEMONSTRATE THAT REFERENTIAL LANGUAGE OF A threeD SHAPE CAN BE LEVERAGED TO GUIDE THE LEARNING PROCESS TO DISCOVER SEMANTIC PARTS OF THE threeD SHAPE.
utt_0007 utt 65.97 76.37 -X A LINGUISTIC DESCRIPTION OF A threeD SHAPE CAN BE EASILY OBTAINED FROM A SPEAKER-AND-LISTENER CONVERSATION ABOUT THE threeD SHAPE, WHICH WE CALL REFERENCE GAME.
utt_0008 utt 76.40 81.53 -X GIVEN A TRIPLET OF SHAPES, WE LET THE SPEAKER DESCRIBE THE TARGET SHAPE,
utt_0009 utt 81.53 86.17 -X SO THAT THE LISTENER CAN DISCRIMINATE THE TARGET FROM THE OTHER TWO DISTRACTORS.
utt_0010 utt 86.71 96.57 -X SINCE THE CHARACTERISTICS OF THE TARGET SHAPE ARE USUALLY DEPICTED WITH DISCRIMINATIVE PARTS, THE LISTENER CAN FIND THE TARGET WHILE FOCUSING ON THE DESCRIBED PARTS.
utt_0011 utt 96.95 107.58 -X OUR KEY IDEA HERE IS TO BUILD A NEURAL LISTENER FINDING THE TARGET SHAPE WHILE CREATING AN ATTENTION MODULE THAT DISCOVERS THE SEMANTIC PART DESCRIBED IN THE INPUT UTTERANCE.
utt_0012 utt 108.12 122.62 -X HERE IS THE PARTGLOT FRAMEWORK. FIRST, THERE ARE THREE ENCODERS THAT TAKE AN UTTERANCE AND SUPER-SEGMENTS OF A SHAPE AS INPUT. WE USE LSTM AND A VARIANT OF POINTNET AS THE UTTERANCE AND SUPER-SEGMENT ENCODERS.
utt_0013 utt 123.25 132.57 -X THEN THE FEATURE OF THE INPUT UTTERANCE AND SUPER-SEGMENTS OF THE INPUT SHAPE ARE FED TO THE ATTENTION MODULE TO COMPUTE ATTENTION MAPS.
utt_0014 utt 132.57 138.14 -X REFER TO OUR PAPER FOR THE CRUCIAL DETAILS IN THE DESIGN OF THE ENCODER AND THE ATTENTION MODULE.
utt_0015 utt 138.77 147.48 -X LASTLY, AN MLP PREDICTS A CLASSIFICATION SCORE FROM THE OUTPUTS OF THE ATTENTION MODULE AND CLASSIFICATION ENCODER.
utt_0016 utt 147.48 157.95 -X IF A SET OF PREDEFINED PART NAMES IS GIVEN IN THE TRAINING, PARTGLOT CAN LEVERAGE THIS AS ADDITIONAL SUPERVISION, WHICH WE CALL THE PART-NAME-AWARE LEARNING.
utt_0017 utt 157.95 171.01 -X HERE, THE ATTENTION MAPS ARE COMPUTED FOR ALL THE PART NAMES AND NORMALIZED OVER THEM. THEN, THE ATTENTION MAP OF THE PART NAME INCLUDED IN THE UTTERANCE IS USED FOR THE TARGET SHAPE CLASSIFICATION.
utt_0018 utt 171.01 181.41 -X IN THE INFERENCE TIME, IF PARTGLOT IS TRAINED WITHOUT THE PART NAMES, WE USE A TEMPLATE UTTERANCE WITH A PART NAME TO OBTAIN THE ATTENTION MAP OF THE PART.
utt_0019 utt 181.41 188.06 -X IN PART-NAME-AWARE CASE, WE DIRECTLY FEED A PART NAME INSTEAD OF A TEMPLATE UTTERANCE WITH A threeD SHAPE.
utt_0020 utt 188.19 199.58 -X THE FINAL PART SEGMENTS ARE OBTAINED BY NORMALIZING THE ATTENTION MAPS OVER THE SUPER-SEGMENTS AND TAKING THE ARGMAX OF THE ATTENTION MAPS ALONG THE PART NAMES OR UTTERANCES.
utt_0021 utt 200.35 211.49 -X HERE ARE OUR QUALITATIVE RESULTS. COMPARED TO GROUND TRUTHS, BOTH THE PART-NAME-AGNOSTIC AND PART-NAME-AWARE LEARNING CASES DISCOVER THE SEMANTIC PARTS CORRECTLY.
utt_0022 utt 211.58 225.19 -X WHEN THE PART NAMES ARE GIVEN AS ADDITIONAL SUPERVISION, PARTGLOT FURTHER IMPROVES THE SEGMENTATION, ESPECIALLY IN CHALLENGING CASES SUCH AS DISTINGUISHING BETWEEN SIMILAR-LOOKING ARMS AND LEGS.
utt_0023 utt 225.63 237.44 -X QUANTITATIVELY, OUR PARTGLOT ALSO ACHIEVES seventy-nine% MIOU IN THE SHAPENET CHAIR PART SEGMENTATION, WHICH IS COMPARABLE TO THE RESULTS OF A SUPERVISED METHOD.
utt_0024 utt 237.95 247.46 -X WE ALSO FIND THAT OUR PARTGLOT TRAINED WITH LINGUISTIC DESCRIPTIONS CAN BE ZERO-SHOT GENERALIZABLE TO THE OTHER CLASSES OF threeD SHAPES.
utt_0025 utt 247.46 261.73 -X FOR INSTANCE, WHEN TRAINING WITH CHAIR DATASET AND TESTING WITH TABLES AND LAMPS, PARTGLOT DETECTS THE TABLE TOP AND LAMP SHADE AS CHAIR SEAT, AND ALSO THE TABLE LEG AND LAMP BASE AS CHAIR LEG.
utt_0026 utt 262.24 272.90 -X ALSO, PARTGLOT DISCOVERS NOT ONLY SEMANTIC PARTS IN THE threeD SHAPE BUT ALSO CORRESPONDING WORDS IN THE UTTERANCE THROUGH ANOTHER ATTENTION.
utt_0027 utt 272.90 281.64 -X THE ATTENTION ENCODER OF THE UTTERANCE DECIDES WHERE TO LOOK IN THE TARGET SHAPE DISCRIMINATION, AND IT ATTENDS TO THE PROPER PART WORD IN THE UTTERANCE.
utt_0028 utt 282.56 294.47 -X WE ALSO EXPERIMENTED WITH SYNTHETIC DESCRIPTION ABOUT FINER-GRAINED PARTS IN PARTNET. AS SHOWN HERE, OUR PARTGLOT ALSO ACCURATELY DISCOVERS THE FINE-GRAINED PARTS.
utt_0029 utt 294.56 299.27 -4.9044 PLEASE COME TO OUR POSTER AT forty-nine FOR MORE DETAILS. THANK YOU.
